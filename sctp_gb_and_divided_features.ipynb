{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import cluster\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras import callbacks\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_id_droped = train_df[train_df.columns.drop('ID_code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94672,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['var_0'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.apply(pd.unique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_dict = {column_name: train_df_id_droped[column_name].unique() for column_name in train_df_id_droped.columns.drop('target').tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_dict_counts = {column_name: uniques.shape[0] for column_name, uniques in uniques_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_counts_series = pd.Series(uniques_dict_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_0     94672\n",
       "var_1    108932\n",
       "var_2     86555\n",
       "var_3     74597\n",
       "var_4     63515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = plt.figure(figsize=(24, 18))\\nax = fig.add_subplot(111)\\nax.bar(np.arange(200), uniques_counts_series.values.astype(np.int64))\\n#ax.bar(uniques_counts_series)\\nax.set_title('Features uniques values num')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(200), uniques_counts_series.values.astype(np.int64))\n",
    "#ax.bar(uniques_counts_series)\n",
    "ax.set_title('Features uniques values num')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cells execution time: 0.33239564498265584 min\n"
     ]
    }
   ],
   "source": [
    "all_cells_execution_time = time.time() - start_time\n",
    "print(\"all cells execution time: {} min\".format(all_cells_execution_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_id_droped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(24, 18))\\nplt.title(\"Distributon of unqie values per column in the train dataset\")\\n#sns.distplot(train_df_id_droped[train_df_id_droped.columns.drop(\\'target\\').tolist()].unique(), color=\\'green\\', kde=True, bins=200, label=\"train\")\\nsns.distplot(uniques_counts_series.values.astype(np.int64), color=\\'green\\', kde=True, bins=200, label=\"train\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(24, 18))\n",
    "plt.title(\"Distributon of unqie values per column in the train dataset\")\n",
    "#sns.distplot(train_df_id_droped[train_df_id_droped.columns.drop('target').tolist()].unique(), color='green', kde=True, bins=200, label=\"train\")\n",
    "sns.distplot(uniques_counts_series.values.astype(np.int64), color='green', kde=True, bins=200, label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = train_df.columns.values[2:202]\\nplt.figure(figsize=(24, 18))\\nplt.title(\"Distribution of mean values per column in the train and test set\")\\nsns.distplot(train_df[features].mean(axis=0), color=\"magenta\", kde=True,bins=120, label=\\'train\\')\\n#sns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label=\\'test\\')\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.figure(figsize=(24, 18))\n",
    "plt.title(\"Distribution of mean values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].mean(axis=0), color=\"magenta\", kde=True,bins=120, label='train')\n",
    "#sns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(24, 18))\\nfeatures = train_df.columns.values[2:202]\\n#plt.title(\"Distribution of mean values per row in the train and test set\")\\nplt.title(\"Distribution of mean values per row in the train set\")\\nsns.distplot(train_df[features].mean(axis=1), color=\"blue\", kde=True, bins=120, label=\\'train\\')\\n#sns.distplot(test_df[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label=\\'test\\')\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(24, 18))\n",
    "features = train_df.columns.values[2:202]\n",
    "#plt.title(\"Distribution of mean values per row in the train and test set\")\n",
    "plt.title(\"Distribution of mean values per row in the train set\")\n",
    "sns.distplot(train_df[features].mean(axis=1), color=\"blue\", kde=True, bins=120, label='train')\n",
    "#sns.distplot(test_df[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\\noof = np.zeros(len(train_df))\\npredictions = np.zeros(len(test_df))\\nfeature_importance_df = pd.DataFrame()\\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\\n    print(\"Fold {}\".format(fold_))\\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\\n    num_round = 1000000\\n    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\\n    fold_importance_df = pd.DataFrame()\\n    fold_importance_df[\\'Feature\\'] = features\\n    fold_importance_df[\\'importance\\'] = clf.feature_importance()\\n    fold_importance_df[\\'fold\\'] = fold_ + 1\\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['importance'] = clf.feature_importance()\n",
    "    fold_importance_df['fold'] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols = (feature_importance_df[[\"Feature\", \"importance\"]]\\n        .groupby(\"Feature\")\\n        .mean()\\n        .sort_values(by=\"importance\", ascending=False)[:150].index)\\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\\n\\nplt.figure(figsize=(14,28))\\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\\nplt.title(\\'Features importance (averaged/folds)\\')\\nplt.tight_layout()\\nplt.savefig(\\'FI.png\\')\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rows_count = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_rows_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_2 = uniques_counts_series[uniques_counts_series > train_df_rows_count / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_4_less_1_2 = uniques_counts_series[uniques_counts_series < train_df_rows_count / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniques_count_less_1_2_more_1_4 = uniques_counts_series[\n",
    "#    ((uniques_counts_series < train_df_rows_count / 2).bool() and (uniques_counts_series > train_df_rows_count / 4).bool()).bool()\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_less_1_2_more_1_4 = uniques_count_more_1_4_less_1_2[uniques_count_more_1_4_less_1_2 > train_df_rows_count / 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_4_less_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_less_1_4 = uniques_counts_series[uniques_counts_series < train_df_rows_count / 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_less_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_6     38599\n",
       "var_9     49417\n",
       "var_12     9561\n",
       "var_15    19810\n",
       "var_23    24913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_less_1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniques_count_less_1_4.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, target, features, param, num_round=1000000):\n",
    "    start_time = time.time()\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "    oof = np.zeros(len(train_df))\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    lgb_classifier = None\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "        num_round = num_round\n",
    "        clf = lgb.train(\n",
    "            param,\n",
    "            trn_data,\n",
    "            num_round,\n",
    "            valid_sets=[trn_data, val_data],\n",
    "            verbose_eval=1000,\n",
    "            early_stopping_rounds=3000\n",
    "        )\n",
    "        lgb_classifier = clf\n",
    "        oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['Feature'] = features\n",
    "        fold_importance_df['importance'] = clf.feature_importance()\n",
    "        fold_importance_df['fold'] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    print(\"Total run time {} min:\".format((time.time() - start_time) / 60))\n",
    "    print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "    return oof, predictions, feature_importance_df, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.836449\tvalid_1's auc: 0.819362\n",
      "[2000]\ttraining's auc: 0.845447\tvalid_1's auc: 0.823533\n",
      "[3000]\ttraining's auc: 0.852066\tvalid_1's auc: 0.82583\n",
      "[4000]\ttraining's auc: 0.858253\tvalid_1's auc: 0.826207\n",
      "[5000]\ttraining's auc: 0.864232\tvalid_1's auc: 0.826657\n",
      "[6000]\ttraining's auc: 0.869822\tvalid_1's auc: 0.826773\n",
      "[7000]\ttraining's auc: 0.875256\tvalid_1's auc: 0.826797\n",
      "[8000]\ttraining's auc: 0.880766\tvalid_1's auc: 0.826868\n",
      "[9000]\ttraining's auc: 0.886046\tvalid_1's auc: 0.826551\n",
      "[10000]\ttraining's auc: 0.89129\tvalid_1's auc: 0.826084\n",
      "Early stopping, best iteration is:\n",
      "[7789]\ttraining's auc: 0.879598\tvalid_1's auc: 0.826957\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837076\tvalid_1's auc: 0.81285\n",
      "[2000]\ttraining's auc: 0.845801\tvalid_1's auc: 0.817226\n",
      "[3000]\ttraining's auc: 0.852524\tvalid_1's auc: 0.819153\n",
      "[4000]\ttraining's auc: 0.858646\tvalid_1's auc: 0.820293\n",
      "[5000]\ttraining's auc: 0.86449\tvalid_1's auc: 0.820602\n",
      "[6000]\ttraining's auc: 0.870205\tvalid_1's auc: 0.820765\n",
      "[7000]\ttraining's auc: 0.875586\tvalid_1's auc: 0.821063\n",
      "[8000]\ttraining's auc: 0.881104\tvalid_1's auc: 0.820872\n",
      "[9000]\ttraining's auc: 0.886385\tvalid_1's auc: 0.82061\n",
      "[10000]\ttraining's auc: 0.89155\tvalid_1's auc: 0.820347\n",
      "Early stopping, best iteration is:\n",
      "[7150]\ttraining's auc: 0.876402\tvalid_1's auc: 0.821213\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838141\tvalid_1's auc: 0.807929\n",
      "[2000]\ttraining's auc: 0.846529\tvalid_1's auc: 0.811863\n",
      "[3000]\ttraining's auc: 0.853191\tvalid_1's auc: 0.813311\n",
      "[4000]\ttraining's auc: 0.859342\tvalid_1's auc: 0.814044\n",
      "[5000]\ttraining's auc: 0.865203\tvalid_1's auc: 0.814173\n",
      "[6000]\ttraining's auc: 0.870852\tvalid_1's auc: 0.813993\n",
      "[7000]\ttraining's auc: 0.876352\tvalid_1's auc: 0.813619\n",
      "[8000]\ttraining's auc: 0.881739\tvalid_1's auc: 0.813524\n",
      "Early stopping, best iteration is:\n",
      "[5294]\ttraining's auc: 0.866862\tvalid_1's auc: 0.814361\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83737\tvalid_1's auc: 0.814511\n",
      "[2000]\ttraining's auc: 0.84593\tvalid_1's auc: 0.818681\n",
      "[3000]\ttraining's auc: 0.852735\tvalid_1's auc: 0.820327\n",
      "[4000]\ttraining's auc: 0.858933\tvalid_1's auc: 0.821008\n",
      "[5000]\ttraining's auc: 0.864774\tvalid_1's auc: 0.821135\n",
      "[6000]\ttraining's auc: 0.870494\tvalid_1's auc: 0.82112\n",
      "[7000]\ttraining's auc: 0.875947\tvalid_1's auc: 0.821159\n",
      "[8000]\ttraining's auc: 0.881307\tvalid_1's auc: 0.820649\n",
      "[9000]\ttraining's auc: 0.886576\tvalid_1's auc: 0.820463\n",
      "Early stopping, best iteration is:\n",
      "[6494]\ttraining's auc: 0.873253\tvalid_1's auc: 0.821365\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837201\tvalid_1's auc: 0.815883\n",
      "[2000]\ttraining's auc: 0.845801\tvalid_1's auc: 0.818807\n",
      "[3000]\ttraining's auc: 0.852523\tvalid_1's auc: 0.82041\n",
      "[4000]\ttraining's auc: 0.858805\tvalid_1's auc: 0.820887\n",
      "[5000]\ttraining's auc: 0.864648\tvalid_1's auc: 0.820858\n",
      "[6000]\ttraining's auc: 0.870328\tvalid_1's auc: 0.820962\n",
      "[7000]\ttraining's auc: 0.875798\tvalid_1's auc: 0.820743\n",
      "Early stopping, best iteration is:\n",
      "[4169]\ttraining's auc: 0.859817\tvalid_1's auc: 0.821108\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.836614\tvalid_1's auc: 0.816979\n",
      "[2000]\ttraining's auc: 0.845298\tvalid_1's auc: 0.8223\n",
      "[3000]\ttraining's auc: 0.852074\tvalid_1's auc: 0.823567\n",
      "[4000]\ttraining's auc: 0.85838\tvalid_1's auc: 0.824654\n",
      "[5000]\ttraining's auc: 0.864291\tvalid_1's auc: 0.825168\n",
      "[6000]\ttraining's auc: 0.870026\tvalid_1's auc: 0.825245\n",
      "[7000]\ttraining's auc: 0.875607\tvalid_1's auc: 0.824881\n",
      "[8000]\ttraining's auc: 0.880936\tvalid_1's auc: 0.824322\n",
      "Early stopping, best iteration is:\n",
      "[5646]\ttraining's auc: 0.868012\tvalid_1's auc: 0.825416\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837153\tvalid_1's auc: 0.816308\n",
      "[2000]\ttraining's auc: 0.845773\tvalid_1's auc: 0.819828\n",
      "[3000]\ttraining's auc: 0.852615\tvalid_1's auc: 0.821906\n",
      "[4000]\ttraining's auc: 0.858637\tvalid_1's auc: 0.822926\n",
      "[5000]\ttraining's auc: 0.8646\tvalid_1's auc: 0.82323\n",
      "[6000]\ttraining's auc: 0.87036\tvalid_1's auc: 0.823403\n",
      "[7000]\ttraining's auc: 0.875825\tvalid_1's auc: 0.823228\n",
      "[8000]\ttraining's auc: 0.881214\tvalid_1's auc: 0.823043\n",
      "Early stopping, best iteration is:\n",
      "[5996]\ttraining's auc: 0.870341\tvalid_1's auc: 0.823436\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837297\tvalid_1's auc: 0.814775\n",
      "[2000]\ttraining's auc: 0.845852\tvalid_1's auc: 0.818869\n",
      "[3000]\ttraining's auc: 0.852618\tvalid_1's auc: 0.820686\n",
      "[4000]\ttraining's auc: 0.858746\tvalid_1's auc: 0.820824\n",
      "[5000]\ttraining's auc: 0.864679\tvalid_1's auc: 0.82129\n",
      "[6000]\ttraining's auc: 0.870403\tvalid_1's auc: 0.821242\n",
      "[7000]\ttraining's auc: 0.875887\tvalid_1's auc: 0.821146\n",
      "[8000]\ttraining's auc: 0.881266\tvalid_1's auc: 0.821139\n",
      "Early stopping, best iteration is:\n",
      "[5110]\ttraining's auc: 0.865289\tvalid_1's auc: 0.821403\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837407\tvalid_1's auc: 0.818679\n",
      "[2000]\ttraining's auc: 0.845927\tvalid_1's auc: 0.822556\n",
      "[3000]\ttraining's auc: 0.852328\tvalid_1's auc: 0.823827\n",
      "[4000]\ttraining's auc: 0.858727\tvalid_1's auc: 0.824384\n",
      "[5000]\ttraining's auc: 0.864571\tvalid_1's auc: 0.824331\n",
      "[6000]\ttraining's auc: 0.870117\tvalid_1's auc: 0.824362\n",
      "[7000]\ttraining's auc: 0.875658\tvalid_1's auc: 0.824355\n",
      "Early stopping, best iteration is:\n",
      "[4415]\ttraining's auc: 0.861206\tvalid_1's auc: 0.824684\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837504\tvalid_1's auc: 0.81507\n",
      "[2000]\ttraining's auc: 0.846349\tvalid_1's auc: 0.818156\n",
      "[3000]\ttraining's auc: 0.852866\tvalid_1's auc: 0.819337\n",
      "[4000]\ttraining's auc: 0.859122\tvalid_1's auc: 0.819734\n",
      "[5000]\ttraining's auc: 0.864944\tvalid_1's auc: 0.820142\n",
      "[6000]\ttraining's auc: 0.870478\tvalid_1's auc: 0.819976\n",
      "[7000]\ttraining's auc: 0.876074\tvalid_1's auc: 0.819546\n",
      "[8000]\ttraining's auc: 0.881559\tvalid_1's auc: 0.819124\n",
      "Early stopping, best iteration is:\n",
      "[5267]\ttraining's auc: 0.866477\tvalid_1's auc: 0.820232\n",
      "Total run time 18.519540925820667 min:\n",
      "CV score: 0.82181 \n"
     ]
    }
   ],
   "source": [
    "train_results_more_1_2 = train(train_df, test_df, target, uniques_count_more_1_2.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772379\tvalid_1's auc: 0.741305\n",
      "[2000]\ttraining's auc: 0.778907\tvalid_1's auc: 0.742285\n",
      "[3000]\ttraining's auc: 0.78477\tvalid_1's auc: 0.742419\n",
      "[4000]\ttraining's auc: 0.790565\tvalid_1's auc: 0.742499\n",
      "[5000]\ttraining's auc: 0.796234\tvalid_1's auc: 0.742592\n",
      "Early stopping, best iteration is:\n",
      "[2500]\ttraining's auc: 0.782039\tvalid_1's auc: 0.742856\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771593\tvalid_1's auc: 0.748627\n",
      "[2000]\ttraining's auc: 0.778487\tvalid_1's auc: 0.749908\n",
      "[3000]\ttraining's auc: 0.784376\tvalid_1's auc: 0.749326\n",
      "[4000]\ttraining's auc: 0.790141\tvalid_1's auc: 0.74907\n",
      "[5000]\ttraining's auc: 0.795899\tvalid_1's auc: 0.749057\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's auc: 0.779966\tvalid_1's auc: 0.750254\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772997\tvalid_1's auc: 0.737963\n",
      "[2000]\ttraining's auc: 0.779626\tvalid_1's auc: 0.739392\n",
      "[3000]\ttraining's auc: 0.785579\tvalid_1's auc: 0.73971\n",
      "[4000]\ttraining's auc: 0.791248\tvalid_1's auc: 0.73936\n",
      "[5000]\ttraining's auc: 0.796893\tvalid_1's auc: 0.739274\n",
      "[6000]\ttraining's auc: 0.80269\tvalid_1's auc: 0.739035\n",
      "Early stopping, best iteration is:\n",
      "[3161]\ttraining's auc: 0.786431\tvalid_1's auc: 0.739781\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771872\tvalid_1's auc: 0.747499\n",
      "[2000]\ttraining's auc: 0.778401\tvalid_1's auc: 0.748093\n",
      "[3000]\ttraining's auc: 0.784342\tvalid_1's auc: 0.74764\n",
      "[4000]\ttraining's auc: 0.790019\tvalid_1's auc: 0.74776\n",
      "Early stopping, best iteration is:\n",
      "[1744]\ttraining's auc: 0.776637\tvalid_1's auc: 0.748236\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771952\tvalid_1's auc: 0.74676\n",
      "[2000]\ttraining's auc: 0.778441\tvalid_1's auc: 0.748555\n",
      "[3000]\ttraining's auc: 0.784194\tvalid_1's auc: 0.749124\n",
      "[4000]\ttraining's auc: 0.790029\tvalid_1's auc: 0.749077\n",
      "[5000]\ttraining's auc: 0.795629\tvalid_1's auc: 0.749408\n",
      "[6000]\ttraining's auc: 0.801543\tvalid_1's auc: 0.749246\n",
      "[7000]\ttraining's auc: 0.807335\tvalid_1's auc: 0.74886\n",
      "[8000]\ttraining's auc: 0.812987\tvalid_1's auc: 0.748721\n",
      "Early stopping, best iteration is:\n",
      "[5634]\ttraining's auc: 0.799409\tvalid_1's auc: 0.749554\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771907\tvalid_1's auc: 0.748371\n",
      "[2000]\ttraining's auc: 0.778453\tvalid_1's auc: 0.749848\n",
      "[3000]\ttraining's auc: 0.784327\tvalid_1's auc: 0.749354\n",
      "[4000]\ttraining's auc: 0.790126\tvalid_1's auc: 0.748775\n",
      "Early stopping, best iteration is:\n",
      "[1722]\ttraining's auc: 0.776629\tvalid_1's auc: 0.750204\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772484\tvalid_1's auc: 0.741211\n",
      "[2000]\ttraining's auc: 0.778999\tvalid_1's auc: 0.74236\n",
      "[3000]\ttraining's auc: 0.784811\tvalid_1's auc: 0.742919\n",
      "[4000]\ttraining's auc: 0.790679\tvalid_1's auc: 0.742781\n",
      "[5000]\ttraining's auc: 0.796364\tvalid_1's auc: 0.74281\n",
      "[6000]\ttraining's auc: 0.802233\tvalid_1's auc: 0.74233\n",
      "Early stopping, best iteration is:\n",
      "[3573]\ttraining's auc: 0.788257\tvalid_1's auc: 0.743142\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772164\tvalid_1's auc: 0.74432\n",
      "[2000]\ttraining's auc: 0.77872\tvalid_1's auc: 0.744878\n",
      "[3000]\ttraining's auc: 0.784661\tvalid_1's auc: 0.744347\n",
      "[4000]\ttraining's auc: 0.790484\tvalid_1's auc: 0.743797\n",
      "Early stopping, best iteration is:\n",
      "[1746]\ttraining's auc: 0.777203\tvalid_1's auc: 0.745094\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771936\tvalid_1's auc: 0.750562\n",
      "[2000]\ttraining's auc: 0.778404\tvalid_1's auc: 0.7509\n",
      "[3000]\ttraining's auc: 0.784202\tvalid_1's auc: 0.751218\n",
      "[4000]\ttraining's auc: 0.789994\tvalid_1's auc: 0.750821\n",
      "[5000]\ttraining's auc: 0.795768\tvalid_1's auc: 0.750642\n",
      "[6000]\ttraining's auc: 0.801562\tvalid_1's auc: 0.749857\n",
      "Early stopping, best iteration is:\n",
      "[3051]\ttraining's auc: 0.784434\tvalid_1's auc: 0.751275\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772258\tvalid_1's auc: 0.747536\n",
      "[2000]\ttraining's auc: 0.778676\tvalid_1's auc: 0.748527\n",
      "[3000]\ttraining's auc: 0.78447\tvalid_1's auc: 0.748814\n",
      "[4000]\ttraining's auc: 0.79024\tvalid_1's auc: 0.74886\n",
      "[5000]\ttraining's auc: 0.795989\tvalid_1's auc: 0.748595\n",
      "Early stopping, best iteration is:\n",
      "[2636]\ttraining's auc: 0.782482\tvalid_1's auc: 0.749035\n",
      "Total run time 11.460956879456837 min:\n",
      "CV score: 0.74490 \n"
     ]
    }
   ],
   "source": [
    "train_results_less_1_2_more_1_4 = train(train_df, test_df, target, uniques_count_less_1_2_more_1_4.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744883\tvalid_1's auc: 0.710591\n",
      "[2000]\ttraining's auc: 0.750561\tvalid_1's auc: 0.712807\n",
      "[3000]\ttraining's auc: 0.753888\tvalid_1's auc: 0.713001\n",
      "[4000]\ttraining's auc: 0.75647\tvalid_1's auc: 0.712625\n",
      "Early stopping, best iteration is:\n",
      "[1837]\ttraining's auc: 0.750068\tvalid_1's auc: 0.713563\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744471\tvalid_1's auc: 0.712185\n",
      "[2000]\ttraining's auc: 0.749998\tvalid_1's auc: 0.715383\n",
      "[3000]\ttraining's auc: 0.75323\tvalid_1's auc: 0.716157\n",
      "[4000]\ttraining's auc: 0.755847\tvalid_1's auc: 0.715947\n",
      "[5000]\ttraining's auc: 0.758416\tvalid_1's auc: 0.715308\n",
      "[6000]\ttraining's auc: 0.760556\tvalid_1's auc: 0.714514\n",
      "Early stopping, best iteration is:\n",
      "[3082]\ttraining's auc: 0.753392\tvalid_1's auc: 0.71638\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744833\tvalid_1's auc: 0.71363\n",
      "[2000]\ttraining's auc: 0.750203\tvalid_1's auc: 0.715187\n",
      "[3000]\ttraining's auc: 0.753513\tvalid_1's auc: 0.715357\n",
      "[4000]\ttraining's auc: 0.756268\tvalid_1's auc: 0.714718\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's auc: 0.749507\tvalid_1's auc: 0.716002\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.745151\tvalid_1's auc: 0.714864\n",
      "[2000]\ttraining's auc: 0.750299\tvalid_1's auc: 0.716888\n",
      "[3000]\ttraining's auc: 0.753618\tvalid_1's auc: 0.71749\n",
      "[4000]\ttraining's auc: 0.756363\tvalid_1's auc: 0.716579\n",
      "[5000]\ttraining's auc: 0.758952\tvalid_1's auc: 0.715651\n",
      "[6000]\ttraining's auc: 0.76138\tvalid_1's auc: 0.714836\n",
      "Early stopping, best iteration is:\n",
      "[3251]\ttraining's auc: 0.754277\tvalid_1's auc: 0.717792\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744609\tvalid_1's auc: 0.719996\n",
      "[2000]\ttraining's auc: 0.749666\tvalid_1's auc: 0.720711\n",
      "[3000]\ttraining's auc: 0.752933\tvalid_1's auc: 0.720733\n",
      "[4000]\ttraining's auc: 0.755554\tvalid_1's auc: 0.720477\n",
      "Early stopping, best iteration is:\n",
      "[1618]\ttraining's auc: 0.748468\tvalid_1's auc: 0.721845\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744326\tvalid_1's auc: 0.719381\n",
      "[2000]\ttraining's auc: 0.749394\tvalid_1's auc: 0.721236\n",
      "[3000]\ttraining's auc: 0.752783\tvalid_1's auc: 0.72188\n",
      "[4000]\ttraining's auc: 0.755488\tvalid_1's auc: 0.721261\n",
      "[5000]\ttraining's auc: 0.758121\tvalid_1's auc: 0.720766\n",
      "Early stopping, best iteration is:\n",
      "[2191]\ttraining's auc: 0.750008\tvalid_1's auc: 0.722064\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.745271\tvalid_1's auc: 0.714455\n",
      "[2000]\ttraining's auc: 0.75028\tvalid_1's auc: 0.716878\n",
      "[3000]\ttraining's auc: 0.75365\tvalid_1's auc: 0.717483\n",
      "[4000]\ttraining's auc: 0.756258\tvalid_1's auc: 0.716911\n",
      "[5000]\ttraining's auc: 0.758948\tvalid_1's auc: 0.716131\n",
      "Early stopping, best iteration is:\n",
      "[2513]\ttraining's auc: 0.751983\tvalid_1's auc: 0.717691\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744869\tvalid_1's auc: 0.71634\n",
      "[2000]\ttraining's auc: 0.749753\tvalid_1's auc: 0.717663\n",
      "[3000]\ttraining's auc: 0.752987\tvalid_1's auc: 0.716878\n",
      "[4000]\ttraining's auc: 0.755709\tvalid_1's auc: 0.716438\n",
      "[5000]\ttraining's auc: 0.758333\tvalid_1's auc: 0.71611\n",
      "Early stopping, best iteration is:\n",
      "[2025]\ttraining's auc: 0.749834\tvalid_1's auc: 0.71783\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744513\tvalid_1's auc: 0.721857\n",
      "[2000]\ttraining's auc: 0.750086\tvalid_1's auc: 0.723495\n",
      "[3000]\ttraining's auc: 0.753296\tvalid_1's auc: 0.722767\n",
      "[4000]\ttraining's auc: 0.755936\tvalid_1's auc: 0.721734\n",
      "[5000]\ttraining's auc: 0.758412\tvalid_1's auc: 0.720454\n",
      "Early stopping, best iteration is:\n",
      "[2360]\ttraining's auc: 0.751117\tvalid_1's auc: 0.723748\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744753\tvalid_1's auc: 0.714829\n",
      "[2000]\ttraining's auc: 0.750212\tvalid_1's auc: 0.717169\n",
      "[3000]\ttraining's auc: 0.753564\tvalid_1's auc: 0.717526\n",
      "[4000]\ttraining's auc: 0.756157\tvalid_1's auc: 0.716683\n",
      "Early stopping, best iteration is:\n",
      "[1813]\ttraining's auc: 0.749579\tvalid_1's auc: 0.717868\n",
      "Total run time 10.562069928646087 min:\n",
      "CV score: 0.71718 \n"
     ]
    }
   ],
   "source": [
    "train_results_less_1_4 = train(train_df, test_df, target, uniques_count_less_1_4.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_features_maker = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_feature_name(feature_name):\n",
    "    if '^' in feature_name:\n",
    "        return '_'.join(feature_name.split('^'))\n",
    "    elif ' ' in feature_name:\n",
    "        return '_'.join(feature_name.split())\n",
    "    else:\n",
    "        return feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised_feature_names = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(['var0', 'var1', 'var2', 'var3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\\n    #scaled_train_values,\\n    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\\n    target_values,\\n    test_size=0.2,\\n    random_state=0\\n)\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_more_1_2 = train_df[uniques_count_more_1_2.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_more_1_4_less_1_2 = train_df[uniques_count_more_1_4_less_1_2.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_less_1_4 = train_df[uniques_count_less_1_4.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in train_df_uniques_count_less_1_4.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_more_1_2 = polinomial_features_maker.fit_transform(train_df_uniques_count_more_1_2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_polinomial_values_uniques_count_more_1_2 = standard_scaler.fit_transform(polinomial_values_uniques_count_more_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_more_1_2 = [\n",
    "    normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_more_1_2.columns.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6215"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_feature_names_uniques_count_more_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_2, holdout_test_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, holdout_test_target_values_ucm_1_2 = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    scaled_polinomial_values_uniques_count_more_1_2,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_polinomial_df_ucm_1_2 = reduce_mem_usage(pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2\n",
    "))\n",
    "'''\n",
    "train_polinomial_df_ucm_1_2 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_df_ucm_1_2 = pd.DataFrame(data=train_target_values_ucm_1_2, columns=['target'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_df_ucm_1_2.values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_2 = pd.Series(train_target_values_ucm_1_2, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_target_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 6215)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polinomial_df_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_2</th>\n",
       "      <th>var_190_var_193</th>\n",
       "      <th>var_190_var_196</th>\n",
       "      <th>var_190_var_199</th>\n",
       "      <th>var_193_2</th>\n",
       "      <th>var_193_var_196</th>\n",
       "      <th>var_193_var_199</th>\n",
       "      <th>var_196_2</th>\n",
       "      <th>var_196_var_199</th>\n",
       "      <th>var_199_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.4003</td>\n",
       "      <td>-15.1480</td>\n",
       "      <td>23.001101</td>\n",
       "      <td>-12.8277</td>\n",
       "      <td>-11.9705</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>-13.7352</td>\n",
       "      <td>8.9064</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>2.9975</td>\n",
       "      <td>...</td>\n",
       "      <td>97.253128</td>\n",
       "      <td>103.938377</td>\n",
       "      <td>63.965946</td>\n",
       "      <td>-21.822956</td>\n",
       "      <td>111.083176</td>\n",
       "      <td>68.363007</td>\n",
       "      <td>-23.323080</td>\n",
       "      <td>42.072086</td>\n",
       "      <td>-14.353533</td>\n",
       "      <td>4.896926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.3055</td>\n",
       "      <td>-3.9362</td>\n",
       "      <td>20.108700</td>\n",
       "      <td>-2.1613</td>\n",
       "      <td>2.0213</td>\n",
       "      <td>12.1363</td>\n",
       "      <td>-11.3936</td>\n",
       "      <td>2.4146</td>\n",
       "      <td>12.208200</td>\n",
       "      <td>18.9734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180540</td>\n",
       "      <td>-1.965333</td>\n",
       "      <td>-0.716424</td>\n",
       "      <td>7.052490</td>\n",
       "      <td>21.394325</td>\n",
       "      <td>7.798887</td>\n",
       "      <td>-76.772385</td>\n",
       "      <td>2.842933</td>\n",
       "      <td>-27.985888</td>\n",
       "      <td>275.493591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0901</td>\n",
       "      <td>-19.5462</td>\n",
       "      <td>16.896999</td>\n",
       "      <td>-9.5860</td>\n",
       "      <td>-2.1832</td>\n",
       "      <td>8.4016</td>\n",
       "      <td>-3.2487</td>\n",
       "      <td>11.4263</td>\n",
       "      <td>13.995400</td>\n",
       "      <td>15.6798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587348</td>\n",
       "      <td>8.172215</td>\n",
       "      <td>-1.094097</td>\n",
       "      <td>13.587013</td>\n",
       "      <td>42.073387</td>\n",
       "      <td>-5.632790</td>\n",
       "      <td>69.950638</td>\n",
       "      <td>0.754119</td>\n",
       "      <td>-9.364999</td>\n",
       "      <td>116.298965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8913</td>\n",
       "      <td>-14.9898</td>\n",
       "      <td>21.246300</td>\n",
       "      <td>7.0288</td>\n",
       "      <td>2.4824</td>\n",
       "      <td>-0.0570</td>\n",
       "      <td>-5.4731</td>\n",
       "      <td>7.6422</td>\n",
       "      <td>12.221700</td>\n",
       "      <td>4.5632</td>\n",
       "      <td>...</td>\n",
       "      <td>138.525833</td>\n",
       "      <td>105.143440</td>\n",
       "      <td>-12.135738</td>\n",
       "      <td>70.626442</td>\n",
       "      <td>79.805641</td>\n",
       "      <td>-9.211229</td>\n",
       "      <td>53.606655</td>\n",
       "      <td>1.063167</td>\n",
       "      <td>-6.187322</td>\n",
       "      <td>36.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1761</td>\n",
       "      <td>-17.0776</td>\n",
       "      <td>16.811001</td>\n",
       "      <td>4.6831</td>\n",
       "      <td>-2.1157</td>\n",
       "      <td>16.5910</td>\n",
       "      <td>-8.8183</td>\n",
       "      <td>23.8480</td>\n",
       "      <td>23.709801</td>\n",
       "      <td>15.3342</td>\n",
       "      <td>...</td>\n",
       "      <td>16.612961</td>\n",
       "      <td>36.816788</td>\n",
       "      <td>20.045683</td>\n",
       "      <td>-83.176071</td>\n",
       "      <td>81.591469</td>\n",
       "      <td>44.424210</td>\n",
       "      <td>-184.330536</td>\n",
       "      <td>24.187706</td>\n",
       "      <td>-100.362679</td>\n",
       "      <td>416.437469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_1    var_5      var_7   var_10   var_11   var_13   var_17   var_18  \\\n",
       "0 -1.4003 -15.1480  23.001101 -12.8277 -11.9705   0.9585 -13.7352   8.9064   \n",
       "1 -2.3055  -3.9362  20.108700  -2.1613   2.0213  12.1363 -11.3936   2.4146   \n",
       "2  2.0901 -19.5462  16.896999  -9.5860  -2.1832   8.4016  -3.2487  11.4263   \n",
       "3  1.8913 -14.9898  21.246300   7.0288   2.4824  -0.0570  -5.4731   7.6422   \n",
       "4  2.1761 -17.0776  16.811001   4.6831  -2.1157  16.5910  -8.8183  23.8480   \n",
       "\n",
       "      var_19   var_20     ...       var_190_2  var_190_var_193  \\\n",
       "0   0.698000   2.9975     ...       97.253128       103.938377   \n",
       "1  12.208200  18.9734     ...        0.180540        -1.965333   \n",
       "2  13.995400  15.6798     ...        1.587348         8.172215   \n",
       "3  12.221700   4.5632     ...      138.525833       105.143440   \n",
       "4  23.709801  15.3342     ...       16.612961        36.816788   \n",
       "\n",
       "   var_190_var_196  var_190_var_199   var_193_2  var_193_var_196  \\\n",
       "0        63.965946       -21.822956  111.083176        68.363007   \n",
       "1        -0.716424         7.052490   21.394325         7.798887   \n",
       "2        -1.094097        13.587013   42.073387        -5.632790   \n",
       "3       -12.135738        70.626442   79.805641        -9.211229   \n",
       "4        20.045683       -83.176071   81.591469        44.424210   \n",
       "\n",
       "   var_193_var_199  var_196_2  var_196_var_199   var_199_2  \n",
       "0       -23.323080  42.072086       -14.353533    4.896926  \n",
       "1       -76.772385   2.842933       -27.985888  275.493591  \n",
       "2        69.950638   0.754119        -9.364999  116.298965  \n",
       "3        53.606655   1.063167        -6.187322   36.008400  \n",
       "4      -184.330536  24.187706      -100.362679  416.437469  \n",
       "\n",
       "[5 rows x 6215 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polinomial_df_ucm_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_ucm_1_2 = polinomial_features_maker.fit_transform(test_df[uniques_count_more_1_2.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_2 = pd.DataFrame(\n",
    "    data=test_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del polinomial_values_uniques_count_more_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838762\tvalid_1's auc: 0.802518\n",
      "[2000]\ttraining's auc: 0.864215\tvalid_1's auc: 0.811186\n",
      "[3000]\ttraining's auc: 0.882027\tvalid_1's auc: 0.812682\n",
      "[4000]\ttraining's auc: 0.898256\tvalid_1's auc: 0.812993\n",
      "[5000]\ttraining's auc: 0.913146\tvalid_1's auc: 0.812344\n",
      "[6000]\ttraining's auc: 0.926696\tvalid_1's auc: 0.812159\n",
      "Early stopping, best iteration is:\n",
      "[3874]\ttraining's auc: 0.896196\tvalid_1's auc: 0.813274\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838786\tvalid_1's auc: 0.802206\n",
      "[2000]\ttraining's auc: 0.863654\tvalid_1's auc: 0.812419\n",
      "[3000]\ttraining's auc: 0.881227\tvalid_1's auc: 0.815243\n",
      "[4000]\ttraining's auc: 0.897331\tvalid_1's auc: 0.816398\n",
      "[5000]\ttraining's auc: 0.912293\tvalid_1's auc: 0.816428\n",
      "[6000]\ttraining's auc: 0.925757\tvalid_1's auc: 0.816328\n",
      "[7000]\ttraining's auc: 0.938058\tvalid_1's auc: 0.81598\n",
      "Early stopping, best iteration is:\n",
      "[4563]\ttraining's auc: 0.905992\tvalid_1's auc: 0.816707\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838071\tvalid_1's auc: 0.809383\n",
      "[2000]\ttraining's auc: 0.86336\tvalid_1's auc: 0.818606\n",
      "[3000]\ttraining's auc: 0.881368\tvalid_1's auc: 0.819967\n",
      "[4000]\ttraining's auc: 0.897395\tvalid_1's auc: 0.820065\n",
      "[5000]\ttraining's auc: 0.912531\tvalid_1's auc: 0.81987\n",
      "[6000]\ttraining's auc: 0.926124\tvalid_1's auc: 0.819698\n",
      "[7000]\ttraining's auc: 0.938423\tvalid_1's auc: 0.819576\n",
      "Early stopping, best iteration is:\n",
      "[4016]\ttraining's auc: 0.897645\tvalid_1's auc: 0.820173\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83821\tvalid_1's auc: 0.809438\n",
      "[2000]\ttraining's auc: 0.86321\tvalid_1's auc: 0.819368\n",
      "[3000]\ttraining's auc: 0.881006\tvalid_1's auc: 0.821936\n",
      "[4000]\ttraining's auc: 0.897131\tvalid_1's auc: 0.822499\n",
      "[5000]\ttraining's auc: 0.911879\tvalid_1's auc: 0.82282\n",
      "[6000]\ttraining's auc: 0.92562\tvalid_1's auc: 0.823172\n",
      "[7000]\ttraining's auc: 0.937801\tvalid_1's auc: 0.822963\n",
      "[8000]\ttraining's auc: 0.948581\tvalid_1's auc: 0.822633\n",
      "[9000]\ttraining's auc: 0.957718\tvalid_1's auc: 0.821821\n",
      "Early stopping, best iteration is:\n",
      "[6007]\ttraining's auc: 0.925733\tvalid_1's auc: 0.823204\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.839185\tvalid_1's auc: 0.805585\n",
      "[2000]\ttraining's auc: 0.863926\tvalid_1's auc: 0.815801\n",
      "[3000]\ttraining's auc: 0.881486\tvalid_1's auc: 0.817704\n",
      "[4000]\ttraining's auc: 0.897704\tvalid_1's auc: 0.817464\n",
      "[5000]\ttraining's auc: 0.912498\tvalid_1's auc: 0.81786\n",
      "[6000]\ttraining's auc: 0.926144\tvalid_1's auc: 0.817553\n",
      "[7000]\ttraining's auc: 0.938247\tvalid_1's auc: 0.817042\n",
      "Early stopping, best iteration is:\n",
      "[4727]\ttraining's auc: 0.908605\tvalid_1's auc: 0.817979\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83942\tvalid_1's auc: 0.797128\n",
      "[2000]\ttraining's auc: 0.864591\tvalid_1's auc: 0.806734\n",
      "[3000]\ttraining's auc: 0.882115\tvalid_1's auc: 0.809022\n",
      "[4000]\ttraining's auc: 0.898067\tvalid_1's auc: 0.809662\n",
      "[5000]\ttraining's auc: 0.912624\tvalid_1's auc: 0.80983\n",
      "[6000]\ttraining's auc: 0.92629\tvalid_1's auc: 0.809578\n",
      "[7000]\ttraining's auc: 0.938296\tvalid_1's auc: 0.809112\n",
      "[8000]\ttraining's auc: 0.94887\tvalid_1's auc: 0.809175\n",
      "Early stopping, best iteration is:\n",
      "[5433]\ttraining's auc: 0.918789\tvalid_1's auc: 0.809953\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838826\tvalid_1's auc: 0.798452\n",
      "[2000]\ttraining's auc: 0.864251\tvalid_1's auc: 0.809565\n",
      "[3000]\ttraining's auc: 0.881883\tvalid_1's auc: 0.811075\n",
      "[4000]\ttraining's auc: 0.898102\tvalid_1's auc: 0.811875\n",
      "[5000]\ttraining's auc: 0.912852\tvalid_1's auc: 0.812476\n",
      "[6000]\ttraining's auc: 0.926231\tvalid_1's auc: 0.81229\n",
      "[7000]\ttraining's auc: 0.938218\tvalid_1's auc: 0.812081\n",
      "[8000]\ttraining's auc: 0.948838\tvalid_1's auc: 0.811973\n",
      "Early stopping, best iteration is:\n",
      "[5241]\ttraining's auc: 0.916196\tvalid_1's auc: 0.812793\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838208\tvalid_1's auc: 0.80803\n",
      "[2000]\ttraining's auc: 0.863463\tvalid_1's auc: 0.817872\n",
      "[3000]\ttraining's auc: 0.88124\tvalid_1's auc: 0.819231\n",
      "[4000]\ttraining's auc: 0.897286\tvalid_1's auc: 0.819254\n",
      "[5000]\ttraining's auc: 0.912181\tvalid_1's auc: 0.819314\n",
      "[6000]\ttraining's auc: 0.925699\tvalid_1's auc: 0.818978\n",
      "[7000]\ttraining's auc: 0.937965\tvalid_1's auc: 0.818554\n",
      "Early stopping, best iteration is:\n",
      "[4392]\ttraining's auc: 0.903324\tvalid_1's auc: 0.819676\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838555\tvalid_1's auc: 0.812231\n",
      "[2000]\ttraining's auc: 0.863825\tvalid_1's auc: 0.820539\n",
      "[3000]\ttraining's auc: 0.881444\tvalid_1's auc: 0.821546\n",
      "[4000]\ttraining's auc: 0.897503\tvalid_1's auc: 0.821649\n",
      "[5000]\ttraining's auc: 0.91227\tvalid_1's auc: 0.821277\n",
      "[6000]\ttraining's auc: 0.92582\tvalid_1's auc: 0.820819\n",
      "Early stopping, best iteration is:\n",
      "[3757]\ttraining's auc: 0.89367\tvalid_1's auc: 0.821993\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838625\tvalid_1's auc: 0.805455\n",
      "[2000]\ttraining's auc: 0.864076\tvalid_1's auc: 0.814822\n",
      "[3000]\ttraining's auc: 0.881819\tvalid_1's auc: 0.816536\n",
      "[4000]\ttraining's auc: 0.897938\tvalid_1's auc: 0.816276\n",
      "[5000]\ttraining's auc: 0.912877\tvalid_1's auc: 0.815507\n",
      "[6000]\ttraining's auc: 0.926537\tvalid_1's auc: 0.8154\n",
      "Early stopping, best iteration is:\n",
      "[3254]\ttraining's auc: 0.885929\tvalid_1's auc: 0.816673\n",
      "Total run time 84.49654633204142 min:\n",
      "CV score: 0.81718 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_2 = train(\n",
    "    train_polinomial_df_ucm_1_2,\n",
    "    test_polinomial_df_ucm_1_2,\n",
    "    train_target_series_ucm_1_2,\n",
    "    train_polinomial_df_ucm_1_2.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof, predictions, feature_importance_df, clf = train_results_polinomial_ucm_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(predictions)\n",
    "predictions_df = pd.DataFrame(data=predictions, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_2.to_csv('train_polinomial_data_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_2.to_csv('test_polinomial_data_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_2.to_csv('train_target_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_2\n",
    "del test_polinomial_df_ucm_1_2\n",
    "del train_target_series_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('lgbm_ucf_1_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_more_1_4_less_1_2 = polinomial_features_maker.fit_transform(train_df_uniques_count_more_1_4_less_1_2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_values_uniques_count_more_1_4_less_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_more_1_4_less_1_2 = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_more_1_4_less_1_2.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_4_1_2, holdout_test_polinomial_values_ucm_1_4_1_2, train_target_values_ucm_1_4_1_2, holdout_test_target_values_ucm_1_4_1_2 = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    polinomial_values_uniques_count_more_1_4_less_1_2,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4_1_2 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_4_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_4_less_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4_1_2 = pd.Series(train_target_values_ucm_1_4_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_values_ucm_1_4_1_2 = polinomial_features_maker.fit_transform(test_df[uniques_count_more_1_4_less_1_2.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4_1_2 = pd.DataFrame(\n",
    "    data=test_polinomial_values_ucm_1_4_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_4_less_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del polinomial_values_uniques_count_more_1_4_less_1_2\n",
    "del train_polinomial_values_ucm_1_4_1_2\n",
    "del test_polinomial_values_ucm_1_4_1_2\n",
    "del train_target_values_ucm_1_4_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83246\tvalid_1's auc: 0.801038\n",
      "[2000]\ttraining's auc: 0.854414\tvalid_1's auc: 0.805477\n",
      "[3000]\ttraining's auc: 0.871523\tvalid_1's auc: 0.806123\n",
      "[4000]\ttraining's auc: 0.887375\tvalid_1's auc: 0.805903\n",
      "[5000]\ttraining's auc: 0.902057\tvalid_1's auc: 0.806144\n",
      "Early stopping, best iteration is:\n",
      "[2842]\ttraining's auc: 0.868851\tvalid_1's auc: 0.80622\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831354\tvalid_1's auc: 0.807533\n",
      "[2000]\ttraining's auc: 0.853586\tvalid_1's auc: 0.814413\n",
      "[3000]\ttraining's auc: 0.871036\tvalid_1's auc: 0.815046\n",
      "[4000]\ttraining's auc: 0.887196\tvalid_1's auc: 0.814766\n",
      "[5000]\ttraining's auc: 0.90206\tvalid_1's auc: 0.814434\n",
      "[6000]\ttraining's auc: 0.915315\tvalid_1's auc: 0.814192\n",
      "Early stopping, best iteration is:\n",
      "[3584]\ttraining's auc: 0.880639\tvalid_1's auc: 0.815199\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832987\tvalid_1's auc: 0.787713\n",
      "[2000]\ttraining's auc: 0.854887\tvalid_1's auc: 0.796167\n",
      "[3000]\ttraining's auc: 0.871821\tvalid_1's auc: 0.798036\n",
      "[4000]\ttraining's auc: 0.887704\tvalid_1's auc: 0.797854\n",
      "[5000]\ttraining's auc: 0.902365\tvalid_1's auc: 0.797431\n",
      "[6000]\ttraining's auc: 0.915516\tvalid_1's auc: 0.796584\n",
      "Early stopping, best iteration is:\n",
      "[3588]\ttraining's auc: 0.88123\tvalid_1's auc: 0.798177\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83157\tvalid_1's auc: 0.804276\n",
      "[2000]\ttraining's auc: 0.853535\tvalid_1's auc: 0.812183\n",
      "[3000]\ttraining's auc: 0.870667\tvalid_1's auc: 0.813517\n",
      "[4000]\ttraining's auc: 0.886516\tvalid_1's auc: 0.81351\n",
      "[5000]\ttraining's auc: 0.901362\tvalid_1's auc: 0.813701\n",
      "[6000]\ttraining's auc: 0.914925\tvalid_1's auc: 0.812733\n",
      "[7000]\ttraining's auc: 0.92705\tvalid_1's auc: 0.81272\n",
      "Early stopping, best iteration is:\n",
      "[4670]\ttraining's auc: 0.896781\tvalid_1's auc: 0.813876\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832125\tvalid_1's auc: 0.799563\n",
      "[2000]\ttraining's auc: 0.853766\tvalid_1's auc: 0.806429\n",
      "[3000]\ttraining's auc: 0.870873\tvalid_1's auc: 0.807988\n",
      "[4000]\ttraining's auc: 0.886879\tvalid_1's auc: 0.808158\n",
      "[5000]\ttraining's auc: 0.90159\tvalid_1's auc: 0.807828\n",
      "[6000]\ttraining's auc: 0.915042\tvalid_1's auc: 0.80758\n",
      "Early stopping, best iteration is:\n",
      "[3935]\ttraining's auc: 0.88583\tvalid_1's auc: 0.808242\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831351\tvalid_1's auc: 0.811016\n",
      "[2000]\ttraining's auc: 0.853406\tvalid_1's auc: 0.818441\n",
      "[3000]\ttraining's auc: 0.870881\tvalid_1's auc: 0.819958\n",
      "[4000]\ttraining's auc: 0.886907\tvalid_1's auc: 0.820278\n",
      "[5000]\ttraining's auc: 0.901431\tvalid_1's auc: 0.819977\n",
      "[6000]\ttraining's auc: 0.915073\tvalid_1's auc: 0.819888\n",
      "[7000]\ttraining's auc: 0.927059\tvalid_1's auc: 0.819745\n",
      "Early stopping, best iteration is:\n",
      "[4146]\ttraining's auc: 0.889148\tvalid_1's auc: 0.820399\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832273\tvalid_1's auc: 0.798405\n",
      "[2000]\ttraining's auc: 0.8543\tvalid_1's auc: 0.806109\n",
      "[3000]\ttraining's auc: 0.871403\tvalid_1's auc: 0.80715\n",
      "[4000]\ttraining's auc: 0.887216\tvalid_1's auc: 0.807956\n",
      "[5000]\ttraining's auc: 0.901963\tvalid_1's auc: 0.807674\n",
      "[6000]\ttraining's auc: 0.915062\tvalid_1's auc: 0.807656\n",
      "[7000]\ttraining's auc: 0.927253\tvalid_1's auc: 0.807556\n",
      "[8000]\ttraining's auc: 0.938083\tvalid_1's auc: 0.806961\n",
      "[9000]\ttraining's auc: 0.947545\tvalid_1's auc: 0.806782\n",
      "Early stopping, best iteration is:\n",
      "[6221]\ttraining's auc: 0.918006\tvalid_1's auc: 0.807967\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832335\tvalid_1's auc: 0.79963\n",
      "[2000]\ttraining's auc: 0.854273\tvalid_1's auc: 0.80552\n",
      "[3000]\ttraining's auc: 0.871351\tvalid_1's auc: 0.806012\n",
      "[4000]\ttraining's auc: 0.887247\tvalid_1's auc: 0.805516\n",
      "[5000]\ttraining's auc: 0.901805\tvalid_1's auc: 0.805131\n",
      "Early stopping, best iteration is:\n",
      "[2897]\ttraining's auc: 0.869676\tvalid_1's auc: 0.806269\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831371\tvalid_1's auc: 0.807862\n",
      "[2000]\ttraining's auc: 0.85343\tvalid_1's auc: 0.812993\n",
      "[3000]\ttraining's auc: 0.870821\tvalid_1's auc: 0.813938\n",
      "[4000]\ttraining's auc: 0.886624\tvalid_1's auc: 0.81392\n",
      "[5000]\ttraining's auc: 0.901593\tvalid_1's auc: 0.813434\n",
      "[6000]\ttraining's auc: 0.91483\tvalid_1's auc: 0.813018\n",
      "Early stopping, best iteration is:\n",
      "[3335]\ttraining's auc: 0.876231\tvalid_1's auc: 0.814166\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831903\tvalid_1's auc: 0.801807\n",
      "[2000]\ttraining's auc: 0.853965\tvalid_1's auc: 0.80871\n",
      "[3000]\ttraining's auc: 0.871177\tvalid_1's auc: 0.809762\n",
      "[4000]\ttraining's auc: 0.887158\tvalid_1's auc: 0.809797\n",
      "[5000]\ttraining's auc: 0.901809\tvalid_1's auc: 0.809146\n",
      "[6000]\ttraining's auc: 0.915162\tvalid_1's auc: 0.809073\n",
      "Early stopping, best iteration is:\n",
      "[3338]\ttraining's auc: 0.876738\tvalid_1's auc: 0.810069\n",
      "Total run time 56.124856078624724 min:\n",
      "CV score: 0.80998 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_4_1_2 = train(\n",
    "    train_polinomial_df_ucm_1_4_1_2,\n",
    "    test_polinomial_df_ucm_1_4_1_2,\n",
    "    train_target_series_ucm_1_4_1_2,\n",
    "    train_polinomial_df_ucm_1_4_1_2.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_1_4_1_2, predictions_ucm_1_4_1_2, feature_importance_df_ucm_1_4_1_2, clf_ucm_1_4_1_2 = train_results_polinomial_ucm_1_4_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(oof_ucm_1_4_1_2)\n",
    "predictions_df_ucm_1_4_1_2 = pd.DataFrame(data=predictions_ucm_1_4_1_2, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4_1_2.to_csv('predictions_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4_1_2.to_csv('train_polinomial_data_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4_1_2.to_csv('test_polinomial_data_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4_1_2.to_csv('train_target_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_4_1_2\n",
    "del test_polinomial_df_ucm_1_4_1_2\n",
    "del train_target_series_ucm_1_4_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ucm_1_4_1_2.save_model('lgbm_ucm_1_4_1_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_less_1_4 = polinomial_features_maker.fit_transform(train_df_uniques_count_less_1_4).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 819)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_values_uniques_count_less_1_4)\n",
    "polinomial_values_uniques_count_less_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_less_1_4 = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_less_1_4.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_4, holdout_test_polinomial_values_ucm_1_4, train_target_values_ucm_1_4, holdout_test_target_values_ucm_1_4 = train_test_split(\n",
    "    polinomial_values_uniques_count_less_1_4,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_4,\n",
    "    columns=polinomial_feature_names_uniques_count_less_1_4,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4 = pd.Series(train_target_values_ucm_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_values_ucm_1_4 = polinomial_features_maker.fit_transform(test_df[uniques_count_less_1_4.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4 = pd.DataFrame(\n",
    "    data=test_values_ucm_1_4,\n",
    "    columns=polinomial_feature_names_uniques_count_less_1_4,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del polinomial_values_uniques_count_less_1_4\n",
    "#del train_polinomial_values_ucm_1_4\n",
    "del test_polinomial_values_ucm_1_4\n",
    "del train_target_values_ucm_1_4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.750146\tvalid_1's auc: 0.706936\n",
      "[2000]\ttraining's auc: 0.773966\tvalid_1's auc: 0.707595\n",
      "[3000]\ttraining's auc: 0.796843\tvalid_1's auc: 0.706173\n",
      "[4000]\ttraining's auc: 0.817903\tvalid_1's auc: 0.705203\n",
      "Early stopping, best iteration is:\n",
      "[1548]\ttraining's auc: 0.763514\tvalid_1's auc: 0.70773\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748817\tvalid_1's auc: 0.719931\n",
      "[2000]\ttraining's auc: 0.773467\tvalid_1's auc: 0.720096\n",
      "[3000]\ttraining's auc: 0.7964\tvalid_1's auc: 0.718983\n",
      "[4000]\ttraining's auc: 0.816975\tvalid_1's auc: 0.718124\n",
      "Early stopping, best iteration is:\n",
      "[1220]\ttraining's auc: 0.754455\tvalid_1's auc: 0.721226\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749849\tvalid_1's auc: 0.706014\n",
      "[2000]\ttraining's auc: 0.773877\tvalid_1's auc: 0.708997\n",
      "[3000]\ttraining's auc: 0.796516\tvalid_1's auc: 0.70895\n",
      "[4000]\ttraining's auc: 0.81705\tvalid_1's auc: 0.708867\n",
      "[5000]\ttraining's auc: 0.836355\tvalid_1's auc: 0.708074\n",
      "[6000]\ttraining's auc: 0.853892\tvalid_1's auc: 0.706934\n",
      "Early stopping, best iteration is:\n",
      "[3242]\ttraining's auc: 0.801658\tvalid_1's auc: 0.709186\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748514\tvalid_1's auc: 0.719323\n",
      "[2000]\ttraining's auc: 0.773032\tvalid_1's auc: 0.720864\n",
      "[3000]\ttraining's auc: 0.796123\tvalid_1's auc: 0.720432\n",
      "[4000]\ttraining's auc: 0.816791\tvalid_1's auc: 0.71999\n",
      "Early stopping, best iteration is:\n",
      "[1815]\ttraining's auc: 0.768745\tvalid_1's auc: 0.721344\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.747734\tvalid_1's auc: 0.730777\n",
      "[2000]\ttraining's auc: 0.772388\tvalid_1's auc: 0.731844\n",
      "[3000]\ttraining's auc: 0.795545\tvalid_1's auc: 0.731315\n",
      "[4000]\ttraining's auc: 0.816848\tvalid_1's auc: 0.730588\n",
      "Early stopping, best iteration is:\n",
      "[1730]\ttraining's auc: 0.765903\tvalid_1's auc: 0.732473\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748986\tvalid_1's auc: 0.719056\n",
      "[2000]\ttraining's auc: 0.773019\tvalid_1's auc: 0.721977\n",
      "[3000]\ttraining's auc: 0.796138\tvalid_1's auc: 0.721909\n",
      "[4000]\ttraining's auc: 0.817114\tvalid_1's auc: 0.721614\n",
      "[5000]\ttraining's auc: 0.83643\tvalid_1's auc: 0.720305\n",
      "Early stopping, best iteration is:\n",
      "[2402]\ttraining's auc: 0.782434\tvalid_1's auc: 0.7223\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748927\tvalid_1's auc: 0.725424\n",
      "[2000]\ttraining's auc: 0.772999\tvalid_1's auc: 0.72615\n",
      "[3000]\ttraining's auc: 0.795584\tvalid_1's auc: 0.725309\n",
      "[4000]\ttraining's auc: 0.816672\tvalid_1's auc: 0.724426\n",
      "Early stopping, best iteration is:\n",
      "[1397]\ttraining's auc: 0.758519\tvalid_1's auc: 0.726685\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749575\tvalid_1's auc: 0.712295\n",
      "[2000]\ttraining's auc: 0.773407\tvalid_1's auc: 0.713449\n",
      "[3000]\ttraining's auc: 0.796533\tvalid_1's auc: 0.713512\n",
      "[4000]\ttraining's auc: 0.817448\tvalid_1's auc: 0.713536\n",
      "[5000]\ttraining's auc: 0.836752\tvalid_1's auc: 0.712608\n",
      "[6000]\ttraining's auc: 0.85448\tvalid_1's auc: 0.711863\n",
      "[7000]\ttraining's auc: 0.870511\tvalid_1's auc: 0.711157\n",
      "Early stopping, best iteration is:\n",
      "[4060]\ttraining's auc: 0.818768\tvalid_1's auc: 0.713807\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748423\tvalid_1's auc: 0.728226\n",
      "[2000]\ttraining's auc: 0.772738\tvalid_1's auc: 0.728536\n",
      "[3000]\ttraining's auc: 0.795657\tvalid_1's auc: 0.727199\n",
      "[4000]\ttraining's auc: 0.816851\tvalid_1's auc: 0.726828\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's auc: 0.757013\tvalid_1's auc: 0.729147\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749738\tvalid_1's auc: 0.715395\n",
      "[2000]\ttraining's auc: 0.77371\tvalid_1's auc: 0.716612\n",
      "[3000]\ttraining's auc: 0.796409\tvalid_1's auc: 0.71626\n",
      "[4000]\ttraining's auc: 0.817618\tvalid_1's auc: 0.715617\n",
      "[5000]\ttraining's auc: 0.836863\tvalid_1's auc: 0.715057\n",
      "Early stopping, best iteration is:\n",
      "[2348]\ttraining's auc: 0.781765\tvalid_1's auc: 0.716939\n",
      "Total run time 15.038687678178151 min:\n",
      "CV score: 0.71978 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_4 = train(\n",
    "    train_polinomial_df_ucm_1_4,\n",
    "    test_polinomial_df_ucm_1_4,\n",
    "    train_target_series_ucm_1_4,\n",
    "    train_polinomial_df_ucm_1_4.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_1_4, predictions_ucm_1_4, feature_importance_df_ucm_1_4, clf_ucm_1_4 = train_results_polinomial_ucm_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4 = pd.DataFrame(data=predictions_ucm_1_4, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4.to_csv('predictions_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4.to_csv('train_polinomial_data_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4.to_csv('test_polinomial_data_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4.to_csv('train_target_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_4\n",
    "del test_polinomial_df_ucm_1_4\n",
    "del train_target_series_ucm_1_4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ucm_1_4.save_model('lgbm_ucm_1_4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions_df.head())\n",
    "#print(predictions_df.shape)\n",
    "#print(predictions_df_ucm_1_4_1_2.head())\n",
    "#print(predictions_df_ucm_1_4_1_2.shape)\n",
    "#print(predictions_df_ucm_1_4.head())\n",
    "#print(predictions_df_ucm_1_4.shape)\n",
    "#predictions_df.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simply_blend(prediction_dataframes, weights, target_column_name='target'):\n",
    "    blended_prediction_df = pd.DataFrame(data=np.zeros(prediction_dataframes[0].shape[0]), columns=[target_column_name])\n",
    "    for prediction_df, weight in zip(prediction_dataframes, weights):\n",
    "        blended_prediction_df[target_column_name] = blended_prediction_df[target_column_name] + weight * prediction_df[target_column_name]\n",
    "        #blended_prediction_df.add(weight * prediction_df)\n",
    "    return blended_prediction_df / sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_polinomial_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4],\n",
    "    [1, 1, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_polinomial_prediction.head()\n",
    "blended_polinomial_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_code = test_df['ID_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_polinomial_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('simply_blended_polinom_lgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_more_1_2, predictions_more_1_2, feature_importance_df_more_1_2, clf_more_1_2 = train_results_more_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_more_1_2 = pd.DataFrame(data=predictions_more_1_2, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_4_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2],\n",
    "    [1, 1, 1, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_4_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_4_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_4_df.to_csv('blended_4_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.89904\tvalid_1's auc: 0.880364\n",
      "[2000]\ttraining's auc: 0.911204\tvalid_1's auc: 0.888868\n",
      "[3000]\ttraining's auc: 0.91903\tvalid_1's auc: 0.893151\n",
      "[4000]\ttraining's auc: 0.924854\tvalid_1's auc: 0.896012\n",
      "[5000]\ttraining's auc: 0.929701\tvalid_1's auc: 0.897714\n",
      "[6000]\ttraining's auc: 0.933934\tvalid_1's auc: 0.898494\n",
      "[7000]\ttraining's auc: 0.93786\tvalid_1's auc: 0.898994\n",
      "[8000]\ttraining's auc: 0.941613\tvalid_1's auc: 0.89928\n",
      "[9000]\ttraining's auc: 0.945152\tvalid_1's auc: 0.899671\n",
      "[10000]\ttraining's auc: 0.948466\tvalid_1's auc: 0.899878\n",
      "[11000]\ttraining's auc: 0.951758\tvalid_1's auc: 0.900177\n",
      "[12000]\ttraining's auc: 0.954863\tvalid_1's auc: 0.899992\n",
      "[13000]\ttraining's auc: 0.957793\tvalid_1's auc: 0.899881\n",
      "[14000]\ttraining's auc: 0.96065\tvalid_1's auc: 0.899628\n",
      "Early stopping, best iteration is:\n",
      "[11045]\ttraining's auc: 0.951908\tvalid_1's auc: 0.900223\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898872\tvalid_1's auc: 0.881324\n",
      "[2000]\ttraining's auc: 0.911092\tvalid_1's auc: 0.890141\n",
      "[3000]\ttraining's auc: 0.918887\tvalid_1's auc: 0.894037\n",
      "[4000]\ttraining's auc: 0.924725\tvalid_1's auc: 0.896563\n",
      "[5000]\ttraining's auc: 0.929615\tvalid_1's auc: 0.898167\n",
      "[6000]\ttraining's auc: 0.933852\tvalid_1's auc: 0.898875\n",
      "[7000]\ttraining's auc: 0.937735\tvalid_1's auc: 0.89924\n",
      "[8000]\ttraining's auc: 0.941427\tvalid_1's auc: 0.899545\n",
      "[9000]\ttraining's auc: 0.945019\tvalid_1's auc: 0.899597\n",
      "[10000]\ttraining's auc: 0.948402\tvalid_1's auc: 0.899566\n",
      "[11000]\ttraining's auc: 0.951631\tvalid_1's auc: 0.899664\n",
      "[12000]\ttraining's auc: 0.954666\tvalid_1's auc: 0.899486\n",
      "[13000]\ttraining's auc: 0.957626\tvalid_1's auc: 0.89939\n",
      "Early stopping, best iteration is:\n",
      "[10577]\ttraining's auc: 0.950291\tvalid_1's auc: 0.899729\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.899456\tvalid_1's auc: 0.875464\n",
      "[2000]\ttraining's auc: 0.911636\tvalid_1's auc: 0.88445\n",
      "[3000]\ttraining's auc: 0.919401\tvalid_1's auc: 0.889283\n",
      "[4000]\ttraining's auc: 0.925163\tvalid_1's auc: 0.891698\n",
      "[5000]\ttraining's auc: 0.930008\tvalid_1's auc: 0.893217\n",
      "[6000]\ttraining's auc: 0.934161\tvalid_1's auc: 0.894368\n",
      "[7000]\ttraining's auc: 0.938011\tvalid_1's auc: 0.894915\n",
      "[8000]\ttraining's auc: 0.941698\tvalid_1's auc: 0.895107\n",
      "[9000]\ttraining's auc: 0.945271\tvalid_1's auc: 0.89496\n",
      "[10000]\ttraining's auc: 0.948626\tvalid_1's auc: 0.894985\n",
      "Early stopping, best iteration is:\n",
      "[7863]\ttraining's auc: 0.941219\tvalid_1's auc: 0.895159\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898755\tvalid_1's auc: 0.880937\n",
      "[2000]\ttraining's auc: 0.910972\tvalid_1's auc: 0.890718\n",
      "[3000]\ttraining's auc: 0.918966\tvalid_1's auc: 0.894582\n",
      "[4000]\ttraining's auc: 0.924802\tvalid_1's auc: 0.896677\n",
      "[5000]\ttraining's auc: 0.929742\tvalid_1's auc: 0.897598\n",
      "[6000]\ttraining's auc: 0.933987\tvalid_1's auc: 0.898084\n",
      "[7000]\ttraining's auc: 0.937911\tvalid_1's auc: 0.898305\n",
      "[8000]\ttraining's auc: 0.941628\tvalid_1's auc: 0.898558\n",
      "[9000]\ttraining's auc: 0.945165\tvalid_1's auc: 0.898465\n",
      "[10000]\ttraining's auc: 0.948493\tvalid_1's auc: 0.898567\n",
      "[11000]\ttraining's auc: 0.951717\tvalid_1's auc: 0.898491\n",
      "[12000]\ttraining's auc: 0.954791\tvalid_1's auc: 0.898268\n",
      "Early stopping, best iteration is:\n",
      "[9716]\ttraining's auc: 0.947579\tvalid_1's auc: 0.898615\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898756\tvalid_1's auc: 0.880866\n",
      "[2000]\ttraining's auc: 0.910845\tvalid_1's auc: 0.890799\n",
      "[3000]\ttraining's auc: 0.918796\tvalid_1's auc: 0.895208\n",
      "[4000]\ttraining's auc: 0.924658\tvalid_1's auc: 0.897531\n",
      "[5000]\ttraining's auc: 0.929576\tvalid_1's auc: 0.898924\n",
      "[6000]\ttraining's auc: 0.933837\tvalid_1's auc: 0.899703\n",
      "[7000]\ttraining's auc: 0.937772\tvalid_1's auc: 0.900308\n",
      "[8000]\ttraining's auc: 0.941416\tvalid_1's auc: 0.900431\n",
      "[9000]\ttraining's auc: 0.944971\tvalid_1's auc: 0.900233\n",
      "[10000]\ttraining's auc: 0.948268\tvalid_1's auc: 0.900028\n",
      "[11000]\ttraining's auc: 0.951548\tvalid_1's auc: 0.900111\n",
      "Early stopping, best iteration is:\n",
      "[8031]\ttraining's auc: 0.941528\tvalid_1's auc: 0.900462\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898106\tvalid_1's auc: 0.886226\n",
      "[2000]\ttraining's auc: 0.910525\tvalid_1's auc: 0.894652\n",
      "[3000]\ttraining's auc: 0.918514\tvalid_1's auc: 0.898661\n",
      "[4000]\ttraining's auc: 0.924481\tvalid_1's auc: 0.900751\n",
      "[5000]\ttraining's auc: 0.929454\tvalid_1's auc: 0.902105\n",
      "[6000]\ttraining's auc: 0.933804\tvalid_1's auc: 0.902821\n",
      "[7000]\ttraining's auc: 0.937765\tvalid_1's auc: 0.902995\n",
      "[8000]\ttraining's auc: 0.941446\tvalid_1's auc: 0.903154\n",
      "[9000]\ttraining's auc: 0.944993\tvalid_1's auc: 0.903363\n",
      "[10000]\ttraining's auc: 0.948314\tvalid_1's auc: 0.9034\n",
      "[11000]\ttraining's auc: 0.951562\tvalid_1's auc: 0.903391\n",
      "[12000]\ttraining's auc: 0.954655\tvalid_1's auc: 0.903289\n",
      "[13000]\ttraining's auc: 0.957648\tvalid_1's auc: 0.903262\n",
      "Early stopping, best iteration is:\n",
      "[10229]\ttraining's auc: 0.949078\tvalid_1's auc: 0.903449\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898631\tvalid_1's auc: 0.883448\n",
      "[2000]\ttraining's auc: 0.91088\tvalid_1's auc: 0.892046\n",
      "[3000]\ttraining's auc: 0.918802\tvalid_1's auc: 0.896592\n",
      "[4000]\ttraining's auc: 0.924723\tvalid_1's auc: 0.898649\n",
      "[5000]\ttraining's auc: 0.929617\tvalid_1's auc: 0.899721\n",
      "[6000]\ttraining's auc: 0.933906\tvalid_1's auc: 0.900308\n",
      "[7000]\ttraining's auc: 0.937832\tvalid_1's auc: 0.900717\n",
      "[8000]\ttraining's auc: 0.941555\tvalid_1's auc: 0.900916\n",
      "[9000]\ttraining's auc: 0.94506\tvalid_1's auc: 0.900607\n",
      "[10000]\ttraining's auc: 0.948425\tvalid_1's auc: 0.900518\n",
      "Early stopping, best iteration is:\n",
      "[7475]\ttraining's auc: 0.939642\tvalid_1's auc: 0.900965\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898676\tvalid_1's auc: 0.880199\n",
      "[2000]\ttraining's auc: 0.911049\tvalid_1's auc: 0.889752\n",
      "[3000]\ttraining's auc: 0.918968\tvalid_1's auc: 0.894568\n",
      "[4000]\ttraining's auc: 0.924842\tvalid_1's auc: 0.897449\n",
      "[5000]\ttraining's auc: 0.929663\tvalid_1's auc: 0.89896\n",
      "[6000]\ttraining's auc: 0.933875\tvalid_1's auc: 0.899934\n",
      "[7000]\ttraining's auc: 0.937866\tvalid_1's auc: 0.90027\n",
      "[8000]\ttraining's auc: 0.941586\tvalid_1's auc: 0.900556\n",
      "[9000]\ttraining's auc: 0.945083\tvalid_1's auc: 0.900757\n",
      "[10000]\ttraining's auc: 0.948416\tvalid_1's auc: 0.900799\n",
      "[11000]\ttraining's auc: 0.951675\tvalid_1's auc: 0.900676\n",
      "[12000]\ttraining's auc: 0.954768\tvalid_1's auc: 0.900403\n",
      "[13000]\ttraining's auc: 0.95775\tvalid_1's auc: 0.900246\n",
      "Early stopping, best iteration is:\n",
      "[10038]\ttraining's auc: 0.948551\tvalid_1's auc: 0.900819\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.89779\tvalid_1's auc: 0.888166\n",
      "[2000]\ttraining's auc: 0.910458\tvalid_1's auc: 0.896618\n",
      "[3000]\ttraining's auc: 0.918615\tvalid_1's auc: 0.900943\n",
      "[4000]\ttraining's auc: 0.924387\tvalid_1's auc: 0.903001\n",
      "[5000]\ttraining's auc: 0.9293\tvalid_1's auc: 0.904178\n",
      "[6000]\ttraining's auc: 0.933534\tvalid_1's auc: 0.904738\n",
      "[7000]\ttraining's auc: 0.937463\tvalid_1's auc: 0.905103\n",
      "[8000]\ttraining's auc: 0.94117\tvalid_1's auc: 0.905392\n",
      "[9000]\ttraining's auc: 0.944675\tvalid_1's auc: 0.905481\n",
      "[10000]\ttraining's auc: 0.948106\tvalid_1's auc: 0.905589\n",
      "[11000]\ttraining's auc: 0.951319\tvalid_1's auc: 0.90545\n",
      "[12000]\ttraining's auc: 0.954441\tvalid_1's auc: 0.905497\n",
      "[13000]\ttraining's auc: 0.957453\tvalid_1's auc: 0.905272\n",
      "Early stopping, best iteration is:\n",
      "[10232]\ttraining's auc: 0.948883\tvalid_1's auc: 0.905628\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898783\tvalid_1's auc: 0.883983\n",
      "[2000]\ttraining's auc: 0.911112\tvalid_1's auc: 0.891819\n",
      "[3000]\ttraining's auc: 0.919056\tvalid_1's auc: 0.896176\n",
      "[4000]\ttraining's auc: 0.924853\tvalid_1's auc: 0.89825\n",
      "[5000]\ttraining's auc: 0.929797\tvalid_1's auc: 0.899577\n",
      "[6000]\ttraining's auc: 0.934085\tvalid_1's auc: 0.900182\n",
      "[7000]\ttraining's auc: 0.937978\tvalid_1's auc: 0.900687\n",
      "[8000]\ttraining's auc: 0.941648\tvalid_1's auc: 0.900745\n",
      "[9000]\ttraining's auc: 0.945235\tvalid_1's auc: 0.900773\n",
      "[10000]\ttraining's auc: 0.94862\tvalid_1's auc: 0.900838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000]\ttraining's auc: 0.951843\tvalid_1's auc: 0.900587\n",
      "[12000]\ttraining's auc: 0.954894\tvalid_1's auc: 0.900639\n",
      "Early stopping, best iteration is:\n",
      "[9691]\ttraining's auc: 0.947612\tvalid_1's auc: 0.900898\n",
      "Total run time 32.88335924545924 min:\n",
      "CV score: 0.90053 \n"
     ]
    }
   ],
   "source": [
    "train_results_whole = train(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    train_df['target'],\n",
    "    train_df.columns.drop(['ID_code', 'target']).tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_whole, predictions_whole, feature_importance_whole, clf_ucm_whole = train_results_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_whole = pd.DataFrame(data=predictions_whole, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_5_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2, predictions_df_whole],\n",
    "    [1, 1, 1, 2, 3]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_5_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_5_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_5_df.to_csv('blended_5_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_less_1_4, predictions_less_1_4, feature_importance_less_1_4, clf_less_1_4 = train_results_less_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_less_1_4 = pd.DataFrame(data=predictions_less_1_4, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_6_var_1_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2, predictions_df_whole, predictions_df_less_1_4],\n",
    "    [1, 1, 1, 1, 4, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_6_var_1_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_6_var_1_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_6_var_1_df.to_csv('blended_6_var_1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_whole_only_df = pd.DataFrame({'ID_code': ID_code, 'target': predictions_df_whole['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_whole_only_df.to_csv('submission_whole_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(train_features, train_targets, model, batch_size=100, epochs=20, n_splits=5):\n",
    "    loss_history = LossHistory()\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [EarlyStopping(monitor='val_auc', patience=20, mode='max'), loss_history, annealer]\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits)\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in sss.split(train_features, train_targets):\n",
    "        X_train, X_val = train_features[train_index], train_features[test_index]\n",
    "        Y_train, Y_val = train_targets[train_index], train_targets[test_index]\n",
    "        #X_tr, Y_tr = augment(X_train, Y_train)\n",
    "        #print(\"{} iteration\".format(i+1))\n",
    "        history= model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "        #history= sequential_nn_model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "        del X_train, X_val, Y_train, Y_val\n",
    "        gc.collect()\n",
    "    print(\"Run time {} min\".format((time.time() - start_time) / 60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer=regularizers.l2(0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_polinomial_values_ucm_1_2.shape[1],)))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, input_shape=(train_polinomial_values_ucm_1_2.shape[1] / 2, ), activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, input_shape=(train_polinomial_values_ucm_1_2.shape[1] / 4, ), activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "#def auc(y_pred, y_true):\n",
    "    #print(y_true[:5])\n",
    "    #print(y_pred[:5])  \n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 10s 71us/step - loss: 0.3273 - acc: 0.8830 - auc: 0.6907 - val_loss: 0.2801 - val_acc: 0.9012 - val_auc: 0.7700\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2842 - acc: 0.8997 - auc: 0.7627 - val_loss: 0.2769 - val_acc: 0.9036 - val_auc: 0.7740\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2805 - acc: 0.9000 - auc: 0.7732 - val_loss: 0.2771 - val_acc: 0.9014 - val_auc: 0.7752\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2783 - acc: 0.9003 - auc: 0.7787 - val_loss: 0.2769 - val_acc: 0.9026 - val_auc: 0.7759\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2765 - acc: 0.9007 - auc: 0.7827 - val_loss: 0.2744 - val_acc: 0.9031 - val_auc: 0.7804\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2753 - acc: 0.9007 - auc: 0.7861 - val_loss: 0.2768 - val_acc: 0.9028 - val_auc: 0.7797\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2728 - acc: 0.9013 - auc: 0.7911 - val_loss: 0.2747 - val_acc: 0.9033 - val_auc: 0.7806\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2708 - acc: 0.9018 - auc: 0.7948 - val_loss: 0.2824 - val_acc: 0.9031 - val_auc: 0.7787\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2691 - acc: 0.9020 - auc: 0.7991 - val_loss: 0.2752 - val_acc: 0.9038 - val_auc: 0.7788\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2687 - acc: 0.9017 - auc: 0.8003 - val_loss: 0.2734 - val_acc: 0.9036 - val_auc: 0.7829\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2670 - acc: 0.9021 - auc: 0.8042 - val_loss: 0.2734 - val_acc: 0.9044 - val_auc: 0.7821\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2657 - acc: 0.9032 - auc: 0.8056 - val_loss: 0.2735 - val_acc: 0.9048 - val_auc: 0.7805\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2635 - acc: 0.9032 - auc: 0.8106 - val_loss: 0.2737 - val_acc: 0.9042 - val_auc: 0.7818\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2621 - acc: 0.9034 - auc: 0.8137 - val_loss: 0.2754 - val_acc: 0.9039 - val_auc: 0.7824\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2597 - acc: 0.9049 - auc: 0.8173 - val_loss: 0.2786 - val_acc: 0.9039 - val_auc: 0.7808\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2582 - acc: 0.9053 - auc: 0.8206 - val_loss: 0.2772 - val_acc: 0.9044 - val_auc: 0.7805\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2579 - acc: 0.9050 - auc: 0.8201 - val_loss: 0.2736 - val_acc: 0.9048 - val_auc: 0.7809\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2552 - acc: 0.9054 - auc: 0.8262 - val_loss: 0.2757 - val_acc: 0.9032 - val_auc: 0.7808\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2528 - acc: 0.9065 - auc: 0.8295 - val_loss: 0.2792 - val_acc: 0.9038 - val_auc: 0.7785\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2507 - acc: 0.9067 - auc: 0.8336 - val_loss: 0.2767 - val_acc: 0.9041 - val_auc: 0.7800\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2499 - acc: 0.9076 - auc: 0.8346 - val_loss: 0.2787 - val_acc: 0.9031 - val_auc: 0.7797\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2473 - acc: 0.9079 - auc: 0.8388 - val_loss: 0.2755 - val_acc: 0.9038 - val_auc: 0.7784\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2450 - acc: 0.9086 - auc: 0.8425 - val_loss: 0.2834 - val_acc: 0.9039 - val_auc: 0.7743\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2411 - acc: 0.9104 - auc: 0.8489 - val_loss: 0.2790 - val_acc: 0.9027 - val_auc: 0.7735\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2394 - acc: 0.9106 - auc: 0.8511 - val_loss: 0.2845 - val_acc: 0.9023 - val_auc: 0.7715\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2370 - acc: 0.9118 - auc: 0.8545 - val_loss: 0.2901 - val_acc: 0.9028 - val_auc: 0.7690\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2331 - acc: 0.9133 - auc: 0.8604 - val_loss: 0.2819 - val_acc: 0.9027 - val_auc: 0.7706\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2310 - acc: 0.9152 - auc: 0.8630 - val_loss: 0.2851 - val_acc: 0.9009 - val_auc: 0.7694\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2287 - acc: 0.9158 - auc: 0.8669 - val_loss: 0.2894 - val_acc: 0.9024 - val_auc: 0.7669\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2242 - acc: 0.9172 - auc: 0.8722 - val_loss: 0.2902 - val_acc: 0.9018 - val_auc: 0.7663\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2523 - acc: 0.9077 - auc: 0.8287 - val_loss: 0.2402 - val_acc: 0.9116 - val_auc: 0.8512\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2520 - acc: 0.9066 - auc: 0.8303 - val_loss: 0.2442 - val_acc: 0.9104 - val_auc: 0.8463\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2511 - acc: 0.9083 - auc: 0.8306 - val_loss: 0.2425 - val_acc: 0.9105 - val_auc: 0.8468\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2490 - acc: 0.9085 - auc: 0.8348 - val_loss: 0.2457 - val_acc: 0.9106 - val_auc: 0.8455\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2475 - acc: 0.9088 - auc: 0.8373 - val_loss: 0.2440 - val_acc: 0.9119 - val_auc: 0.8416\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2449 - acc: 0.9101 - auc: 0.8404 - val_loss: 0.2485 - val_acc: 0.9086 - val_auc: 0.8420\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2437 - acc: 0.9104 - auc: 0.8442 - val_loss: 0.2467 - val_acc: 0.9100 - val_auc: 0.8410\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2415 - acc: 0.9110 - auc: 0.8476 - val_loss: 0.2477 - val_acc: 0.9110 - val_auc: 0.8375\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2394 - acc: 0.9123 - auc: 0.8499 - val_loss: 0.2469 - val_acc: 0.9108 - val_auc: 0.8391\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2360 - acc: 0.9136 - auc: 0.8541 - val_loss: 0.2455 - val_acc: 0.9119 - val_auc: 0.8373\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2329 - acc: 0.9142 - auc: 0.8592 - val_loss: 0.2446 - val_acc: 0.9116 - val_auc: 0.8387\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2305 - acc: 0.9158 - auc: 0.8624 - val_loss: 0.2498 - val_acc: 0.9101 - val_auc: 0.8377\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2286 - acc: 0.9163 - auc: 0.8648 - val_loss: 0.2519 - val_acc: 0.9108 - val_auc: 0.8370\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2238 - acc: 0.9190 - auc: 0.8701 - val_loss: 0.2472 - val_acc: 0.9086 - val_auc: 0.8368\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2213 - acc: 0.9201 - auc: 0.8743 - val_loss: 0.2507 - val_acc: 0.9094 - val_auc: 0.8351\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2179 - acc: 0.9214 - auc: 0.8771 - val_loss: 0.2489 - val_acc: 0.9108 - val_auc: 0.8381\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2140 - acc: 0.9235 - auc: 0.8814 - val_loss: 0.2491 - val_acc: 0.9109 - val_auc: 0.8369\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2096 - acc: 0.9250 - auc: 0.8874 - val_loss: 0.2489 - val_acc: 0.9117 - val_auc: 0.8344\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 56us/step - loss: 0.2079 - acc: 0.9255 - auc: 0.8898 - val_loss: 0.2521 - val_acc: 0.9113 - val_auc: 0.8342\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2031 - acc: 0.9276 - auc: 0.8951 - val_loss: 0.2609 - val_acc: 0.9103 - val_auc: 0.8275\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 7s 46us/step - loss: 0.2002 - acc: 0.9290 - auc: 0.8972 - val_loss: 0.2567 - val_acc: 0.9109 - val_auc: 0.8333\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2283 - acc: 0.9178 - auc: 0.8640 - val_loss: 0.1989 - val_acc: 0.9279 - val_auc: 0.9058\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2265 - acc: 0.9182 - auc: 0.8657 - val_loss: 0.2043 - val_acc: 0.9251 - val_auc: 0.9025\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2252 - acc: 0.9182 - auc: 0.8686 - val_loss: 0.2091 - val_acc: 0.9226 - val_auc: 0.8934\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2231 - acc: 0.9196 - auc: 0.8711 - val_loss: 0.2068 - val_acc: 0.9233 - val_auc: 0.8989\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2200 - acc: 0.9208 - auc: 0.8745 - val_loss: 0.2130 - val_acc: 0.9197 - val_auc: 0.8985\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2167 - acc: 0.9223 - auc: 0.8780 - val_loss: 0.2056 - val_acc: 0.9256 - val_auc: 0.8943\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2149 - acc: 0.9229 - auc: 0.8808 - val_loss: 0.2082 - val_acc: 0.9246 - val_auc: 0.8975\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2108 - acc: 0.9249 - auc: 0.8861 - val_loss: 0.2097 - val_acc: 0.9227 - val_auc: 0.8941\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2078 - acc: 0.9257 - auc: 0.8889 - val_loss: 0.2035 - val_acc: 0.9274 - val_auc: 0.8950\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2043 - acc: 0.9269 - auc: 0.8924 - val_loss: 0.2393 - val_acc: 0.9103 - val_auc: 0.8884\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2020 - acc: 0.9281 - auc: 0.8952 - val_loss: 0.2123 - val_acc: 0.9212 - val_auc: 0.8926\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1977 - acc: 0.9304 - auc: 0.8998 - val_loss: 0.2130 - val_acc: 0.9217 - val_auc: 0.8937\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1930 - acc: 0.9320 - auc: 0.9049 - val_loss: 0.2173 - val_acc: 0.9195 - val_auc: 0.8934\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1898 - acc: 0.9331 - auc: 0.9080 - val_loss: 0.2034 - val_acc: 0.9287 - val_auc: 0.8965\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1868 - acc: 0.9343 - auc: 0.9107 - val_loss: 0.2116 - val_acc: 0.9261 - val_auc: 0.8941\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1830 - acc: 0.9363 - auc: 0.9142 - val_loss: 0.2064 - val_acc: 0.9261 - val_auc: 0.8937\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1791 - acc: 0.9380 - auc: 0.9170 - val_loss: 0.2203 - val_acc: 0.9202 - val_auc: 0.8908\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1759 - acc: 0.9390 - auc: 0.9202 - val_loss: 0.2174 - val_acc: 0.9249 - val_auc: 0.8936\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1732 - acc: 0.9401 - auc: 0.9237 - val_loss: 0.2120 - val_acc: 0.9241 - val_auc: 0.8925\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1693 - acc: 0.9418 - auc: 0.9264 - val_loss: 0.2013 - val_acc: 0.9294 - val_auc: 0.8960\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1664 - acc: 0.9424 - auc: 0.9299 - val_loss: 0.2040 - val_acc: 0.9277 - val_auc: 0.8980\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2004 - acc: 0.9290 - auc: 0.8964 - val_loss: 0.1622 - val_acc: 0.9427 - val_auc: 0.9434\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2020 - acc: 0.9290 - auc: 0.8937 - val_loss: 0.1670 - val_acc: 0.9414 - val_auc: 0.9389\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1976 - acc: 0.9296 - auc: 0.9008 - val_loss: 0.1695 - val_acc: 0.9378 - val_auc: 0.9385\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1960 - acc: 0.9317 - auc: 0.9015 - val_loss: 0.1681 - val_acc: 0.9411 - val_auc: 0.9384\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1937 - acc: 0.9313 - auc: 0.9051 - val_loss: 0.1640 - val_acc: 0.9437 - val_auc: 0.9352\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1879 - acc: 0.9336 - auc: 0.9099 - val_loss: 0.1647 - val_acc: 0.9424 - val_auc: 0.9361\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1850 - acc: 0.9350 - auc: 0.9127 - val_loss: 0.1633 - val_acc: 0.9456 - val_auc: 0.9317\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1835 - acc: 0.9358 - auc: 0.9146 - val_loss: 0.1610 - val_acc: 0.9454 - val_auc: 0.9340\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1788 - acc: 0.9371 - auc: 0.9187 - val_loss: 0.1769 - val_acc: 0.9354 - val_auc: 0.9368\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1747 - acc: 0.9387 - auc: 0.9234 - val_loss: 0.1734 - val_acc: 0.9347 - val_auc: 0.9385\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1715 - acc: 0.9405 - auc: 0.9252 - val_loss: 0.1643 - val_acc: 0.9409 - val_auc: 0.9354\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1700 - acc: 0.9403 - auc: 0.9278 - val_loss: 0.1634 - val_acc: 0.9431 - val_auc: 0.9337\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1655 - acc: 0.9423 - auc: 0.9319 - val_loss: 0.1686 - val_acc: 0.9402 - val_auc: 0.9330\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1635 - acc: 0.9434 - auc: 0.9324 - val_loss: 0.1709 - val_acc: 0.9405 - val_auc: 0.9363\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1596 - acc: 0.9444 - auc: 0.9361 - val_loss: 0.1612 - val_acc: 0.9444 - val_auc: 0.9362\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1554 - acc: 0.9461 - auc: 0.9396 - val_loss: 0.1678 - val_acc: 0.9397 - val_auc: 0.9355\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1521 - acc: 0.9472 - auc: 0.9425 - val_loss: 0.1685 - val_acc: 0.9418 - val_auc: 0.9344\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1490 - acc: 0.9483 - auc: 0.9444 - val_loss: 0.1585 - val_acc: 0.9459 - val_auc: 0.9355\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1476 - acc: 0.9496 - auc: 0.9455 - val_loss: 0.1637 - val_acc: 0.9430 - val_auc: 0.9343\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1424 - acc: 0.9502 - auc: 0.9498 - val_loss: 0.1811 - val_acc: 0.9377 - val_auc: 0.9348\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1407 - acc: 0.9514 - auc: 0.9501 - val_loss: 0.1630 - val_acc: 0.9453 - val_auc: 0.9363\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1753 - acc: 0.9386 - auc: 0.9231 - val_loss: 0.1274 - val_acc: 0.9563 - val_auc: 0.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1791 - acc: 0.9381 - auc: 0.9184 - val_loss: 0.1329 - val_acc: 0.9527 - val_auc: 0.9623\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1746 - acc: 0.9390 - auc: 0.9242 - val_loss: 0.1444 - val_acc: 0.9447 - val_auc: 0.9621\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1716 - acc: 0.9401 - auc: 0.9268 - val_loss: 0.1353 - val_acc: 0.9496 - val_auc: 0.9602\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1696 - acc: 0.9405 - auc: 0.9279 - val_loss: 0.1419 - val_acc: 0.9460 - val_auc: 0.9617\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 55us/step - loss: 0.1663 - acc: 0.9422 - auc: 0.9317 - val_loss: 0.1568 - val_acc: 0.9418 - val_auc: 0.9591\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1636 - acc: 0.9428 - auc: 0.9330 - val_loss: 0.1380 - val_acc: 0.9483 - val_auc: 0.9602\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1609 - acc: 0.9435 - auc: 0.9367 - val_loss: 0.1327 - val_acc: 0.9524 - val_auc: 0.9582\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1537 - acc: 0.9455 - auc: 0.9424 - val_loss: 0.1432 - val_acc: 0.9461 - val_auc: 0.9612\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1521 - acc: 0.9465 - auc: 0.9434 - val_loss: 0.1468 - val_acc: 0.9437 - val_auc: 0.9622\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1491 - acc: 0.9479 - auc: 0.9452 - val_loss: 0.1419 - val_acc: 0.9452 - val_auc: 0.9617\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1474 - acc: 0.9486 - auc: 0.9459 - val_loss: 0.1522 - val_acc: 0.9408 - val_auc: 0.9618\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1429 - acc: 0.9503 - auc: 0.9494 - val_loss: 0.1488 - val_acc: 0.9409 - val_auc: 0.9636\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1405 - acc: 0.9514 - auc: 0.9511 - val_loss: 0.1382 - val_acc: 0.9488 - val_auc: 0.9601\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1371 - acc: 0.9526 - auc: 0.9535 - val_loss: 0.1360 - val_acc: 0.9487 - val_auc: 0.9616\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1335 - acc: 0.9539 - auc: 0.9553 - val_loss: 0.1444 - val_acc: 0.9426 - val_auc: 0.9639\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1300 - acc: 0.9547 - auc: 0.9581 - val_loss: 0.1319 - val_acc: 0.9518 - val_auc: 0.9621\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1291 - acc: 0.9548 - auc: 0.9590 - val_loss: 0.1347 - val_acc: 0.9497 - val_auc: 0.9625\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.1251 - acc: 0.9561 - auc: 0.9618 - val_loss: 0.1353 - val_acc: 0.9489 - val_auc: 0.9625\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1237 - acc: 0.9574 - auc: 0.9619 - val_loss: 0.1354 - val_acc: 0.9491 - val_auc: 0.9618\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1210 - acc: 0.9579 - auc: 0.9644 - val_loss: 0.1267 - val_acc: 0.9544 - val_auc: 0.9635\n",
      "Run time 16.190694542725883 min\n"
     ]
    }
   ],
   "source": [
    "train_nn_result_ucm_1_2 = train_nn(train_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 61us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = train_nn_result_ucm_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40964529108256104, 0.8953000018000603, 0.7162384706535537]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 55us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = train_nn_result_ucm_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40964529108256104, 0.8953000018000603, 0.7162384706535537]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_polinomial_values_ucm_1_2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6215"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dim = train_polinomial_values_ucm_1_4_1_2.shape[1]\n",
    "input_dim = train_polinomial_values_ucm_1_4.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model = Sequential()\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "#sequential_nn_model.add(Dropout(0.4))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 2, kernel_initializer='normal', activation='sigmoid'))\n",
    "####sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 10, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "####sequential_nn_model.add(Dropout(0.4))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dropout(0.76))\n",
    "#sequential_nn_model.add(Dropout(0.24))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2873 - acc: 0.8991 - auc: 0.7600 - val_loss: 0.2802 - val_acc: 0.9019 - val_auc: 0.7811\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2755 - acc: 0.9005 - auc: 0.7835 - val_loss: 0.2751 - val_acc: 0.9026 - val_auc: 0.7857\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2714 - acc: 0.9018 - auc: 0.7928 - val_loss: 0.2758 - val_acc: 0.9033 - val_auc: 0.7868\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2681 - acc: 0.9031 - auc: 0.8019 - val_loss: 0.2731 - val_acc: 0.9035 - val_auc: 0.7881\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2639 - acc: 0.9036 - auc: 0.8090 - val_loss: 0.2736 - val_acc: 0.9039 - val_auc: 0.7849\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2605 - acc: 0.9046 - auc: 0.8161 - val_loss: 0.2725 - val_acc: 0.9041 - val_auc: 0.7880\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2575 - acc: 0.9052 - auc: 0.8223 - val_loss: 0.2734 - val_acc: 0.9029 - val_auc: 0.7840\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2540 - acc: 0.9057 - auc: 0.8291 - val_loss: 0.2759 - val_acc: 0.9032 - val_auc: 0.7823\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2510 - acc: 0.9072 - auc: 0.8344 - val_loss: 0.2752 - val_acc: 0.9032 - val_auc: 0.7815\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2467 - acc: 0.9081 - auc: 0.8425 - val_loss: 0.2793 - val_acc: 0.9041 - val_auc: 0.7816\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2442 - acc: 0.9087 - auc: 0.8465 - val_loss: 0.2828 - val_acc: 0.9038 - val_auc: 0.7808\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2401 - acc: 0.9097 - auc: 0.8538 - val_loss: 0.2811 - val_acc: 0.9030 - val_auc: 0.7788\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2362 - acc: 0.9106 - auc: 0.8603 - val_loss: 0.2835 - val_acc: 0.9026 - val_auc: 0.7767\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2314 - acc: 0.9120 - auc: 0.8673 - val_loss: 0.2874 - val_acc: 0.9036 - val_auc: 0.7747\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2275 - acc: 0.9125 - auc: 0.8743 - val_loss: 0.2918 - val_acc: 0.9028 - val_auc: 0.7725\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 55us/step - loss: 0.2233 - acc: 0.9137 - auc: 0.8797 - val_loss: 0.2933 - val_acc: 0.9021 - val_auc: 0.7683\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2173 - acc: 0.9154 - auc: 0.8873 - val_loss: 0.2924 - val_acc: 0.9016 - val_auc: 0.7689\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2138 - acc: 0.9161 - auc: 0.8925 - val_loss: 0.3010 - val_acc: 0.8989 - val_auc: 0.7656\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2068 - acc: 0.9185 - auc: 0.9016 - val_loss: 0.3111 - val_acc: 0.8999 - val_auc: 0.7630\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2027 - acc: 0.9196 - auc: 0.9065 - val_loss: 0.3106 - val_acc: 0.8983 - val_auc: 0.7643\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1959 - acc: 0.9219 - auc: 0.9137 - val_loss: 0.3140 - val_acc: 0.8994 - val_auc: 0.7564\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1890 - acc: 0.9241 - auc: 0.9205 - val_loss: 0.3221 - val_acc: 0.8994 - val_auc: 0.7561\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1836 - acc: 0.9261 - auc: 0.9261 - val_loss: 0.3372 - val_acc: 0.8961 - val_auc: 0.7544\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.1771 - acc: 0.9284 - auc: 0.9316 - val_loss: 0.3471 - val_acc: 0.8974 - val_auc: 0.7479\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2200 - acc: 0.9159 - auc: 0.8824 - val_loss: 0.2048 - val_acc: 0.9221 - val_auc: 0.9031\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2161 - acc: 0.9171 - auc: 0.8888 - val_loss: 0.2091 - val_acc: 0.9166 - val_auc: 0.8983\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2103 - acc: 0.9186 - auc: 0.8955 - val_loss: 0.2090 - val_acc: 0.9166 - val_auc: 0.8985\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.2061 - acc: 0.9196 - auc: 0.9007 - val_loss: 0.2107 - val_acc: 0.9175 - val_auc: 0.8949\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2010 - acc: 0.9215 - auc: 0.9062 - val_loss: 0.2116 - val_acc: 0.9186 - val_auc: 0.8950\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1950 - acc: 0.9237 - auc: 0.9126 - val_loss: 0.2160 - val_acc: 0.9171 - val_auc: 0.8947\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1875 - acc: 0.9260 - auc: 0.9212 - val_loss: 0.2165 - val_acc: 0.9174 - val_auc: 0.8881\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1848 - acc: 0.9270 - auc: 0.9238 - val_loss: 0.2196 - val_acc: 0.9149 - val_auc: 0.8885\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1768 - acc: 0.9300 - auc: 0.9304 - val_loss: 0.2218 - val_acc: 0.9177 - val_auc: 0.8862\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1711 - acc: 0.9324 - auc: 0.9351 - val_loss: 0.2226 - val_acc: 0.9171 - val_auc: 0.8841\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 6s 44us/step - loss: 0.1652 - acc: 0.9339 - auc: 0.9410 - val_loss: 0.2231 - val_acc: 0.9171 - val_auc: 0.8860\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1584 - acc: 0.9373 - auc: 0.9459 - val_loss: 0.2281 - val_acc: 0.9166 - val_auc: 0.8821\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1513 - acc: 0.9403 - auc: 0.9505 - val_loss: 0.2359 - val_acc: 0.9161 - val_auc: 0.8827\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 7s 45us/step - loss: 0.1439 - acc: 0.9439 - auc: 0.9555 - val_loss: 0.2388 - val_acc: 0.9156 - val_auc: 0.8788\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1378 - acc: 0.9468 - auc: 0.9593 - val_loss: 0.2463 - val_acc: 0.9154 - val_auc: 0.8794\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1335 - acc: 0.9490 - auc: 0.9618 - val_loss: 0.2466 - val_acc: 0.9159 - val_auc: 0.8777\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1272 - acc: 0.9510 - auc: 0.9657 - val_loss: 0.2584 - val_acc: 0.9150 - val_auc: 0.8765\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1234 - acc: 0.9529 - auc: 0.9676 - val_loss: 0.2647 - val_acc: 0.9155 - val_auc: 0.8731\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1182 - acc: 0.9557 - auc: 0.9703 - val_loss: 0.2477 - val_acc: 0.9142 - val_auc: 0.8778\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1123 - acc: 0.9575 - auc: 0.9733 - val_loss: 0.2517 - val_acc: 0.9154 - val_auc: 0.8776\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1074 - acc: 0.9599 - auc: 0.9751 - val_loss: 0.2627 - val_acc: 0.9141 - val_auc: 0.8755\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 6s 44us/step - loss: 0.1604 - acc: 0.9399 - auc: 0.9412 - val_loss: 0.1247 - val_acc: 0.9546 - val_auc: 0.9671\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1574 - acc: 0.9406 - auc: 0.9444 - val_loss: 0.1260 - val_acc: 0.9531 - val_auc: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1520 - acc: 0.9425 - auc: 0.9482 - val_loss: 0.1302 - val_acc: 0.9500 - val_auc: 0.9634\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.1462 - acc: 0.9451 - auc: 0.9530 - val_loss: 0.1314 - val_acc: 0.9482 - val_auc: 0.9630\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1391 - acc: 0.9477 - auc: 0.9572 - val_loss: 0.1352 - val_acc: 0.9479 - val_auc: 0.9594\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1351 - acc: 0.9496 - auc: 0.9599 - val_loss: 0.1364 - val_acc: 0.9492 - val_auc: 0.9590\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1286 - acc: 0.9526 - auc: 0.9631 - val_loss: 0.1445 - val_acc: 0.9430 - val_auc: 0.9591\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1252 - acc: 0.9539 - auc: 0.9654 - val_loss: 0.1350 - val_acc: 0.9491 - val_auc: 0.9590\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 45us/step - loss: 0.1186 - acc: 0.9567 - auc: 0.9688 - val_loss: 0.1374 - val_acc: 0.9485 - val_auc: 0.9593\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1149 - acc: 0.9577 - auc: 0.9713 - val_loss: 0.1455 - val_acc: 0.9442 - val_auc: 0.9598\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1066 - acc: 0.9616 - auc: 0.9745 - val_loss: 0.1405 - val_acc: 0.9468 - val_auc: 0.9586\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1048 - acc: 0.9619 - auc: 0.9754 - val_loss: 0.1471 - val_acc: 0.9456 - val_auc: 0.9557\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0990 - acc: 0.9644 - auc: 0.9784 - val_loss: 0.1441 - val_acc: 0.9484 - val_auc: 0.9560\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0936 - acc: 0.9664 - auc: 0.9801 - val_loss: 0.1476 - val_acc: 0.9451 - val_auc: 0.9581\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0895 - acc: 0.9683 - auc: 0.9819 - val_loss: 0.1461 - val_acc: 0.9456 - val_auc: 0.9580\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0854 - acc: 0.9697 - auc: 0.9835 - val_loss: 0.1501 - val_acc: 0.9444 - val_auc: 0.9557\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0834 - acc: 0.9703 - auc: 0.9846 - val_loss: 0.1478 - val_acc: 0.9469 - val_auc: 0.9571\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0788 - acc: 0.9720 - auc: 0.9859 - val_loss: 0.1529 - val_acc: 0.9455 - val_auc: 0.9557\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0759 - acc: 0.9733 - auc: 0.9866 - val_loss: 0.1520 - val_acc: 0.9470 - val_auc: 0.9543\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0741 - acc: 0.9739 - auc: 0.9874 - val_loss: 0.1497 - val_acc: 0.9473 - val_auc: 0.9553\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0696 - acc: 0.9757 - auc: 0.9887 - val_loss: 0.1696 - val_acc: 0.9435 - val_auc: 0.9541\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1229 - acc: 0.9556 - auc: 0.9651 - val_loss: 0.0741 - val_acc: 0.9791 - val_auc: 0.9892\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1209 - acc: 0.9560 - auc: 0.9671 - val_loss: 0.0776 - val_acc: 0.9777 - val_auc: 0.9885\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1144 - acc: 0.9583 - auc: 0.9709 - val_loss: 0.0822 - val_acc: 0.9770 - val_auc: 0.9871\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1117 - acc: 0.9591 - auc: 0.9720 - val_loss: 0.0776 - val_acc: 0.9760 - val_auc: 0.9868\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1049 - acc: 0.9621 - auc: 0.9755 - val_loss: 0.0802 - val_acc: 0.9747 - val_auc: 0.9870\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0989 - acc: 0.9644 - auc: 0.9782 - val_loss: 0.0792 - val_acc: 0.9711 - val_auc: 0.9875\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0964 - acc: 0.9652 - auc: 0.9792 - val_loss: 0.0839 - val_acc: 0.9682 - val_auc: 0.9860\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0923 - acc: 0.9669 - auc: 0.9807 - val_loss: 0.0826 - val_acc: 0.9722 - val_auc: 0.9854\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0876 - acc: 0.9692 - auc: 0.9824 - val_loss: 0.0804 - val_acc: 0.9705 - val_auc: 0.9865\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0828 - acc: 0.9709 - auc: 0.9842 - val_loss: 0.0795 - val_acc: 0.9729 - val_auc: 0.9857\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0807 - acc: 0.9717 - auc: 0.9853 - val_loss: 0.0817 - val_acc: 0.9696 - val_auc: 0.9863\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0741 - acc: 0.9742 - auc: 0.9870 - val_loss: 0.0814 - val_acc: 0.9706 - val_auc: 0.9855\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0719 - acc: 0.9746 - auc: 0.9884 - val_loss: 0.0795 - val_acc: 0.9729 - val_auc: 0.9862\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0710 - acc: 0.9750 - auc: 0.9884 - val_loss: 0.0854 - val_acc: 0.9679 - val_auc: 0.9869\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0665 - acc: 0.9769 - auc: 0.9895 - val_loss: 0.0831 - val_acc: 0.9714 - val_auc: 0.9846\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0641 - acc: 0.9776 - auc: 0.9906 - val_loss: 0.0830 - val_acc: 0.9707 - val_auc: 0.9858\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0599 - acc: 0.9795 - auc: 0.9914 - val_loss: 0.0890 - val_acc: 0.9679 - val_auc: 0.9859\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0569 - acc: 0.9802 - auc: 0.9924 - val_loss: 0.0889 - val_acc: 0.9686 - val_auc: 0.9856\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0546 - acc: 0.9811 - auc: 0.9926 - val_loss: 0.0851 - val_acc: 0.9693 - val_auc: 0.9851\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0541 - acc: 0.9812 - auc: 0.9931 - val_loss: 0.0864 - val_acc: 0.9688 - val_auc: 0.9849\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0514 - acc: 0.9823 - auc: 0.9934 - val_loss: 0.0823 - val_acc: 0.9708 - val_auc: 0.9858\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1008 - acc: 0.9645 - auc: 0.9765 - val_loss: 0.0539 - val_acc: 0.9833 - val_auc: 0.9956\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0975 - acc: 0.9648 - auc: 0.9791 - val_loss: 0.0502 - val_acc: 0.9854 - val_auc: 0.9955\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0944 - acc: 0.9659 - auc: 0.9808 - val_loss: 0.0491 - val_acc: 0.9854 - val_auc: 0.9951\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.0886 - acc: 0.9684 - auc: 0.9826 - val_loss: 0.0534 - val_acc: 0.9851 - val_auc: 0.9941\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.0864 - acc: 0.9683 - auc: 0.9836 - val_loss: 0.0521 - val_acc: 0.9862 - val_auc: 0.9942\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0813 - acc: 0.9710 - auc: 0.9852 - val_loss: 0.0544 - val_acc: 0.9826 - val_auc: 0.9952\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0786 - acc: 0.9719 - auc: 0.9865 - val_loss: 0.0549 - val_acc: 0.9832 - val_auc: 0.9944\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0745 - acc: 0.9731 - auc: 0.9882 - val_loss: 0.0512 - val_acc: 0.9849 - val_auc: 0.9945\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0717 - acc: 0.9749 - auc: 0.9886 - val_loss: 0.0544 - val_acc: 0.9816 - val_auc: 0.9947\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0672 - acc: 0.9764 - auc: 0.9897 - val_loss: 0.0513 - val_acc: 0.9844 - val_auc: 0.9942\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0645 - acc: 0.9774 - auc: 0.9905 - val_loss: 0.0544 - val_acc: 0.9821 - val_auc: 0.9940\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0623 - acc: 0.9785 - auc: 0.9912 - val_loss: 0.0528 - val_acc: 0.9831 - val_auc: 0.9937\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0581 - acc: 0.9800 - auc: 0.9921 - val_loss: 0.0567 - val_acc: 0.9799 - val_auc: 0.9939\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0548 - acc: 0.9809 - auc: 0.9932 - val_loss: 0.0544 - val_acc: 0.9832 - val_auc: 0.9933\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0532 - acc: 0.9818 - auc: 0.9933 - val_loss: 0.0499 - val_acc: 0.9833 - val_auc: 0.9942\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0517 - acc: 0.9820 - auc: 0.9937 - val_loss: 0.0471 - val_acc: 0.9851 - val_auc: 0.9945\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0476 - acc: 0.9835 - auc: 0.9949 - val_loss: 0.0500 - val_acc: 0.9841 - val_auc: 0.9942\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0472 - acc: 0.9838 - auc: 0.9946 - val_loss: 0.0512 - val_acc: 0.9839 - val_auc: 0.9938\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0452 - acc: 0.9844 - auc: 0.9951 - val_loss: 0.0491 - val_acc: 0.9841 - val_auc: 0.9938\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0429 - acc: 0.9853 - auc: 0.9954 - val_loss: 0.0485 - val_acc: 0.9842 - val_auc: 0.9938\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0396 - acc: 0.9863 - auc: 0.9963 - val_loss: 0.0488 - val_acc: 0.9842 - val_auc: 0.9934\n",
      "Run time 13.482337999343873 min\n"
     ]
    }
   ],
   "source": [
    "secquential_nn_model_1_2 = train_nn(train_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, sequential_nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 52us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = secquential_nn_model_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.585995932482183, 0.8846999990940094, 0.5885962312027564]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5543117852136493, 0.8831499993801117, 0.7176417884978589]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequential_model_min(input_dim):\n",
    "    sequential_nn_model_min = Sequential()\n",
    "    sequential_nn_model_min.add(Dense(batch_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    sequential_nn_model_min.add(Dropout(0.4))\n",
    "    sequential_nn_model_min.add(BatchNormalization())\n",
    "    sequential_nn_model_min.add(Dense(batch_size, input_dim=input_dim / 10, kernel_initializer='normal', activation='sigmoid'))\n",
    "    sequential_nn_model_min.add(Dropout(0.4))\n",
    "    sequential_nn_model_min.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    return sequential_nn_model_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_2 = make_sequential_model_min(train_polinomial_values_ucm_1_2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0891 - acc: 0.9683 - auc: 0.9820 - val_loss: 0.0416 - val_acc: 0.9907 - val_auc: 0.9967\n",
      "Epoch 2/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0890 - acc: 0.9677 - auc: 0.9830 - val_loss: 0.0389 - val_acc: 0.9897 - val_auc: 0.9971\n",
      "Epoch 3/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0838 - acc: 0.9700 - auc: 0.9851 - val_loss: 0.0415 - val_acc: 0.9897 - val_auc: 0.9960\n",
      "Epoch 4/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0766 - acc: 0.9725 - auc: 0.9873 - val_loss: 0.0407 - val_acc: 0.9908 - val_auc: 0.9963\n",
      "Epoch 5/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0747 - acc: 0.9734 - auc: 0.9873 - val_loss: 0.0403 - val_acc: 0.9879 - val_auc: 0.9965\n",
      "Epoch 6/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0709 - acc: 0.9747 - auc: 0.9889 - val_loss: 0.0417 - val_acc: 0.9884 - val_auc: 0.9963\n",
      "Epoch 7/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0680 - acc: 0.9757 - auc: 0.9901 - val_loss: 0.0386 - val_acc: 0.9891 - val_auc: 0.9970\n",
      "Epoch 8/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0647 - acc: 0.9775 - auc: 0.9906 - val_loss: 0.0425 - val_acc: 0.9866 - val_auc: 0.9964\n",
      "Epoch 9/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0601 - acc: 0.9793 - auc: 0.9918 - val_loss: 0.0386 - val_acc: 0.9895 - val_auc: 0.9964\n",
      "Epoch 10/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0595 - acc: 0.9790 - auc: 0.9921 - val_loss: 0.0398 - val_acc: 0.9892 - val_auc: 0.9966\n",
      "Epoch 11/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0562 - acc: 0.9803 - auc: 0.9929 - val_loss: 0.0365 - val_acc: 0.9892 - val_auc: 0.9969\n",
      "Epoch 12/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0515 - acc: 0.9822 - auc: 0.9938 - val_loss: 0.0370 - val_acc: 0.9894 - val_auc: 0.9966\n",
      "Epoch 13/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0519 - acc: 0.9824 - auc: 0.9939 - val_loss: 0.0386 - val_acc: 0.9894 - val_auc: 0.9960\n",
      "Epoch 14/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0488 - acc: 0.9834 - auc: 0.9944 - val_loss: 0.0361 - val_acc: 0.9881 - val_auc: 0.9971\n",
      "Epoch 15/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0464 - acc: 0.9841 - auc: 0.9952 - val_loss: 0.0338 - val_acc: 0.9915 - val_auc: 0.9966\n",
      "Epoch 16/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0448 - acc: 0.9847 - auc: 0.9954 - val_loss: 0.0340 - val_acc: 0.9900 - val_auc: 0.9970\n",
      "Epoch 17/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0426 - acc: 0.9855 - auc: 0.9957 - val_loss: 0.0329 - val_acc: 0.9906 - val_auc: 0.9975\n",
      "Epoch 18/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0424 - acc: 0.9859 - auc: 0.9957 - val_loss: 0.0337 - val_acc: 0.9907 - val_auc: 0.9969\n",
      "Epoch 19/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0387 - acc: 0.9865 - auc: 0.9966 - val_loss: 0.0333 - val_acc: 0.9908 - val_auc: 0.9975\n",
      "Epoch 20/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0379 - acc: 0.9871 - auc: 0.9967 - val_loss: 0.0326 - val_acc: 0.9914 - val_auc: 0.9965\n",
      "Epoch 21/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0362 - acc: 0.9879 - auc: 0.9967 - val_loss: 0.0345 - val_acc: 0.9900 - val_auc: 0.9970\n",
      "Epoch 22/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0338 - acc: 0.9882 - auc: 0.9973 - val_loss: 0.0321 - val_acc: 0.9901 - val_auc: 0.9969\n",
      "Epoch 23/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0339 - acc: 0.9884 - auc: 0.9973 - val_loss: 0.0310 - val_acc: 0.9902 - val_auc: 0.9972\n",
      "Epoch 24/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0311 - acc: 0.9896 - auc: 0.9977 - val_loss: 0.0312 - val_acc: 0.9910 - val_auc: 0.9975\n",
      "Epoch 25/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0315 - acc: 0.9897 - auc: 0.9974 - val_loss: 0.0279 - val_acc: 0.9921 - val_auc: 0.9977\n",
      "Epoch 26/30\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0303 - acc: 0.9899 - auc: 0.9977 - val_loss: 0.0333 - val_acc: 0.9898 - val_auc: 0.9967\n",
      "Epoch 27/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0297 - acc: 0.9902 - auc: 0.9978 - val_loss: 0.0332 - val_acc: 0.9911 - val_auc: 0.9971\n",
      "Epoch 28/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0288 - acc: 0.9907 - auc: 0.9978 - val_loss: 0.0293 - val_acc: 0.9922 - val_auc: 0.9974\n",
      "Epoch 29/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0271 - acc: 0.9908 - auc: 0.9982 - val_loss: 0.0320 - val_acc: 0.9898 - val_auc: 0.9976\n",
      "Epoch 30/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0257 - acc: 0.9914 - auc: 0.9983 - val_loss: 0.0301 - val_acc: 0.9915 - val_auc: 0.9974\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0819 - acc: 0.9705 - auc: 0.9847 - val_loss: 0.0371 - val_acc: 0.9908 - val_auc: 0.9975\n",
      "Epoch 2/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0810 - acc: 0.9710 - auc: 0.9857 - val_loss: 0.0365 - val_acc: 0.9923 - val_auc: 0.9980\n",
      "Epoch 3/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0745 - acc: 0.9732 - auc: 0.9884 - val_loss: 0.0318 - val_acc: 0.9936 - val_auc: 0.9986\n",
      "Epoch 4/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0686 - acc: 0.9756 - auc: 0.9896 - val_loss: 0.0321 - val_acc: 0.9912 - val_auc: 0.9984\n",
      "Epoch 5/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0648 - acc: 0.9775 - auc: 0.9905 - val_loss: 0.0299 - val_acc: 0.9928 - val_auc: 0.9983\n",
      "Epoch 6/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0627 - acc: 0.9774 - auc: 0.9915 - val_loss: 0.0293 - val_acc: 0.9936 - val_auc: 0.9983\n",
      "Epoch 7/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0584 - acc: 0.9793 - auc: 0.9926 - val_loss: 0.0258 - val_acc: 0.9944 - val_auc: 0.9988\n",
      "Epoch 8/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0552 - acc: 0.9807 - auc: 0.9930 - val_loss: 0.0294 - val_acc: 0.9913 - val_auc: 0.9980\n",
      "Epoch 9/30\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0539 - acc: 0.9813 - auc: 0.9938 - val_loss: 0.0251 - val_acc: 0.9922 - val_auc: 0.9988\n",
      "Epoch 10/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0509 - acc: 0.9825 - auc: 0.9939 - val_loss: 0.0281 - val_acc: 0.9930 - val_auc: 0.9981\n",
      "Epoch 11/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0501 - acc: 0.9830 - auc: 0.9941 - val_loss: 0.0263 - val_acc: 0.9932 - val_auc: 0.9989\n",
      "Epoch 12/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0443 - acc: 0.9844 - auc: 0.9957 - val_loss: 0.0248 - val_acc: 0.9931 - val_auc: 0.9988\n",
      "Epoch 13/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0447 - acc: 0.9844 - auc: 0.9955 - val_loss: 0.0233 - val_acc: 0.9931 - val_auc: 0.9986\n",
      "Epoch 14/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0440 - acc: 0.9849 - auc: 0.9956 - val_loss: 0.0246 - val_acc: 0.9918 - val_auc: 0.9991\n",
      "Epoch 15/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0401 - acc: 0.9863 - auc: 0.9962 - val_loss: 0.0242 - val_acc: 0.9929 - val_auc: 0.9987\n",
      "Epoch 16/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0373 - acc: 0.9875 - auc: 0.9968 - val_loss: 0.0248 - val_acc: 0.9925 - val_auc: 0.9986\n",
      "Epoch 17/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0362 - acc: 0.9877 - auc: 0.9971 - val_loss: 0.0262 - val_acc: 0.9914 - val_auc: 0.9987\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0342 - acc: 0.9884 - auc: 0.9972 - val_loss: 0.0271 - val_acc: 0.9911 - val_auc: 0.9990\n",
      "Epoch 19/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0347 - acc: 0.9883 - auc: 0.9970 - val_loss: 0.0202 - val_acc: 0.9938 - val_auc: 0.9988\n",
      "Epoch 20/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0325 - acc: 0.9892 - auc: 0.9974 - val_loss: 0.0230 - val_acc: 0.9931 - val_auc: 0.9990\n",
      "Epoch 21/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0301 - acc: 0.9896 - auc: 0.9979 - val_loss: 0.0204 - val_acc: 0.9939 - val_auc: 0.9989\n",
      "Epoch 22/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0299 - acc: 0.9899 - auc: 0.9980 - val_loss: 0.0236 - val_acc: 0.9936 - val_auc: 0.9989\n",
      "Epoch 23/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0289 - acc: 0.9904 - auc: 0.9978 - val_loss: 0.0214 - val_acc: 0.9939 - val_auc: 0.9990\n",
      "Epoch 24/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0281 - acc: 0.9908 - auc: 0.9981 - val_loss: 0.0225 - val_acc: 0.9929 - val_auc: 0.9988\n",
      "Epoch 25/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0266 - acc: 0.9911 - auc: 0.9984 - val_loss: 0.0214 - val_acc: 0.9938 - val_auc: 0.9988\n",
      "Epoch 26/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0258 - acc: 0.9915 - auc: 0.9983 - val_loss: 0.0216 - val_acc: 0.9937 - val_auc: 0.9991\n",
      "Epoch 27/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0254 - acc: 0.9914 - auc: 0.9984 - val_loss: 0.0207 - val_acc: 0.9943 - val_auc: 0.9991\n",
      "Epoch 28/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0239 - acc: 0.9923 - auc: 0.9986 - val_loss: 0.0192 - val_acc: 0.9941 - val_auc: 0.9991\n",
      "Epoch 29/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0232 - acc: 0.9923 - auc: 0.9987 - val_loss: 0.0217 - val_acc: 0.9937 - val_auc: 0.9989\n",
      "Epoch 30/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0226 - acc: 0.9924 - auc: 0.9988 - val_loss: 0.0201 - val_acc: 0.9946 - val_auc: 0.9990\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0718 - acc: 0.9744 - auc: 0.9883 - val_loss: 0.0250 - val_acc: 0.9945 - val_auc: 0.9992\n",
      "Epoch 2/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0733 - acc: 0.9742 - auc: 0.9885 - val_loss: 0.0245 - val_acc: 0.9935 - val_auc: 0.9992\n",
      "Epoch 3/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0643 - acc: 0.9771 - auc: 0.9909 - val_loss: 0.0264 - val_acc: 0.9945 - val_auc: 0.9991\n",
      "Epoch 4/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0624 - acc: 0.9779 - auc: 0.9913 - val_loss: 0.0225 - val_acc: 0.9953 - val_auc: 0.9993\n",
      "Epoch 5/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0592 - acc: 0.9792 - auc: 0.9921 - val_loss: 0.0211 - val_acc: 0.9958 - val_auc: 0.9994\n",
      "Epoch 6/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0544 - acc: 0.9806 - auc: 0.9936 - val_loss: 0.0256 - val_acc: 0.9936 - val_auc: 0.9990\n",
      "Epoch 7/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0514 - acc: 0.9820 - auc: 0.9941 - val_loss: 0.0186 - val_acc: 0.9952 - val_auc: 0.9995\n",
      "Epoch 8/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0492 - acc: 0.9827 - auc: 0.9947 - val_loss: 0.0213 - val_acc: 0.9942 - val_auc: 0.9994\n",
      "Epoch 9/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0464 - acc: 0.9838 - auc: 0.9951 - val_loss: 0.0195 - val_acc: 0.9959 - val_auc: 0.9992\n",
      "Epoch 10/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0446 - acc: 0.9848 - auc: 0.9955 - val_loss: 0.0204 - val_acc: 0.9955 - val_auc: 0.9994\n",
      "Epoch 11/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0417 - acc: 0.9857 - auc: 0.9961 - val_loss: 0.0164 - val_acc: 0.9971 - val_auc: 0.9997\n",
      "Epoch 12/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0415 - acc: 0.9853 - auc: 0.9962 - val_loss: 0.0185 - val_acc: 0.9950 - val_auc: 0.9994\n",
      "Epoch 13/30\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0393 - acc: 0.9865 - auc: 0.9965 - val_loss: 0.0177 - val_acc: 0.9959 - val_auc: 0.9996\n",
      "Epoch 14/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0364 - acc: 0.9875 - auc: 0.9970 - val_loss: 0.0168 - val_acc: 0.9952 - val_auc: 0.9996\n",
      "Epoch 15/30\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.0349 - acc: 0.9880 - auc: 0.9972 - val_loss: 0.0165 - val_acc: 0.9958 - val_auc: 0.9995\n",
      "Epoch 16/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0331 - acc: 0.9888 - auc: 0.9973 - val_loss: 0.0155 - val_acc: 0.9961 - val_auc: 0.9996\n",
      "Epoch 17/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0320 - acc: 0.9893 - auc: 0.9975 - val_loss: 0.0170 - val_acc: 0.9953 - val_auc: 0.9994\n",
      "Epoch 18/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0315 - acc: 0.9896 - auc: 0.9976 - val_loss: 0.0154 - val_acc: 0.9957 - val_auc: 0.9996\n",
      "Epoch 19/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0287 - acc: 0.9901 - auc: 0.9979 - val_loss: 0.0141 - val_acc: 0.9959 - val_auc: 0.9997\n",
      "Epoch 20/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0280 - acc: 0.9904 - auc: 0.9981 - val_loss: 0.0150 - val_acc: 0.9959 - val_auc: 0.9994\n",
      "Epoch 21/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0272 - acc: 0.9911 - auc: 0.9983 - val_loss: 0.0146 - val_acc: 0.9958 - val_auc: 0.9997\n",
      "Epoch 22/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0268 - acc: 0.9910 - auc: 0.9982 - val_loss: 0.0132 - val_acc: 0.9966 - val_auc: 0.9996\n",
      "Epoch 23/30\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.0248 - acc: 0.9920 - auc: 0.9985 - val_loss: 0.0147 - val_acc: 0.9958 - val_auc: 0.9997\n",
      "Epoch 24/30\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.0247 - acc: 0.9917 - auc: 0.9986 - val_loss: 0.0146 - val_acc: 0.9959 - val_auc: 0.9996\n",
      "Epoch 25/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0229 - acc: 0.9926 - auc: 0.9987 - val_loss: 0.0131 - val_acc: 0.9966 - val_auc: 0.9995\n",
      "Epoch 26/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0220 - acc: 0.9926 - auc: 0.9988 - val_loss: 0.0132 - val_acc: 0.9964 - val_auc: 0.9995\n",
      "Epoch 27/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0225 - acc: 0.9927 - auc: 0.9988 - val_loss: 0.0123 - val_acc: 0.9963 - val_auc: 0.9997\n",
      "Epoch 28/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0206 - acc: 0.9932 - auc: 0.9990 - val_loss: 0.0113 - val_acc: 0.9972 - val_auc: 0.9997\n",
      "Epoch 29/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0200 - acc: 0.9936 - auc: 0.9989 - val_loss: 0.0117 - val_acc: 0.9966 - val_auc: 0.9997\n",
      "Epoch 30/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0203 - acc: 0.9935 - auc: 0.9988 - val_loss: 0.0129 - val_acc: 0.9963 - val_auc: 0.9997\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0664 - acc: 0.9764 - auc: 0.9900 - val_loss: 0.0230 - val_acc: 0.9946 - val_auc: 0.9995\n",
      "Epoch 2/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0667 - acc: 0.9760 - auc: 0.9906 - val_loss: 0.0189 - val_acc: 0.9959 - val_auc: 0.9997\n",
      "Epoch 3/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0598 - acc: 0.9783 - auc: 0.9926 - val_loss: 0.0190 - val_acc: 0.9958 - val_auc: 0.9996\n",
      "Epoch 4/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0576 - acc: 0.9799 - auc: 0.9929 - val_loss: 0.0202 - val_acc: 0.9958 - val_auc: 0.9995\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0525 - acc: 0.9815 - auc: 0.9940 - val_loss: 0.0212 - val_acc: 0.9933 - val_auc: 0.9995\n",
      "Epoch 6/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0502 - acc: 0.9826 - auc: 0.9943 - val_loss: 0.0177 - val_acc: 0.9965 - val_auc: 0.9996\n",
      "Epoch 7/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0467 - acc: 0.9837 - auc: 0.9954 - val_loss: 0.0189 - val_acc: 0.9945 - val_auc: 0.9995\n",
      "Epoch 8/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0455 - acc: 0.9838 - auc: 0.9954 - val_loss: 0.0174 - val_acc: 0.9961 - val_auc: 0.9994\n",
      "Epoch 9/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0414 - acc: 0.9857 - auc: 0.9962 - val_loss: 0.0186 - val_acc: 0.9945 - val_auc: 0.9997\n",
      "Epoch 10/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0413 - acc: 0.9859 - auc: 0.9961 - val_loss: 0.0135 - val_acc: 0.9971 - val_auc: 0.9997\n",
      "Epoch 11/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0397 - acc: 0.9865 - auc: 0.9964 - val_loss: 0.0154 - val_acc: 0.9961 - val_auc: 0.9996\n",
      "Epoch 12/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0358 - acc: 0.9873 - auc: 0.9972 - val_loss: 0.0153 - val_acc: 0.9952 - val_auc: 0.9997\n",
      "Epoch 13/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0355 - acc: 0.9880 - auc: 0.9970 - val_loss: 0.0145 - val_acc: 0.9962 - val_auc: 0.9994\n",
      "Epoch 14/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0342 - acc: 0.9885 - auc: 0.9973 - val_loss: 0.0130 - val_acc: 0.9966 - val_auc: 0.9998\n",
      "Epoch 15/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0336 - acc: 0.9885 - auc: 0.9974 - val_loss: 0.0131 - val_acc: 0.9964 - val_auc: 0.9997\n",
      "Epoch 16/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0296 - acc: 0.9898 - auc: 0.9981 - val_loss: 0.0134 - val_acc: 0.9963 - val_auc: 0.9997\n",
      "Epoch 17/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0281 - acc: 0.9904 - auc: 0.9982 - val_loss: 0.0119 - val_acc: 0.9969 - val_auc: 0.9998\n",
      "Epoch 18/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0271 - acc: 0.9909 - auc: 0.9983 - val_loss: 0.0115 - val_acc: 0.9969 - val_auc: 0.9997\n",
      "Epoch 19/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0268 - acc: 0.9908 - auc: 0.9985 - val_loss: 0.0124 - val_acc: 0.9964 - val_auc: 0.9997\n",
      "Epoch 20/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0249 - acc: 0.9917 - auc: 0.9985 - val_loss: 0.0117 - val_acc: 0.9970 - val_auc: 0.9998\n",
      "Epoch 21/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0248 - acc: 0.9917 - auc: 0.9985 - val_loss: 0.0110 - val_acc: 0.9969 - val_auc: 0.9997\n",
      "Epoch 22/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0237 - acc: 0.9921 - auc: 0.9987 - val_loss: 0.0106 - val_acc: 0.9974 - val_auc: 0.9997\n",
      "Epoch 23/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0235 - acc: 0.9922 - auc: 0.9987 - val_loss: 0.0106 - val_acc: 0.9974 - val_auc: 0.9997\n",
      "Epoch 24/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0214 - acc: 0.9929 - auc: 0.9989 - val_loss: 0.0109 - val_acc: 0.9970 - val_auc: 0.9998\n",
      "Epoch 25/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0209 - acc: 0.9931 - auc: 0.9989 - val_loss: 0.0122 - val_acc: 0.9973 - val_auc: 0.9996\n",
      "Epoch 26/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0194 - acc: 0.9933 - auc: 0.9992 - val_loss: 0.0110 - val_acc: 0.9969 - val_auc: 0.9997\n",
      "Epoch 27/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0195 - acc: 0.9934 - auc: 0.9990 - val_loss: 0.0115 - val_acc: 0.9968 - val_auc: 0.9997\n",
      "Epoch 28/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0190 - acc: 0.9937 - auc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9973 - val_auc: 0.9998\n",
      "Epoch 29/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0185 - acc: 0.9939 - auc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9976 - val_auc: 0.9997\n",
      "Epoch 30/30\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0173 - acc: 0.9943 - auc: 0.9993 - val_loss: 0.0100 - val_acc: 0.9974 - val_auc: 0.9998\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0625 - acc: 0.9776 - auc: 0.9914 - val_loss: 0.0201 - val_acc: 0.9962 - val_auc: 0.9996\n",
      "Epoch 2/30\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.0626 - acc: 0.9776 - auc: 0.9917 - val_loss: 0.0181 - val_acc: 0.9963 - val_auc: 0.9995\n",
      "Epoch 3/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0558 - acc: 0.9806 - auc: 0.9932 - val_loss: 0.0174 - val_acc: 0.9965 - val_auc: 0.9993\n",
      "Epoch 4/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0528 - acc: 0.9812 - auc: 0.9943 - val_loss: 0.0170 - val_acc: 0.9958 - val_auc: 0.9996\n",
      "Epoch 5/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0501 - acc: 0.9821 - auc: 0.9946 - val_loss: 0.0154 - val_acc: 0.9960 - val_auc: 0.9997\n",
      "Epoch 6/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0447 - acc: 0.9840 - auc: 0.9959 - val_loss: 0.0165 - val_acc: 0.9966 - val_auc: 0.9996\n",
      "Epoch 7/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0446 - acc: 0.9843 - auc: 0.9959 - val_loss: 0.0128 - val_acc: 0.9973 - val_auc: 0.9997\n",
      "Epoch 8/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0415 - acc: 0.9858 - auc: 0.9962 - val_loss: 0.0128 - val_acc: 0.9968 - val_auc: 0.9997\n",
      "Epoch 9/30\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.0390 - acc: 0.9868 - auc: 0.9968 - val_loss: 0.0118 - val_acc: 0.9974 - val_auc: 0.9998\n",
      "Epoch 10/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0364 - acc: 0.9875 - auc: 0.9972 - val_loss: 0.0128 - val_acc: 0.9974 - val_auc: 0.9996\n",
      "Epoch 11/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0350 - acc: 0.9878 - auc: 0.9973 - val_loss: 0.0108 - val_acc: 0.9978 - val_auc: 0.9997\n",
      "Epoch 12/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0333 - acc: 0.9887 - auc: 0.9974 - val_loss: 0.0105 - val_acc: 0.9978 - val_auc: 0.9997\n",
      "Epoch 13/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0325 - acc: 0.9888 - auc: 0.9977 - val_loss: 0.0122 - val_acc: 0.9972 - val_auc: 0.9998\n",
      "Epoch 14/30\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0321 - acc: 0.9894 - auc: 0.9975 - val_loss: 0.0094 - val_acc: 0.9984 - val_auc: 0.9998\n",
      "Epoch 15/30\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.0292 - acc: 0.9901 - auc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9978 - val_auc: 0.9998\n",
      "Epoch 16/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0292 - acc: 0.9900 - auc: 0.9982 - val_loss: 0.0092 - val_acc: 0.9978 - val_auc: 0.9999\n",
      "Epoch 17/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0263 - acc: 0.9910 - auc: 0.9985 - val_loss: 0.0094 - val_acc: 0.9982 - val_auc: 0.9998\n",
      "Epoch 18/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0250 - acc: 0.9919 - auc: 0.9985 - val_loss: 0.0076 - val_acc: 0.9984 - val_auc: 0.9999\n",
      "Epoch 19/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0230 - acc: 0.9924 - auc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9972 - val_auc: 0.9999\n",
      "Epoch 20/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0238 - acc: 0.9918 - auc: 0.9987 - val_loss: 0.0107 - val_acc: 0.9975 - val_auc: 0.9997\n",
      "Epoch 21/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0230 - acc: 0.9922 - auc: 0.9987 - val_loss: 0.0090 - val_acc: 0.9976 - val_auc: 0.9998\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0233 - acc: 0.9922 - auc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9977 - val_auc: 0.9998\n",
      "Epoch 23/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0200 - acc: 0.9934 - auc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9979 - val_auc: 0.9997\n",
      "Epoch 24/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0196 - acc: 0.9936 - auc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9976 - val_auc: 0.9997\n",
      "Epoch 25/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0185 - acc: 0.9938 - auc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9977 - val_auc: 0.9997\n",
      "Epoch 26/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0180 - acc: 0.9939 - auc: 0.9992 - val_loss: 0.0077 - val_acc: 0.9984 - val_auc: 0.9998\n",
      "Epoch 27/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0186 - acc: 0.9939 - auc: 0.9991 - val_loss: 0.0081 - val_acc: 0.9982 - val_auc: 0.9998\n",
      "Epoch 28/30\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0167 - acc: 0.9944 - auc: 0.9993 - val_loss: 0.0076 - val_acc: 0.9984 - val_auc: 0.9999\n",
      "Epoch 29/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0155 - acc: 0.9949 - auc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9981 - val_auc: 0.9998\n",
      "Epoch 30/30\n",
      "144000/144000 [==============================] - 7s 51us/step - loss: 0.0167 - acc: 0.9944 - auc: 0.9993 - val_loss: 0.0078 - val_acc: 0.9979 - val_auc: 0.9997\n",
      "Run time 18.489072207609812 min\n"
     ]
    }
   ],
   "source": [
    "secquential_nn_model_min_1_2 = train_nn(train_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, sequential_nn_model_min_1_2, batch_size=512, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 58us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = sequential_nn_model_min_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7743384547904134, 0.8839750011265278, 0.7216513503802012]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_2.save('secquential_nn_model_min_1_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_4_1_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/20\n",
      "144000/144000 [==============================] - 13s 87us/step - loss: 0.3272 - acc: 0.8863 - auc: 0.6773 - val_loss: 0.5150 - val_acc: 0.8995 - val_auc: 0.7455\n",
      "Epoch 2/20\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2959 - acc: 0.8994 - auc: 0.7300 - val_loss: 0.2961 - val_acc: 0.8995 - val_auc: 0.7359\n",
      "Epoch 3/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2908 - acc: 0.8995 - auc: 0.7445 - val_loss: 0.3077 - val_acc: 0.8995 - val_auc: 0.7623\n",
      "Epoch 4/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2898 - acc: 0.9002 - auc: 0.7407 - val_loss: 0.2853 - val_acc: 0.8995 - val_auc: 0.7690\n",
      "Epoch 5/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2870 - acc: 0.9008 - auc: 0.7470 - val_loss: 0.2909 - val_acc: 0.8987 - val_auc: 0.7679\n",
      "Epoch 6/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2858 - acc: 0.9014 - auc: 0.7513 - val_loss: 0.2820 - val_acc: 0.9014 - val_auc: 0.7692\n",
      "Epoch 7/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2846 - acc: 0.9020 - auc: 0.7538 - val_loss: 0.2871 - val_acc: 0.9005 - val_auc: 0.7709\n",
      "Epoch 8/20\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2839 - acc: 0.9017 - auc: 0.7562 - val_loss: 0.2833 - val_acc: 0.9005 - val_auc: 0.7744\n",
      "Epoch 9/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2833 - acc: 0.9019 - auc: 0.7569 - val_loss: 0.2901 - val_acc: 0.8923 - val_auc: 0.7762\n",
      "Epoch 10/20\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2821 - acc: 0.9021 - auc: 0.7598 - val_loss: 0.3693 - val_acc: 0.8203 - val_auc: 0.7645\n",
      "Epoch 11/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2817 - acc: 0.9020 - auc: 0.7603 - val_loss: 0.3100 - val_acc: 0.8938 - val_auc: 0.7767\n",
      "Epoch 12/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2815 - acc: 0.9019 - auc: 0.7616 - val_loss: 0.2867 - val_acc: 0.9031 - val_auc: 0.7757\n",
      "Epoch 13/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2814 - acc: 0.9022 - auc: 0.7619 - val_loss: 0.3705 - val_acc: 0.8271 - val_auc: 0.7750\n",
      "Epoch 14/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2807 - acc: 0.9023 - auc: 0.7633 - val_loss: 0.3829 - val_acc: 0.8584 - val_auc: 0.7783\n",
      "Epoch 15/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2797 - acc: 0.9025 - auc: 0.7657 - val_loss: 0.3372 - val_acc: 0.8920 - val_auc: 0.7793\n",
      "Epoch 16/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2799 - acc: 0.9030 - auc: 0.7650 - val_loss: 0.7544 - val_acc: 0.5857 - val_auc: 0.7727\n",
      "Epoch 17/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2792 - acc: 0.9025 - auc: 0.7669 - val_loss: 0.4256 - val_acc: 0.8007 - val_auc: 0.7770\n",
      "Epoch 18/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2789 - acc: 0.9026 - auc: 0.7674 - val_loss: 0.6430 - val_acc: 0.7041 - val_auc: 0.7791\n",
      "Epoch 19/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2791 - acc: 0.9026 - auc: 0.7673 - val_loss: 0.2773 - val_acc: 0.9022 - val_auc: 0.7760\n",
      "Epoch 20/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2782 - acc: 0.9029 - auc: 0.7681 - val_loss: 0.2786 - val_acc: 0.9022 - val_auc: 0.7782\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2819 - acc: 0.9019 - auc: 0.7617 - val_loss: 0.2996 - val_acc: 0.8936 - val_auc: 0.7813\n",
      "Epoch 2/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2823 - acc: 0.9013 - auc: 0.7605 - val_loss: 0.5228 - val_acc: 0.8995 - val_auc: 0.7806\n",
      "Epoch 3/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2811 - acc: 0.9023 - auc: 0.7636 - val_loss: 0.5345 - val_acc: 0.7186 - val_auc: 0.7488\n",
      "Epoch 4/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2802 - acc: 0.9024 - auc: 0.7650 - val_loss: 0.6723 - val_acc: 0.5629 - val_auc: 0.7014\n",
      "Epoch 5/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2811 - acc: 0.9016 - auc: 0.7639 - val_loss: 0.2741 - val_acc: 0.9051 - val_auc: 0.7827\n",
      "Epoch 6/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2805 - acc: 0.9023 - auc: 0.7640 - val_loss: 0.3530 - val_acc: 0.9049 - val_auc: 0.7818\n",
      "Epoch 7/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2802 - acc: 0.9023 - auc: 0.7649 - val_loss: 0.4088 - val_acc: 0.7957 - val_auc: 0.7816\n",
      "Epoch 8/20\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2791 - acc: 0.9023 - auc: 0.7682 - val_loss: 0.2982 - val_acc: 0.8996 - val_auc: 0.7827\n",
      "Epoch 9/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2789 - acc: 0.9025 - auc: 0.7680 - val_loss: 0.3119 - val_acc: 0.9006 - val_auc: 0.7823\n",
      "Epoch 10/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2791 - acc: 0.9023 - auc: 0.7673 - val_loss: 0.2801 - val_acc: 0.9038 - val_auc: 0.7816\n",
      "Epoch 11/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2784 - acc: 0.9027 - auc: 0.7691 - val_loss: 0.3893 - val_acc: 0.8739 - val_auc: 0.7841\n",
      "Epoch 12/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2782 - acc: 0.9031 - auc: 0.7697 - val_loss: 0.2900 - val_acc: 0.8985 - val_auc: 0.7841\n",
      "Epoch 13/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2782 - acc: 0.9029 - auc: 0.7689 - val_loss: 0.3383 - val_acc: 0.8683 - val_auc: 0.7847\n",
      "Epoch 14/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2771 - acc: 0.9033 - auc: 0.7718 - val_loss: 0.7461 - val_acc: 0.4242 - val_auc: 0.7768\n",
      "Epoch 15/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2775 - acc: 0.9031 - auc: 0.7707 - val_loss: 0.3770 - val_acc: 0.8565 - val_auc: 0.7832\n",
      "Epoch 16/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2773 - acc: 0.9033 - auc: 0.7704 - val_loss: 0.8834 - val_acc: 0.3744 - val_auc: 0.7856\n",
      "Epoch 17/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2766 - acc: 0.9031 - auc: 0.7728 - val_loss: 0.3058 - val_acc: 0.8827 - val_auc: 0.7826\n",
      "Epoch 18/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2768 - acc: 0.9028 - auc: 0.7726 - val_loss: 0.4350 - val_acc: 0.8499 - val_auc: 0.7826\n",
      "Epoch 19/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2763 - acc: 0.9033 - auc: 0.7731 - val_loss: 0.4139 - val_acc: 0.7906 - val_auc: 0.7862\n",
      "Epoch 20/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2769 - acc: 0.9031 - auc: 0.7723 - val_loss: 0.4176 - val_acc: 0.8584 - val_auc: 0.7847\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2806 - acc: 0.9025 - auc: 0.7646 - val_loss: 0.3762 - val_acc: 0.8515 - val_auc: 0.7815\n",
      "Epoch 2/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2799 - acc: 0.9027 - auc: 0.7662 - val_loss: 0.3036 - val_acc: 0.9060 - val_auc: 0.7820\n",
      "Epoch 3/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2793 - acc: 0.9023 - auc: 0.7672 - val_loss: 0.3735 - val_acc: 0.7982 - val_auc: 0.7818\n",
      "Epoch 4/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2796 - acc: 0.9021 - auc: 0.7680 - val_loss: 0.3094 - val_acc: 0.8864 - val_auc: 0.7827\n",
      "Epoch 5/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2792 - acc: 0.9021 - auc: 0.7681 - val_loss: 0.4070 - val_acc: 0.8753 - val_auc: 0.7772\n",
      "Epoch 6/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2789 - acc: 0.9028 - auc: 0.7683 - val_loss: 0.2801 - val_acc: 0.9022 - val_auc: 0.7829\n",
      "Epoch 7/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2783 - acc: 0.9030 - auc: 0.7689 - val_loss: 0.3015 - val_acc: 0.9054 - val_auc: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2785 - acc: 0.9030 - auc: 0.7690 - val_loss: 0.2762 - val_acc: 0.9034 - val_auc: 0.7826\n",
      "Epoch 9/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2791 - acc: 0.9026 - auc: 0.7679 - val_loss: 0.2943 - val_acc: 0.9023 - val_auc: 0.7830\n",
      "Epoch 10/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2781 - acc: 0.9035 - auc: 0.7693 - val_loss: 0.3544 - val_acc: 0.8635 - val_auc: 0.7809\n",
      "Epoch 11/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2770 - acc: 0.9034 - auc: 0.7728 - val_loss: 0.3069 - val_acc: 0.9045 - val_auc: 0.7838\n",
      "Epoch 12/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2773 - acc: 0.9033 - auc: 0.7703 - val_loss: 0.3613 - val_acc: 0.8767 - val_auc: 0.7828\n",
      "Epoch 13/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2769 - acc: 0.9036 - auc: 0.7715 - val_loss: 0.3852 - val_acc: 0.8011 - val_auc: 0.7841\n",
      "Epoch 14/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2764 - acc: 0.9034 - auc: 0.7738 - val_loss: 0.4381 - val_acc: 0.7855 - val_auc: 0.7842\n",
      "Epoch 15/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2766 - acc: 0.9031 - auc: 0.7731 - val_loss: 0.5122 - val_acc: 0.7114 - val_auc: 0.7845\n",
      "Epoch 16/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2762 - acc: 0.9030 - auc: 0.7735 - val_loss: 0.4190 - val_acc: 0.7923 - val_auc: 0.7857\n",
      "Epoch 17/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2757 - acc: 0.9033 - auc: 0.7748 - val_loss: 0.5026 - val_acc: 0.8169 - val_auc: 0.7864\n",
      "Epoch 18/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2755 - acc: 0.9036 - auc: 0.7744 - val_loss: 0.7391 - val_acc: 0.5445 - val_auc: 0.7811\n",
      "Epoch 19/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2759 - acc: 0.9035 - auc: 0.7742 - val_loss: 0.3642 - val_acc: 0.8601 - val_auc: 0.7855\n",
      "Epoch 20/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2752 - acc: 0.9038 - auc: 0.7766 - val_loss: 0.6910 - val_acc: 0.5384 - val_auc: 0.6782\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2785 - acc: 0.9029 - auc: 0.7681 - val_loss: 0.3197 - val_acc: 0.8995 - val_auc: 0.7889\n",
      "Epoch 2/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2803 - acc: 0.9027 - auc: 0.7640 - val_loss: 0.4391 - val_acc: 0.7376 - val_auc: 0.7852\n",
      "Epoch 3/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2786 - acc: 0.9029 - auc: 0.7681 - val_loss: 0.2878 - val_acc: 0.8998 - val_auc: 0.7884\n",
      "Epoch 4/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2797 - acc: 0.9018 - auc: 0.7662 - val_loss: 0.3339 - val_acc: 0.8925 - val_auc: 0.7889\n",
      "Epoch 5/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2794 - acc: 0.9022 - auc: 0.7662 - val_loss: 0.7142 - val_acc: 0.7536 - val_auc: 0.7607\n",
      "Epoch 6/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2788 - acc: 0.9035 - auc: 0.7675 - val_loss: 1.7510 - val_acc: 0.1092 - val_auc: 0.3546\n",
      "Epoch 7/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2828 - acc: 0.9022 - auc: 0.7557 - val_loss: 0.2975 - val_acc: 0.8864 - val_auc: 0.7688\n",
      "Epoch 8/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2795 - acc: 0.9032 - auc: 0.7661 - val_loss: 0.4480 - val_acc: 0.7929 - val_auc: 0.7863\n",
      "Epoch 9/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2786 - acc: 0.9026 - auc: 0.7686 - val_loss: 0.4596 - val_acc: 0.6805 - val_auc: 0.7255\n",
      "Epoch 10/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2776 - acc: 0.9030 - auc: 0.7702 - val_loss: 0.3825 - val_acc: 0.8079 - val_auc: 0.7823\n",
      "Epoch 11/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2773 - acc: 0.9036 - auc: 0.7706 - val_loss: 0.3161 - val_acc: 0.8942 - val_auc: 0.7895\n",
      "Epoch 12/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2764 - acc: 0.9041 - auc: 0.7713 - val_loss: 0.4184 - val_acc: 0.7648 - val_auc: 0.7758\n",
      "Epoch 13/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2769 - acc: 0.9037 - auc: 0.7714 - val_loss: 0.2785 - val_acc: 0.9021 - val_auc: 0.7885\n",
      "Epoch 14/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2761 - acc: 0.9043 - auc: 0.7725 - val_loss: 0.3428 - val_acc: 0.8670 - val_auc: 0.7887\n",
      "Epoch 15/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2761 - acc: 0.9042 - auc: 0.7730 - val_loss: 0.2782 - val_acc: 0.9019 - val_auc: 0.7908\n",
      "Epoch 16/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2761 - acc: 0.9040 - auc: 0.7733 - val_loss: 0.7686 - val_acc: 0.3874 - val_auc: 0.7251\n",
      "Epoch 17/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2758 - acc: 0.9039 - auc: 0.7738 - val_loss: 0.3045 - val_acc: 0.8951 - val_auc: 0.7903\n",
      "Epoch 18/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2749 - acc: 0.9044 - auc: 0.7756 - val_loss: 0.6899 - val_acc: 0.5766 - val_auc: 0.7434\n",
      "Epoch 19/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2754 - acc: 0.9036 - auc: 0.7747 - val_loss: 0.3298 - val_acc: 0.8951 - val_auc: 0.7911\n",
      "Epoch 20/20\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2752 - acc: 0.9040 - auc: 0.7743 - val_loss: 0.4701 - val_acc: 0.7986 - val_auc: 0.7905\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/20\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2796 - acc: 0.9026 - auc: 0.7670 - val_loss: 0.2751 - val_acc: 0.9029 - val_auc: 0.7828\n",
      "Epoch 2/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2793 - acc: 0.9024 - auc: 0.7669 - val_loss: 0.4003 - val_acc: 0.8263 - val_auc: 0.7799\n",
      "Epoch 3/20\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2789 - acc: 0.9028 - auc: 0.7677 - val_loss: 0.3963 - val_acc: 0.8611 - val_auc: 0.7847\n",
      "Epoch 4/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2788 - acc: 0.9026 - auc: 0.7681 - val_loss: 0.5577 - val_acc: 0.6614 - val_auc: 0.7471\n",
      "Epoch 5/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2789 - acc: 0.9020 - auc: 0.7687 - val_loss: 0.4156 - val_acc: 0.7971 - val_auc: 0.7767\n",
      "Epoch 6/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2789 - acc: 0.9026 - auc: 0.7691 - val_loss: 0.2746 - val_acc: 0.9040 - val_auc: 0.7825\n",
      "Epoch 7/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2776 - acc: 0.9027 - auc: 0.7718 - val_loss: 0.3017 - val_acc: 0.9030 - val_auc: 0.7830\n",
      "Epoch 8/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2775 - acc: 0.9035 - auc: 0.7714 - val_loss: 0.2883 - val_acc: 0.9033 - val_auc: 0.7873\n",
      "Epoch 9/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2774 - acc: 0.9026 - auc: 0.7712 - val_loss: 0.4843 - val_acc: 0.9023 - val_auc: 0.7803\n",
      "Epoch 10/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2775 - acc: 0.9028 - auc: 0.7710 - val_loss: 0.5344 - val_acc: 0.6927 - val_auc: 0.7694\n",
      "Epoch 11/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2768 - acc: 0.9035 - auc: 0.7729 - val_loss: 0.4286 - val_acc: 0.8328 - val_auc: 0.7795\n",
      "Epoch 12/20\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2772 - acc: 0.9032 - auc: 0.7715 - val_loss: 0.5401 - val_acc: 0.7296 - val_auc: 0.7862\n",
      "Epoch 13/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2763 - acc: 0.9035 - auc: 0.7735 - val_loss: 0.4017 - val_acc: 0.8450 - val_auc: 0.7871\n",
      "Epoch 14/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2772 - acc: 0.9034 - auc: 0.7714 - val_loss: 0.4041 - val_acc: 0.8268 - val_auc: 0.7877\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2758 - acc: 0.9033 - auc: 0.7753 - val_loss: 0.4366 - val_acc: 0.7819 - val_auc: 0.7875\n",
      "Epoch 16/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2757 - acc: 0.9039 - auc: 0.7746 - val_loss: 0.2936 - val_acc: 0.8999 - val_auc: 0.7851\n",
      "Epoch 17/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2759 - acc: 0.9035 - auc: 0.7746 - val_loss: 0.2845 - val_acc: 0.9003 - val_auc: 0.7872\n",
      "Epoch 18/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2746 - acc: 0.9037 - auc: 0.7767 - val_loss: 0.2797 - val_acc: 0.9051 - val_auc: 0.7880\n",
      "Epoch 19/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2748 - acc: 0.9040 - auc: 0.7762 - val_loss: 0.2974 - val_acc: 0.8868 - val_auc: 0.7877\n",
      "Epoch 20/20\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2745 - acc: 0.9040 - auc: 0.7772 - val_loss: 0.5621 - val_acc: 0.6321 - val_auc: 0.7875\n",
      "Run time 14.411114724477132 min\n"
     ]
    }
   ],
   "source": [
    "sequential_nn_model_min_1_4_1_2 = train_nn(train_polinomial_values_ucm_1_4_1_2, train_target_values_ucm_1_4_1_2, sequential_nn_model, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 54us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = sequential_nn_model_min_1_4_1_2.evaluate(holdout_test_polinomial_values_ucm_1_4_1_2, holdout_test_target_values_ucm_1_4_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5642809407413005, 0.6279249995946884, 0.7807801920109606]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2794 - acc: 0.9022 - auc: 0.7672 - val_loss: 0.3033 - val_acc: 0.8971 - val_auc: 0.7774\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2837 - acc: 0.9014 - auc: 0.7555 - val_loss: 0.6129 - val_acc: 0.7759 - val_auc: 0.7805\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2820 - acc: 0.9020 - auc: 0.7604 - val_loss: 0.4146 - val_acc: 0.8995 - val_auc: 0.2637\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2809 - acc: 0.9015 - auc: 0.7623 - val_loss: 0.5426 - val_acc: 0.7528 - val_auc: 0.7565\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2781 - acc: 0.9018 - auc: 0.7716 - val_loss: 0.2886 - val_acc: 0.9032 - val_auc: 0.7760\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2782 - acc: 0.9026 - auc: 0.7692 - val_loss: 0.2731 - val_acc: 0.9051 - val_auc: 0.7830\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2805 - acc: 0.9014 - auc: 0.7649 - val_loss: 0.6009 - val_acc: 0.6393 - val_auc: 0.7810\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2786 - acc: 0.9022 - auc: 0.7697 - val_loss: 0.6936 - val_acc: 0.6489 - val_auc: 0.7716\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2774 - acc: 0.9026 - auc: 0.7716 - val_loss: 0.4208 - val_acc: 0.7710 - val_auc: 0.7822\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2772 - acc: 0.9032 - auc: 0.7718 - val_loss: 1.0896 - val_acc: 0.1674 - val_auc: 0.7188\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2782 - acc: 0.9020 - auc: 0.7704 - val_loss: 0.3547 - val_acc: 0.9006 - val_auc: 0.7816\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2770 - acc: 0.9027 - auc: 0.7719 - val_loss: 0.6738 - val_acc: 0.6398 - val_auc: 0.7811\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 9s 62us/step - loss: 0.2768 - acc: 0.9027 - auc: 0.7724 - val_loss: 0.2791 - val_acc: 0.9011 - val_auc: 0.7835\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2768 - acc: 0.9032 - auc: 0.7727 - val_loss: 0.4111 - val_acc: 0.8187 - val_auc: 0.7827\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2763 - acc: 0.9025 - auc: 0.7745 - val_loss: 0.3768 - val_acc: 0.8413 - val_auc: 0.7787\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 9s 62us/step - loss: 0.2765 - acc: 0.9036 - auc: 0.7737 - val_loss: 0.2849 - val_acc: 0.9054 - val_auc: 0.7809\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2761 - acc: 0.9032 - auc: 0.7742 - val_loss: 0.3350 - val_acc: 0.8801 - val_auc: 0.7756\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2753 - acc: 0.9038 - auc: 0.7752 - val_loss: 1.1625 - val_acc: 0.1395 - val_auc: 0.6178\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2754 - acc: 0.9036 - auc: 0.7753 - val_loss: 0.4288 - val_acc: 0.8468 - val_auc: 0.7833\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2748 - acc: 0.9041 - auc: 0.7764 - val_loss: 0.4808 - val_acc: 0.7027 - val_auc: 0.7807\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2747 - acc: 0.9038 - auc: 0.7772 - val_loss: 0.2723 - val_acc: 0.9051 - val_auc: 0.7809\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2743 - acc: 0.9043 - auc: 0.7778 - val_loss: 0.3087 - val_acc: 0.8924 - val_auc: 0.7824\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2746 - acc: 0.9041 - auc: 0.7764 - val_loss: 0.8464 - val_acc: 0.4214 - val_auc: 0.7842\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2735 - acc: 0.9042 - auc: 0.7801 - val_loss: 0.2783 - val_acc: 0.9054 - val_auc: 0.7825\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 9s 62us/step - loss: 0.2738 - acc: 0.9040 - auc: 0.7787 - val_loss: 0.3078 - val_acc: 0.8935 - val_auc: 0.7838\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2734 - acc: 0.9042 - auc: 0.7801 - val_loss: 0.3613 - val_acc: 0.8609 - val_auc: 0.7798\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2736 - acc: 0.9045 - auc: 0.7787 - val_loss: 0.3869 - val_acc: 0.8269 - val_auc: 0.7841\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2737 - acc: 0.9039 - auc: 0.7788 - val_loss: 0.5325 - val_acc: 0.7023 - val_auc: 0.7828\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2737 - acc: 0.9040 - auc: 0.7789 - val_loss: 0.4199 - val_acc: 0.7955 - val_auc: 0.7830\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2737 - acc: 0.9041 - auc: 0.7793 - val_loss: 0.7089 - val_acc: 0.5706 - val_auc: 0.7813\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2739 - acc: 0.9036 - auc: 0.7794 - val_loss: 0.3156 - val_acc: 0.8754 - val_auc: 0.7828\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2731 - acc: 0.9040 - auc: 0.7799 - val_loss: 0.3349 - val_acc: 0.8978 - val_auc: 0.7853\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2726 - acc: 0.9046 - auc: 0.7802 - val_loss: 0.3672 - val_acc: 0.8632 - val_auc: 0.7837\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2734 - acc: 0.9040 - auc: 0.7797 - val_loss: 0.3959 - val_acc: 0.8305 - val_auc: 0.7836\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2729 - acc: 0.9044 - auc: 0.7797 - val_loss: 0.4560 - val_acc: 0.7719 - val_auc: 0.7825\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2727 - acc: 0.9044 - auc: 0.7805 - val_loss: 0.4884 - val_acc: 0.7168 - val_auc: 0.7819\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2728 - acc: 0.9044 - auc: 0.7809 - val_loss: 0.3027 - val_acc: 0.8921 - val_auc: 0.7852\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2728 - acc: 0.9047 - auc: 0.7809 - val_loss: 0.3090 - val_acc: 0.8850 - val_auc: 0.7863\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2720 - acc: 0.9045 - auc: 0.7827 - val_loss: 0.4189 - val_acc: 0.8256 - val_auc: 0.7847\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2721 - acc: 0.9042 - auc: 0.7828 - val_loss: 0.4959 - val_acc: 0.7562 - val_auc: 0.7843\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2717 - acc: 0.9047 - auc: 0.7838 - val_loss: 0.4212 - val_acc: 0.8321 - val_auc: 0.7814\n",
      "Epoch 42/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2723 - acc: 0.9045 - auc: 0.7823 - val_loss: 0.3231 - val_acc: 0.8801 - val_auc: 0.7844\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2723 - acc: 0.9048 - auc: 0.7812 - val_loss: 0.3513 - val_acc: 0.8604 - val_auc: 0.7850\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2712 - acc: 0.9051 - auc: 0.7843 - val_loss: 0.5904 - val_acc: 0.6869 - val_auc: 0.7684\n",
      "Epoch 45/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2717 - acc: 0.9046 - auc: 0.7829 - val_loss: 0.3079 - val_acc: 0.8918 - val_auc: 0.7844\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2719 - acc: 0.9049 - auc: 0.7822 - val_loss: 0.3867 - val_acc: 0.8356 - val_auc: 0.7858\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2718 - acc: 0.9046 - auc: 0.7831 - val_loss: 0.3637 - val_acc: 0.8504 - val_auc: 0.7849\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2720 - acc: 0.9044 - auc: 0.7826 - val_loss: 0.4078 - val_acc: 0.8071 - val_auc: 0.7836\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2713 - acc: 0.9049 - auc: 0.7841 - val_loss: 0.3420 - val_acc: 0.8689 - val_auc: 0.7851\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2722 - acc: 0.9049 - auc: 0.7820 - val_loss: 0.3936 - val_acc: 0.8155 - val_auc: 0.7846\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2785 - acc: 0.9020 - auc: 0.7689 - val_loss: 0.2797 - val_acc: 0.8952 - val_auc: 0.7827\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2797 - acc: 0.9012 - auc: 0.7662 - val_loss: 0.5063 - val_acc: 0.7407 - val_auc: 0.7810\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2784 - acc: 0.9018 - auc: 0.7696 - val_loss: 0.2786 - val_acc: 0.8997 - val_auc: 0.7826\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2783 - acc: 0.9025 - auc: 0.7690 - val_loss: 0.9237 - val_acc: 0.2981 - val_auc: 0.7691\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2791 - acc: 0.9019 - auc: 0.7681 - val_loss: 0.2791 - val_acc: 0.9025 - val_auc: 0.7770\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2781 - acc: 0.9019 - auc: 0.7702 - val_loss: 0.2790 - val_acc: 0.9024 - val_auc: 0.7855\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2778 - acc: 0.9020 - auc: 0.7705 - val_loss: 0.3516 - val_acc: 0.8996 - val_auc: 0.7827\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2779 - acc: 0.9025 - auc: 0.7703 - val_loss: 0.4473 - val_acc: 0.7977 - val_auc: 0.7874\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2770 - acc: 0.9038 - auc: 0.7704 - val_loss: 0.2864 - val_acc: 0.9041 - val_auc: 0.7842\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2761 - acc: 0.9037 - auc: 0.7735 - val_loss: 0.2776 - val_acc: 0.8986 - val_auc: 0.7863\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2764 - acc: 0.9036 - auc: 0.7730 - val_loss: 0.4007 - val_acc: 0.8150 - val_auc: 0.7877\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2757 - acc: 0.9039 - auc: 0.7735 - val_loss: 1.0272 - val_acc: 0.3574 - val_auc: 0.6960\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2760 - acc: 0.9033 - auc: 0.7732 - val_loss: 0.7151 - val_acc: 0.5623 - val_auc: 0.7541\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2759 - acc: 0.9027 - auc: 0.7751 - val_loss: 0.5728 - val_acc: 0.6959 - val_auc: 0.7888\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2756 - acc: 0.9030 - auc: 0.7768 - val_loss: 0.3713 - val_acc: 0.8381 - val_auc: 0.7881\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2756 - acc: 0.9033 - auc: 0.7750 - val_loss: 0.4320 - val_acc: 0.8136 - val_auc: 0.7810\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2755 - acc: 0.9036 - auc: 0.7754 - val_loss: 0.2933 - val_acc: 0.8889 - val_auc: 0.7878\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2747 - acc: 0.9041 - auc: 0.7765 - val_loss: 0.4152 - val_acc: 0.8358 - val_auc: 0.7876\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2740 - acc: 0.9042 - auc: 0.7790 - val_loss: 0.4366 - val_acc: 0.8187 - val_auc: 0.7884\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2747 - acc: 0.9041 - auc: 0.7768 - val_loss: 0.4688 - val_acc: 0.7675 - val_auc: 0.7894\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2750 - acc: 0.9037 - auc: 0.7768 - val_loss: 0.7079 - val_acc: 0.6338 - val_auc: 0.7882\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2742 - acc: 0.9041 - auc: 0.7780 - val_loss: 0.2845 - val_acc: 0.9009 - val_auc: 0.7865\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2751 - acc: 0.9037 - auc: 0.7757 - val_loss: 0.6824 - val_acc: 0.5564 - val_auc: 0.7895\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2737 - acc: 0.9045 - auc: 0.7783 - val_loss: 0.7817 - val_acc: 0.5363 - val_auc: 0.7871\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2732 - acc: 0.9051 - auc: 0.7791 - val_loss: 0.3419 - val_acc: 0.8881 - val_auc: 0.7910\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2730 - acc: 0.9046 - auc: 0.7796 - val_loss: 0.2850 - val_acc: 0.9031 - val_auc: 0.7874\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2738 - acc: 0.9041 - auc: 0.7785 - val_loss: 0.5633 - val_acc: 0.6846 - val_auc: 0.7915\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2731 - acc: 0.9044 - auc: 0.7793 - val_loss: 0.5071 - val_acc: 0.7251 - val_auc: 0.7887\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2730 - acc: 0.9047 - auc: 0.7805 - val_loss: 0.7142 - val_acc: 0.5657 - val_auc: 0.7865\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2721 - acc: 0.9047 - auc: 0.7820 - val_loss: 0.3944 - val_acc: 0.8364 - val_auc: 0.7887\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2722 - acc: 0.9046 - auc: 0.7825 - val_loss: 0.3251 - val_acc: 0.8896 - val_auc: 0.7915\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2717 - acc: 0.9048 - auc: 0.7833 - val_loss: 0.3634 - val_acc: 0.8629 - val_auc: 0.7900\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2720 - acc: 0.9046 - auc: 0.7819 - val_loss: 0.2741 - val_acc: 0.9046 - val_auc: 0.7897\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2726 - acc: 0.9047 - auc: 0.7807 - val_loss: 0.5094 - val_acc: 0.7264 - val_auc: 0.7876\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2717 - acc: 0.9046 - auc: 0.7823 - val_loss: 0.3850 - val_acc: 0.8464 - val_auc: 0.7899\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2722 - acc: 0.9047 - auc: 0.7817 - val_loss: 0.2941 - val_acc: 0.8972 - val_auc: 0.7912\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2723 - acc: 0.9048 - auc: 0.7808 - val_loss: 0.4432 - val_acc: 0.7966 - val_auc: 0.7906\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2719 - acc: 0.9050 - auc: 0.7817 - val_loss: 0.6141 - val_acc: 0.6102 - val_auc: 0.7914\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2721 - acc: 0.9047 - auc: 0.7819 - val_loss: 0.6487 - val_acc: 0.6031 - val_auc: 0.7915\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2722 - acc: 0.9046 - auc: 0.7821 - val_loss: 0.4844 - val_acc: 0.7853 - val_auc: 0.7918\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2721 - acc: 0.9045 - auc: 0.7817 - val_loss: 0.6067 - val_acc: 0.6705 - val_auc: 0.7915\n",
      "Epoch 42/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2726 - acc: 0.9044 - auc: 0.7807 - val_loss: 0.3913 - val_acc: 0.8176 - val_auc: 0.7916\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2723 - acc: 0.9044 - auc: 0.7818 - val_loss: 0.3639 - val_acc: 0.8455 - val_auc: 0.7909\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2713 - acc: 0.9050 - auc: 0.7834 - val_loss: 0.3962 - val_acc: 0.8257 - val_auc: 0.7934\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2719 - acc: 0.9050 - auc: 0.7825 - val_loss: 0.3304 - val_acc: 0.8698 - val_auc: 0.7927\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2712 - acc: 0.9049 - auc: 0.7836 - val_loss: 0.4025 - val_acc: 0.8293 - val_auc: 0.7924\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2708 - acc: 0.9050 - auc: 0.7848 - val_loss: 0.4965 - val_acc: 0.7257 - val_auc: 0.7927\n",
      "Epoch 48/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2712 - acc: 0.9051 - auc: 0.7837 - val_loss: 0.3558 - val_acc: 0.8525 - val_auc: 0.7925\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2714 - acc: 0.9048 - auc: 0.7837 - val_loss: 0.4796 - val_acc: 0.7676 - val_auc: 0.7919\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2713 - acc: 0.9048 - auc: 0.7832 - val_loss: 0.4180 - val_acc: 0.8081 - val_auc: 0.7925\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2790 - acc: 0.9032 - auc: 0.7679 - val_loss: 0.3681 - val_acc: 0.8996 - val_auc: 0.7828\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2794 - acc: 0.9025 - auc: 0.7667 - val_loss: 0.7199 - val_acc: 0.4763 - val_auc: 0.7777\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2785 - acc: 0.9029 - auc: 0.7695 - val_loss: 0.3357 - val_acc: 0.8995 - val_auc: 0.7752\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2791 - acc: 0.9029 - auc: 0.7648 - val_loss: 0.2845 - val_acc: 0.8998 - val_auc: 0.7833\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2776 - acc: 0.9029 - auc: 0.7700 - val_loss: 0.7865 - val_acc: 0.5826 - val_auc: 0.6987\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2791 - acc: 0.9027 - auc: 0.7679 - val_loss: 0.9767 - val_acc: 0.1760 - val_auc: 0.6740\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2780 - acc: 0.9032 - auc: 0.7701 - val_loss: 0.4292 - val_acc: 0.7409 - val_auc: 0.7811\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2783 - acc: 0.9025 - auc: 0.7696 - val_loss: 0.2950 - val_acc: 0.8992 - val_auc: 0.7828\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2792 - acc: 0.9025 - auc: 0.7661 - val_loss: 0.6446 - val_acc: 0.5141 - val_auc: 0.7786\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2781 - acc: 0.9029 - auc: 0.7698 - val_loss: 0.4264 - val_acc: 0.7658 - val_auc: 0.7836\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2770 - acc: 0.9029 - auc: 0.7715 - val_loss: 0.3188 - val_acc: 0.8876 - val_auc: 0.7886\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2759 - acc: 0.9027 - auc: 0.7751 - val_loss: 0.2861 - val_acc: 0.9018 - val_auc: 0.7869\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2764 - acc: 0.9034 - auc: 0.7722 - val_loss: 0.6876 - val_acc: 0.5576 - val_auc: 0.7294\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2759 - acc: 0.9038 - auc: 0.7745 - val_loss: 0.3412 - val_acc: 0.8602 - val_auc: 0.7897\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2749 - acc: 0.9035 - auc: 0.7757 - val_loss: 0.4549 - val_acc: 0.7570 - val_auc: 0.7817\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2759 - acc: 0.9035 - auc: 0.7739 - val_loss: 0.3088 - val_acc: 0.8612 - val_auc: 0.7894\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2756 - acc: 0.9033 - auc: 0.7754 - val_loss: 0.4023 - val_acc: 0.8617 - val_auc: 0.7876\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2747 - acc: 0.9037 - auc: 0.7766 - val_loss: 0.9552 - val_acc: 0.2811 - val_auc: 0.6331\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2741 - acc: 0.9037 - auc: 0.7787 - val_loss: 0.4172 - val_acc: 0.7938 - val_auc: 0.7895\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2751 - acc: 0.9041 - auc: 0.7760 - val_loss: 0.4252 - val_acc: 0.7504 - val_auc: 0.7844\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2757 - acc: 0.9037 - auc: 0.7760 - val_loss: 0.2866 - val_acc: 0.8996 - val_auc: 0.7902\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2747 - acc: 0.9042 - auc: 0.7760 - val_loss: 0.3644 - val_acc: 0.8493 - val_auc: 0.7859\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2743 - acc: 0.9045 - auc: 0.7777 - val_loss: 0.5856 - val_acc: 0.6657 - val_auc: 0.7417\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2737 - acc: 0.9044 - auc: 0.7787 - val_loss: 0.3919 - val_acc: 0.8426 - val_auc: 0.7845\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2741 - acc: 0.9045 - auc: 0.7777 - val_loss: 0.4326 - val_acc: 0.8061 - val_auc: 0.7889\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2740 - acc: 0.9039 - auc: 0.7784 - val_loss: 0.4069 - val_acc: 0.8229 - val_auc: 0.7897\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2737 - acc: 0.9044 - auc: 0.7796 - val_loss: 0.5181 - val_acc: 0.7012 - val_auc: 0.7740\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2742 - acc: 0.9037 - auc: 0.7786 - val_loss: 0.2795 - val_acc: 0.8981 - val_auc: 0.7897\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2738 - acc: 0.9045 - auc: 0.7787 - val_loss: 0.3181 - val_acc: 0.8858 - val_auc: 0.7931\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2731 - acc: 0.9046 - auc: 0.7797 - val_loss: 0.3871 - val_acc: 0.8559 - val_auc: 0.7892\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2729 - acc: 0.9048 - auc: 0.7801 - val_loss: 0.3870 - val_acc: 0.8478 - val_auc: 0.7915\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2729 - acc: 0.9049 - auc: 0.7796 - val_loss: 0.5578 - val_acc: 0.7233 - val_auc: 0.7828\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2733 - acc: 0.9040 - auc: 0.7795 - val_loss: 0.3325 - val_acc: 0.8878 - val_auc: 0.7922\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2726 - acc: 0.9044 - auc: 0.7808 - val_loss: 0.3937 - val_acc: 0.8325 - val_auc: 0.7903\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2726 - acc: 0.9045 - auc: 0.7812 - val_loss: 0.5289 - val_acc: 0.7114 - val_auc: 0.7835\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2727 - acc: 0.9048 - auc: 0.7812 - val_loss: 0.5369 - val_acc: 0.6853 - val_auc: 0.7700\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2728 - acc: 0.9045 - auc: 0.7812 - val_loss: 0.3135 - val_acc: 0.8966 - val_auc: 0.7929\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2727 - acc: 0.9049 - auc: 0.7809 - val_loss: 0.3901 - val_acc: 0.8378 - val_auc: 0.7849\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2721 - acc: 0.9050 - auc: 0.7827 - val_loss: 0.3310 - val_acc: 0.8933 - val_auc: 0.7935\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2724 - acc: 0.9044 - auc: 0.7812 - val_loss: 0.3619 - val_acc: 0.8555 - val_auc: 0.7923\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2716 - acc: 0.9051 - auc: 0.7823 - val_loss: 0.4126 - val_acc: 0.8375 - val_auc: 0.7906\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2719 - acc: 0.9052 - auc: 0.7825 - val_loss: 0.3925 - val_acc: 0.8541 - val_auc: 0.7935\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2719 - acc: 0.9048 - auc: 0.7830 - val_loss: 0.4440 - val_acc: 0.8216 - val_auc: 0.7909\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2723 - acc: 0.9048 - auc: 0.7815 - val_loss: 0.4012 - val_acc: 0.8277 - val_auc: 0.7892\n",
      "Epoch 45/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2723 - acc: 0.9050 - auc: 0.7816 - val_loss: 0.3453 - val_acc: 0.8706 - val_auc: 0.7927\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2716 - acc: 0.9050 - auc: 0.7830 - val_loss: 0.4309 - val_acc: 0.8026 - val_auc: 0.7918\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2718 - acc: 0.9049 - auc: 0.7830 - val_loss: 0.3135 - val_acc: 0.8855 - val_auc: 0.7936\n",
      "Epoch 48/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2717 - acc: 0.9048 - auc: 0.7829 - val_loss: 0.5685 - val_acc: 0.6846 - val_auc: 0.7872\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2707 - acc: 0.9049 - auc: 0.7856 - val_loss: 0.4129 - val_acc: 0.8341 - val_auc: 0.7911\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2717 - acc: 0.9052 - auc: 0.7823 - val_loss: 0.4061 - val_acc: 0.8320 - val_auc: 0.7908\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2809 - acc: 0.9013 - auc: 0.7653 - val_loss: 0.2779 - val_acc: 0.9002 - val_auc: 0.7779\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2792 - acc: 0.9022 - auc: 0.7686 - val_loss: 0.8113 - val_acc: 0.4494 - val_auc: 0.7705\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2776 - acc: 0.9033 - auc: 0.7710 - val_loss: 0.4591 - val_acc: 0.8100 - val_auc: 0.7767\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2788 - acc: 0.9017 - auc: 0.7682 - val_loss: 0.7068 - val_acc: 0.2412 - val_auc: 0.7006\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2780 - acc: 0.9022 - auc: 0.7711 - val_loss: 0.6350 - val_acc: 0.8995 - val_auc: 0.5044\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2793 - acc: 0.9013 - auc: 0.7678 - val_loss: 0.3239 - val_acc: 0.8903 - val_auc: 0.7828\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2790 - acc: 0.9021 - auc: 0.7673 - val_loss: 0.2884 - val_acc: 0.8979 - val_auc: 0.7881\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2766 - acc: 0.9034 - auc: 0.7724 - val_loss: 0.6279 - val_acc: 0.5800 - val_auc: 0.7622\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2772 - acc: 0.9029 - auc: 0.7719 - val_loss: 0.2759 - val_acc: 0.8992 - val_auc: 0.7863\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2774 - acc: 0.9033 - auc: 0.7708 - val_loss: 0.2781 - val_acc: 0.9039 - val_auc: 0.7847\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2770 - acc: 0.9036 - auc: 0.7720 - val_loss: 0.3456 - val_acc: 0.8541 - val_auc: 0.7861\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2765 - acc: 0.9039 - auc: 0.7705 - val_loss: 0.4249 - val_acc: 0.8084 - val_auc: 0.7782\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2774 - acc: 0.9034 - auc: 0.7700 - val_loss: 0.4935 - val_acc: 0.7264 - val_auc: 0.7810\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2765 - acc: 0.9031 - auc: 0.7727 - val_loss: 0.3498 - val_acc: 0.8662 - val_auc: 0.7848\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2760 - acc: 0.9042 - auc: 0.7727 - val_loss: 0.3436 - val_acc: 0.8696 - val_auc: 0.7852\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2763 - acc: 0.9035 - auc: 0.7733 - val_loss: 1.0488 - val_acc: 0.1285 - val_auc: 0.6444\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2739 - acc: 0.9037 - auc: 0.7781 - val_loss: 0.2818 - val_acc: 0.9009 - val_auc: 0.7838\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2750 - acc: 0.9044 - auc: 0.7751 - val_loss: 0.4009 - val_acc: 0.8194 - val_auc: 0.7828\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2752 - acc: 0.9036 - auc: 0.7765 - val_loss: 0.3150 - val_acc: 0.8906 - val_auc: 0.7858\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2739 - acc: 0.9042 - auc: 0.7790 - val_loss: 0.7365 - val_acc: 0.5431 - val_auc: 0.7775\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2743 - acc: 0.9044 - auc: 0.7762 - val_loss: 0.4121 - val_acc: 0.8274 - val_auc: 0.7857\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2745 - acc: 0.9041 - auc: 0.7769 - val_loss: 0.5978 - val_acc: 0.6896 - val_auc: 0.7800\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2744 - acc: 0.9037 - auc: 0.7774 - val_loss: 0.7029 - val_acc: 0.5224 - val_auc: 0.7601\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2744 - acc: 0.9044 - auc: 0.7773 - val_loss: 0.4574 - val_acc: 0.8004 - val_auc: 0.7824\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2745 - acc: 0.9044 - auc: 0.7760 - val_loss: 0.4793 - val_acc: 0.7875 - val_auc: 0.7874\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2733 - acc: 0.9047 - auc: 0.7791 - val_loss: 0.2922 - val_acc: 0.8947 - val_auc: 0.7870\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2736 - acc: 0.9050 - auc: 0.7788 - val_loss: 0.4374 - val_acc: 0.8003 - val_auc: 0.7864\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2781 - acc: 0.9029 - auc: 0.7699 - val_loss: 0.6028 - val_acc: 0.6322 - val_auc: 0.7591\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2782 - acc: 0.9029 - auc: 0.7680 - val_loss: 0.5781 - val_acc: 0.6595 - val_auc: 0.7742\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2793 - acc: 0.9024 - auc: 0.7671 - val_loss: 0.6978 - val_acc: 0.5119 - val_auc: 0.7715\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2783 - acc: 0.9027 - auc: 0.7684 - val_loss: 0.4178 - val_acc: 0.7597 - val_auc: 0.7671\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2787 - acc: 0.9022 - auc: 0.7680 - val_loss: 0.3652 - val_acc: 0.8847 - val_auc: 0.7821\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2779 - acc: 0.9022 - auc: 0.7693 - val_loss: 0.3636 - val_acc: 0.8400 - val_auc: 0.7824\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2775 - acc: 0.9025 - auc: 0.7709 - val_loss: 0.4396 - val_acc: 0.7812 - val_auc: 0.7791\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2774 - acc: 0.9026 - auc: 0.7714 - val_loss: 0.2968 - val_acc: 0.8942 - val_auc: 0.7790\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2785 - acc: 0.9027 - auc: 0.7680 - val_loss: 0.5755 - val_acc: 0.6900 - val_auc: 0.7795\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2772 - acc: 0.9027 - auc: 0.7712 - val_loss: 0.7509 - val_acc: 0.5282 - val_auc: 0.7744\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 9s 61us/step - loss: 0.2779 - acc: 0.9030 - auc: 0.7688 - val_loss: 0.4709 - val_acc: 0.7677 - val_auc: 0.7809\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2781 - acc: 0.9033 - auc: 0.7683 - val_loss: 0.3703 - val_acc: 0.8443 - val_auc: 0.7832\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2772 - acc: 0.9033 - auc: 0.7691 - val_loss: 0.4839 - val_acc: 0.8028 - val_auc: 0.7813\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2761 - acc: 0.9040 - auc: 0.7730 - val_loss: 0.7946 - val_acc: 0.4943 - val_auc: 0.7862\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2756 - acc: 0.9037 - auc: 0.7745 - val_loss: 0.4451 - val_acc: 0.8036 - val_auc: 0.7867\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2753 - acc: 0.9039 - auc: 0.7757 - val_loss: 0.6176 - val_acc: 0.5579 - val_auc: 0.7825\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2752 - acc: 0.9042 - auc: 0.7749 - val_loss: 0.4010 - val_acc: 0.7887 - val_auc: 0.7845\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2755 - acc: 0.9036 - auc: 0.7741 - val_loss: 0.8419 - val_acc: 0.1047 - val_auc: 0.5154\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2791 - acc: 0.9023 - auc: 0.7661 - val_loss: 0.2845 - val_acc: 0.8996 - val_auc: 0.7829\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2745 - acc: 0.9040 - auc: 0.7766 - val_loss: 0.7861 - val_acc: 0.4572 - val_auc: 0.7743\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2750 - acc: 0.9039 - auc: 0.7756 - val_loss: 0.4458 - val_acc: 0.7557 - val_auc: 0.7858\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2744 - acc: 0.9042 - auc: 0.7759 - val_loss: 0.3320 - val_acc: 0.8715 - val_auc: 0.7857\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2744 - acc: 0.9047 - auc: 0.7749 - val_loss: 0.4119 - val_acc: 0.8182 - val_auc: 0.7895\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2743 - acc: 0.9039 - auc: 0.7765 - val_loss: 0.3909 - val_acc: 0.8135 - val_auc: 0.7828\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2751 - acc: 0.9042 - auc: 0.7752 - val_loss: 0.3112 - val_acc: 0.9026 - val_auc: 0.7882\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2738 - acc: 0.9041 - auc: 0.7795 - val_loss: 0.6295 - val_acc: 0.5911 - val_auc: 0.7857\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2738 - acc: 0.9045 - auc: 0.7780 - val_loss: 0.3716 - val_acc: 0.8473 - val_auc: 0.7889\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2730 - acc: 0.9044 - auc: 0.7804 - val_loss: 0.4411 - val_acc: 0.7958 - val_auc: 0.7869\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2733 - acc: 0.9045 - auc: 0.7791 - val_loss: 0.4801 - val_acc: 0.7572 - val_auc: 0.7885\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2727 - acc: 0.9044 - auc: 0.7812 - val_loss: 0.3831 - val_acc: 0.8196 - val_auc: 0.7883\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2734 - acc: 0.9044 - auc: 0.7795 - val_loss: 0.2872 - val_acc: 0.8938 - val_auc: 0.7907\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2755 - acc: 0.9037 - auc: 0.7730 - val_loss: 0.4308 - val_acc: 0.8315 - val_auc: 0.7853\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2732 - acc: 0.9042 - auc: 0.7793 - val_loss: 0.4787 - val_acc: 0.7910 - val_auc: 0.7893\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2726 - acc: 0.9050 - auc: 0.7800 - val_loss: 0.3435 - val_acc: 0.8563 - val_auc: 0.7895\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2726 - acc: 0.9046 - auc: 0.7806 - val_loss: 0.4006 - val_acc: 0.8207 - val_auc: 0.7898\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2729 - acc: 0.9049 - auc: 0.7799 - val_loss: 0.3945 - val_acc: 0.8344 - val_auc: 0.7897\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2735 - acc: 0.9049 - auc: 0.7782 - val_loss: 0.6207 - val_acc: 0.6142 - val_auc: 0.7811\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2719 - acc: 0.9052 - auc: 0.7823 - val_loss: 0.3211 - val_acc: 0.8741 - val_auc: 0.7895\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2744 - acc: 0.9039 - auc: 0.7771 - val_loss: 0.4069 - val_acc: 0.8449 - val_auc: 0.7869\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2729 - acc: 0.9047 - auc: 0.7798 - val_loss: 0.4112 - val_acc: 0.8193 - val_auc: 0.7892\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2726 - acc: 0.9050 - auc: 0.7807 - val_loss: 0.4022 - val_acc: 0.8231 - val_auc: 0.7885\n",
      "Epoch 42/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2726 - acc: 0.9046 - auc: 0.7809 - val_loss: 0.3753 - val_acc: 0.8451 - val_auc: 0.7894\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2716 - acc: 0.9049 - auc: 0.7826 - val_loss: 0.5502 - val_acc: 0.6901 - val_auc: 0.7831\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2719 - acc: 0.9052 - auc: 0.7815 - val_loss: 0.4027 - val_acc: 0.8149 - val_auc: 0.7902\n",
      "Epoch 45/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2720 - acc: 0.9050 - auc: 0.7818 - val_loss: 0.3635 - val_acc: 0.8694 - val_auc: 0.7902\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2717 - acc: 0.9051 - auc: 0.7818 - val_loss: 0.4603 - val_acc: 0.7979 - val_auc: 0.7905\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2721 - acc: 0.9052 - auc: 0.7810 - val_loss: 0.3598 - val_acc: 0.8631 - val_auc: 0.7903\n",
      "Epoch 48/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2716 - acc: 0.9051 - auc: 0.7824 - val_loss: 0.4355 - val_acc: 0.8030 - val_auc: 0.7908\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2715 - acc: 0.9054 - auc: 0.7824 - val_loss: 0.4625 - val_acc: 0.7767 - val_auc: 0.7907\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2716 - acc: 0.9050 - auc: 0.7822 - val_loss: 0.3630 - val_acc: 0.8522 - val_auc: 0.7920\n",
      "Run time 32.41735044717789 min\n"
     ]
    }
   ],
   "source": [
    "sequential_nn_model_min_1_4_1_2_var_1 = train_nn(train_polinomial_values_ucm_1_4_1_2, train_target_values_ucm_1_4_1_2, sequential_nn_model_min_1_4_1_2, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 59us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics =  sequential_nn_model_min_1_4_1_2_var_1.evaluate(holdout_test_polinomial_values_ucm_1_4_1_2, holdout_test_target_values_ucm_1_4_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36498079597949984, 0.8551249997317791, 0.7808171874243502]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_4 = make_sequential_model_min(train_polinomial_values_ucm_1_4.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min_1_4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 5s 33us/step - loss: 0.3348 - acc: 0.8952 - auc: 0.5298 - val_loss: 0.3283 - val_acc: 0.8995 - val_auc: 0.6296\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3242 - acc: 0.8995 - auc: 0.5612 - val_loss: 0.3200 - val_acc: 0.8995 - val_auc: 0.6592\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3255 - acc: 0.8995 - auc: 0.5466 - val_loss: 0.3272 - val_acc: 0.8995 - val_auc: 0.6086\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3278 - acc: 0.8995 - auc: 0.5099 - val_loss: 0.3255 - val_acc: 0.8995 - val_auc: 0.6310\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3276 - acc: 0.8995 - auc: 0.5040 - val_loss: 0.3271 - val_acc: 0.8995 - val_auc: 0.5416\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3276 - acc: 0.8995 - auc: 0.5054 - val_loss: 0.3279 - val_acc: 0.8995 - val_auc: 0.5227\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3274 - acc: 0.8995 - auc: 0.5024 - val_loss: 0.3264 - val_acc: 0.8995 - val_auc: 0.5165\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3272 - acc: 0.8995 - auc: 0.5057 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.6075\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3273 - acc: 0.8995 - auc: 0.4982 - val_loss: 0.3266 - val_acc: 0.8995 - val_auc: 0.5361\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3270 - acc: 0.8995 - auc: 0.4984 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5757\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3269 - acc: 0.8995 - auc: 0.5011 - val_loss: 0.3264 - val_acc: 0.8995 - val_auc: 0.5030\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3268 - acc: 0.8995 - auc: 0.4983 - val_loss: 0.3263 - val_acc: 0.8995 - val_auc: 0.4868\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3266 - acc: 0.8995 - auc: 0.5010 - val_loss: 0.3264 - val_acc: 0.8995 - val_auc: 0.5144\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3266 - acc: 0.8995 - auc: 0.5030 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5183\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3266 - acc: 0.8995 - auc: 0.5025 - val_loss: 0.3264 - val_acc: 0.8995 - val_auc: 0.5243\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3266 - acc: 0.8995 - auc: 0.4993 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5315\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3265 - acc: 0.8995 - auc: 0.5004 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5536\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3264 - acc: 0.8995 - auc: 0.5020 - val_loss: 0.3263 - val_acc: 0.8995 - val_auc: 0.5439\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3265 - acc: 0.8995 - auc: 0.4979 - val_loss: 0.3264 - val_acc: 0.8995 - val_auc: 0.5405\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3264 - acc: 0.8995 - auc: 0.4998 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5427\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3265 - acc: 0.8995 - auc: 0.4958 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5497\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3263 - acc: 0.8995 - auc: 0.5023 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5540\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3264 - acc: 0.8995 - auc: 0.5035 - val_loss: 0.3263 - val_acc: 0.8995 - val_auc: 0.5453\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3264 - acc: 0.8995 - auc: 0.4952 - val_loss: 0.3262 - val_acc: 0.8995 - val_auc: 0.5485\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3253 - acc: 0.8995 - auc: 0.5300 - val_loss: 0.3266 - val_acc: 0.8995 - val_auc: 0.6521\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3215 - acc: 0.8995 - auc: 0.5883 - val_loss: 0.3345 - val_acc: 0.8995 - val_auc: 0.5306\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3194 - acc: 0.8995 - auc: 0.6161 - val_loss: 0.3443 - val_acc: 0.8995 - val_auc: 0.3663\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3183 - acc: 0.8995 - auc: 0.6193 - val_loss: 0.3450 - val_acc: 0.8995 - val_auc: 0.4564\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3178 - acc: 0.8995 - auc: 0.6217 - val_loss: 0.3526 - val_acc: 0.8995 - val_auc: 0.3906\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3179 - acc: 0.8995 - auc: 0.6211 - val_loss: 0.3532 - val_acc: 0.8995 - val_auc: 0.3349\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3173 - acc: 0.8995 - auc: 0.6229 - val_loss: 0.3617 - val_acc: 0.8995 - val_auc: 0.3354\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3173 - acc: 0.8995 - auc: 0.6258 - val_loss: 0.3562 - val_acc: 0.8995 - val_auc: 0.4211\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3171 - acc: 0.8995 - auc: 0.6251 - val_loss: 0.3539 - val_acc: 0.8995 - val_auc: 0.5687\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3168 - acc: 0.8995 - auc: 0.6264 - val_loss: 0.3572 - val_acc: 0.8995 - val_auc: 0.4824\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6273 - val_loss: 0.3668 - val_acc: 0.8995 - val_auc: 0.3722\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3167 - acc: 0.8995 - auc: 0.6263 - val_loss: 0.3613 - val_acc: 0.8995 - val_auc: 0.3307\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6288 - val_loss: 0.3651 - val_acc: 0.8995 - val_auc: 0.3340\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6287 - val_loss: 0.3607 - val_acc: 0.8995 - val_auc: 0.6274\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6263 - val_loss: 0.3692 - val_acc: 0.8995 - val_auc: 0.3556\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6264 - val_loss: 0.3632 - val_acc: 0.8995 - val_auc: 0.5242\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6288 - val_loss: 0.3709 - val_acc: 0.8995 - val_auc: 0.3599\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6281 - val_loss: 0.3680 - val_acc: 0.8995 - val_auc: 0.3198\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3162 - acc: 0.8995 - auc: 0.6273 - val_loss: 0.3674 - val_acc: 0.8995 - val_auc: 0.3890\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6283 - val_loss: 0.3669 - val_acc: 0.8995 - val_auc: 0.4720\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6255 - val_loss: 0.3604 - val_acc: 0.8995 - val_auc: 0.6329\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3171 - acc: 0.8995 - auc: 0.6238 - val_loss: 0.3530 - val_acc: 0.8995 - val_auc: 0.6462\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3174 - acc: 0.8995 - auc: 0.6218 - val_loss: 0.3558 - val_acc: 0.8995 - val_auc: 0.5912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6270 - val_loss: 0.3660 - val_acc: 0.8995 - val_auc: 0.4139\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3170 - acc: 0.8995 - auc: 0.6251 - val_loss: 0.3587 - val_acc: 0.8995 - val_auc: 0.4579\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3166 - acc: 0.8995 - auc: 0.6270 - val_loss: 0.3631 - val_acc: 0.8995 - val_auc: 0.3282\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6264 - val_loss: 0.3619 - val_acc: 0.8995 - val_auc: 0.3804\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6285 - val_loss: 0.3699 - val_acc: 0.8995 - val_auc: 0.3699\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6258 - val_loss: 0.3664 - val_acc: 0.8995 - val_auc: 0.3836\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3167 - acc: 0.8995 - auc: 0.6260 - val_loss: 0.3655 - val_acc: 0.8995 - val_auc: 0.3304\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6272 - val_loss: 0.3668 - val_acc: 0.8995 - val_auc: 0.3494\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3162 - acc: 0.8995 - auc: 0.6273 - val_loss: 0.3709 - val_acc: 0.8995 - val_auc: 0.3848\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6286 - val_loss: 0.3705 - val_acc: 0.8995 - val_auc: 0.3624\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6286 - val_loss: 0.3691 - val_acc: 0.8995 - val_auc: 0.3309\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6301 - val_loss: 0.3721 - val_acc: 0.8995 - val_auc: 0.3329\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6271 - val_loss: 0.3679 - val_acc: 0.8995 - val_auc: 0.3601\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6256 - val_loss: 0.3674 - val_acc: 0.8995 - val_auc: 0.3686\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6254 - val_loss: 0.3705 - val_acc: 0.8995 - val_auc: 0.3781\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3157 - acc: 0.8995 - auc: 0.6284 - val_loss: 0.3764 - val_acc: 0.8995 - val_auc: 0.3604\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6279 - val_loss: 0.3678 - val_acc: 0.8995 - val_auc: 0.5322\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3156 - acc: 0.8995 - auc: 0.6311 - val_loss: 0.3671 - val_acc: 0.8995 - val_auc: 0.5516\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6268 - val_loss: 0.3783 - val_acc: 0.8995 - val_auc: 0.4030\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6256 - val_loss: 0.3635 - val_acc: 0.8995 - val_auc: 0.3318\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6285 - val_loss: 0.3667 - val_acc: 0.8995 - val_auc: 0.4547\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3171 - acc: 0.8995 - auc: 0.6255 - val_loss: 0.3640 - val_acc: 0.8995 - val_auc: 0.4808\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3167 - acc: 0.8995 - auc: 0.6266 - val_loss: 0.3639 - val_acc: 0.8995 - val_auc: 0.3868\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3171 - acc: 0.8995 - auc: 0.6241 - val_loss: 0.3684 - val_acc: 0.8995 - val_auc: 0.2953\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6281 - val_loss: 0.3659 - val_acc: 0.8995 - val_auc: 0.3288\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3162 - acc: 0.8995 - auc: 0.6289 - val_loss: 0.3642 - val_acc: 0.8995 - val_auc: 0.6283\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6275 - val_loss: 0.3661 - val_acc: 0.8995 - val_auc: 0.3134\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3166 - acc: 0.8995 - auc: 0.6260 - val_loss: 0.3679 - val_acc: 0.8995 - val_auc: 0.4471\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3168 - acc: 0.8995 - auc: 0.6235 - val_loss: 0.3675 - val_acc: 0.8995 - val_auc: 0.4969\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6288 - val_loss: 0.3711 - val_acc: 0.8995 - val_auc: 0.3946\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6244 - val_loss: 0.3585 - val_acc: 0.8995 - val_auc: 0.6792\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6281 - val_loss: 0.3727 - val_acc: 0.8995 - val_auc: 0.3074\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6248 - val_loss: 0.3694 - val_acc: 0.8995 - val_auc: 0.3271\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6299 - val_loss: 0.3585 - val_acc: 0.8995 - val_auc: 0.6321\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6266 - val_loss: 0.3645 - val_acc: 0.8995 - val_auc: 0.3119\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3162 - acc: 0.8995 - auc: 0.6259 - val_loss: 0.3691 - val_acc: 0.8995 - val_auc: 0.3052\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6259 - val_loss: 0.3694 - val_acc: 0.8995 - val_auc: 0.3428\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6279 - val_loss: 0.3673 - val_acc: 0.8995 - val_auc: 0.4748\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6264 - val_loss: 0.3655 - val_acc: 0.8995 - val_auc: 0.3766\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6252 - val_loss: 0.3628 - val_acc: 0.8995 - val_auc: 0.4043\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3155 - acc: 0.8995 - auc: 0.6302 - val_loss: 0.3735 - val_acc: 0.8995 - val_auc: 0.2976\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6285 - val_loss: 0.3700 - val_acc: 0.8995 - val_auc: 0.3516\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3157 - acc: 0.8995 - auc: 0.6296 - val_loss: 0.3722 - val_acc: 0.8995 - val_auc: 0.3052\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3155 - acc: 0.8995 - auc: 0.6286 - val_loss: 0.3720 - val_acc: 0.8995 - val_auc: 0.3032\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3158 - acc: 0.8995 - auc: 0.6302 - val_loss: 0.3733 - val_acc: 0.8995 - val_auc: 0.3521\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6274 - val_loss: 0.3674 - val_acc: 0.8995 - val_auc: 0.4662\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6284 - val_loss: 0.3697 - val_acc: 0.8995 - val_auc: 0.3086\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3153 - acc: 0.8995 - auc: 0.6302 - val_loss: 0.3731 - val_acc: 0.8995 - val_auc: 0.3460\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3159 - acc: 0.8995 - auc: 0.6277 - val_loss: 0.3682 - val_acc: 0.8995 - val_auc: 0.4225\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3154 - acc: 0.8995 - auc: 0.6287 - val_loss: 0.3654 - val_acc: 0.8995 - val_auc: 0.6050\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3156 - acc: 0.8995 - auc: 0.6284 - val_loss: 0.3695 - val_acc: 0.8995 - val_auc: 0.3451\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6263 - val_loss: 0.3646 - val_acc: 0.8995 - val_auc: 0.3885\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3166 - acc: 0.8995 - auc: 0.6264 - val_loss: 0.3665 - val_acc: 0.8995 - val_auc: 0.4609\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3166 - acc: 0.8995 - auc: 0.6241 - val_loss: 0.3516 - val_acc: 0.8995 - val_auc: 0.6895\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3163 - acc: 0.8995 - auc: 0.6281 - val_loss: 0.3644 - val_acc: 0.8995 - val_auc: 0.6061\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3165 - acc: 0.8995 - auc: 0.6256 - val_loss: 0.3700 - val_acc: 0.8995 - val_auc: 0.3123\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6260 - val_loss: 0.3683 - val_acc: 0.8995 - val_auc: 0.3095\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3158 - acc: 0.8995 - auc: 0.6306 - val_loss: 0.3665 - val_acc: 0.8995 - val_auc: 0.5094\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3167 - acc: 0.8995 - auc: 0.6254 - val_loss: 0.3618 - val_acc: 0.8995 - val_auc: 0.4423\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3164 - acc: 0.8995 - auc: 0.6279 - val_loss: 0.3670 - val_acc: 0.8995 - val_auc: 0.3246\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3162 - acc: 0.8995 - auc: 0.6280 - val_loss: 0.3681 - val_acc: 0.8995 - val_auc: 0.4149\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3158 - acc: 0.8995 - auc: 0.6307 - val_loss: 0.3713 - val_acc: 0.8995 - val_auc: 0.3038\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6284 - val_loss: 0.3681 - val_acc: 0.8995 - val_auc: 0.5201\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3160 - acc: 0.8995 - auc: 0.6278 - val_loss: 0.3682 - val_acc: 0.8995 - val_auc: 0.3066\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3154 - acc: 0.8995 - auc: 0.6333 - val_loss: 0.3698 - val_acc: 0.8995 - val_auc: 0.3096\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3156 - acc: 0.8995 - auc: 0.6304 - val_loss: 0.3730 - val_acc: 0.8995 - val_auc: 0.4094\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3161 - acc: 0.8995 - auc: 0.6278 - val_loss: 0.3692 - val_acc: 0.8995 - val_auc: 0.4202\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3157 - acc: 0.8995 - auc: 0.6301 - val_loss: 0.3728 - val_acc: 0.8995 - val_auc: 0.3166\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3156 - acc: 0.8995 - auc: 0.6291 - val_loss: 0.3749 - val_acc: 0.8995 - val_auc: 0.5668\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3156 - acc: 0.8995 - auc: 0.6305 - val_loss: 0.3753 - val_acc: 0.8995 - val_auc: 0.3073\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3152 - acc: 0.8995 - auc: 0.6322 - val_loss: 0.3750 - val_acc: 0.8995 - val_auc: 0.3378\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3154 - acc: 0.8995 - auc: 0.6313 - val_loss: 0.3743 - val_acc: 0.8995 - val_auc: 0.3034\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 2s 16us/step - loss: 0.3155 - acc: 0.8995 - auc: 0.6298 - val_loss: 0.3688 - val_acc: 0.8995 - val_auc: 0.4473\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 2s 17us/step - loss: 0.3155 - acc: 0.8995 - auc: 0.6295 - val_loss: 0.3699 - val_acc: 0.8995 - val_auc: 0.3853\n",
      "Run time 4.980446712176005 min\n"
     ]
    }
   ],
   "source": [
    "sequential_nn_model_min_1_4 = train_nn(train_polinomial_values_ucm_1_4, train_target_values_ucm_1_4, sequential_nn_model_min_1_4, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 35us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics =  sequential_nn_model_min_1_4.evaluate(holdout_test_polinomial_values_ucm_1_4, holdout_test_target_values_ucm_1_4, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36982477001845837, 0.8996500012278557, 0.38214791206169524]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 10s 69us/step - loss: 0.3500 - acc: 0.8864 - auc: 0.5249 - val_loss: 0.3280 - val_acc: 0.8995 - val_auc: 0.5757\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3213 - acc: 0.8995 - auc: 0.5931 - val_loss: 0.3505 - val_acc: 0.8995 - val_auc: 0.3396\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3122 - acc: 0.8995 - auc: 0.6532 - val_loss: 0.3097 - val_acc: 0.8995 - val_auc: 0.6709\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3112 - acc: 0.8995 - auc: 0.6617 - val_loss: 0.3177 - val_acc: 0.8995 - val_auc: 0.6717\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3098 - acc: 0.8995 - auc: 0.6662 - val_loss: 0.3154 - val_acc: 0.8995 - val_auc: 0.6714\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3095 - acc: 0.8995 - auc: 0.6687 - val_loss: 0.3084 - val_acc: 0.8995 - val_auc: 0.6749\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3090 - acc: 0.8995 - auc: 0.6691 - val_loss: 0.3205 - val_acc: 0.8995 - val_auc: 0.6716\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3087 - acc: 0.8995 - auc: 0.6700 - val_loss: 0.3207 - val_acc: 0.8995 - val_auc: 0.6739\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3086 - acc: 0.8995 - auc: 0.6713 - val_loss: 0.3195 - val_acc: 0.8995 - val_auc: 0.6774\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3085 - acc: 0.8995 - auc: 0.6713 - val_loss: 0.3092 - val_acc: 0.8995 - val_auc: 0.6761\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3145 - acc: 0.8994 - auc: 0.6431 - val_loss: 0.3537 - val_acc: 0.8995 - val_auc: 0.6699\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3102 - acc: 0.8994 - auc: 0.6636 - val_loss: 0.3306 - val_acc: 0.8995 - val_auc: 0.6733\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3087 - acc: 0.8996 - auc: 0.6697 - val_loss: 0.3383 - val_acc: 0.8995 - val_auc: 0.6770\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3080 - acc: 0.8995 - auc: 0.6731 - val_loss: 0.3278 - val_acc: 0.8995 - val_auc: 0.6780\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3077 - acc: 0.8995 - auc: 0.6738 - val_loss: 0.4128 - val_acc: 0.8995 - val_auc: 0.6767\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3073 - acc: 0.8995 - auc: 0.6768 - val_loss: 0.3468 - val_acc: 0.8995 - val_auc: 0.6798\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3072 - acc: 0.8994 - auc: 0.6770 - val_loss: 0.3888 - val_acc: 0.8597 - val_auc: 0.6824\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3070 - acc: 0.8996 - auc: 0.6754 - val_loss: 0.3872 - val_acc: 0.8995 - val_auc: 0.6811\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3065 - acc: 0.8995 - auc: 0.6788 - val_loss: 0.5124 - val_acc: 0.8995 - val_auc: 0.6710\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3071 - acc: 0.8994 - auc: 0.6781 - val_loss: 0.3914 - val_acc: 0.8995 - val_auc: 0.6819\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3065 - acc: 0.8996 - auc: 0.6785 - val_loss: 0.3248 - val_acc: 0.9002 - val_auc: 0.6822\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3067 - acc: 0.8995 - auc: 0.6777 - val_loss: 0.4383 - val_acc: 0.8995 - val_auc: 0.6823\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3067 - acc: 0.8997 - auc: 0.6784 - val_loss: 0.4716 - val_acc: 0.7918 - val_auc: 0.6806\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3065 - acc: 0.8996 - auc: 0.6778 - val_loss: 0.3246 - val_acc: 0.9002 - val_auc: 0.6831\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3060 - acc: 0.8993 - auc: 0.6817 - val_loss: 0.3246 - val_acc: 0.8995 - val_auc: 0.6826\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3064 - acc: 0.8996 - auc: 0.6790 - val_loss: 0.3205 - val_acc: 0.8995 - val_auc: 0.6828\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3062 - acc: 0.8997 - auc: 0.6790 - val_loss: 0.3380 - val_acc: 0.8995 - val_auc: 0.6825\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3064 - acc: 0.8997 - auc: 0.6799 - val_loss: 0.3166 - val_acc: 0.9001 - val_auc: 0.6829\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8996 - auc: 0.6823 - val_loss: 0.3331 - val_acc: 0.8979 - val_auc: 0.6821\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3064 - acc: 0.8997 - auc: 0.6782 - val_loss: 0.3344 - val_acc: 0.8961 - val_auc: 0.6829\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3058 - acc: 0.8997 - auc: 0.6803 - val_loss: 0.4889 - val_acc: 0.7424 - val_auc: 0.6819\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3062 - acc: 0.8998 - auc: 0.6790 - val_loss: 0.6019 - val_acc: 0.6399 - val_auc: 0.6835\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3059 - acc: 0.8997 - auc: 0.6807 - val_loss: 0.5171 - val_acc: 0.7170 - val_auc: 0.6821\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3063 - acc: 0.8996 - auc: 0.6791 - val_loss: 0.3576 - val_acc: 0.8850 - val_auc: 0.6835\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3060 - acc: 0.8998 - auc: 0.6800 - val_loss: 0.4569 - val_acc: 0.7999 - val_auc: 0.6841\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3057 - acc: 0.8996 - auc: 0.6814 - val_loss: 0.4683 - val_acc: 0.7950 - val_auc: 0.6837\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3058 - acc: 0.8998 - auc: 0.6798 - val_loss: 0.4467 - val_acc: 0.8995 - val_auc: 0.6728\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3058 - acc: 0.8998 - auc: 0.6806 - val_loss: 0.3970 - val_acc: 0.8561 - val_auc: 0.6834\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3055 - acc: 0.8998 - auc: 0.6822 - val_loss: 0.4127 - val_acc: 0.8363 - val_auc: 0.6835\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3056 - acc: 0.9000 - auc: 0.6812 - val_loss: 0.4362 - val_acc: 0.7852 - val_auc: 0.6832\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3060 - acc: 0.8997 - auc: 0.6800 - val_loss: 0.4373 - val_acc: 0.8343 - val_auc: 0.6839\n",
      "Epoch 42/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6806 - val_loss: 0.3728 - val_acc: 0.8836 - val_auc: 0.6837\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6822 - val_loss: 0.4066 - val_acc: 0.8674 - val_auc: 0.6840\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3053 - acc: 0.8996 - auc: 0.6830 - val_loss: 0.5315 - val_acc: 0.6660 - val_auc: 0.6797\n",
      "Epoch 45/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6813 - val_loss: 0.3632 - val_acc: 0.8810 - val_auc: 0.6837\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6818 - val_loss: 0.4986 - val_acc: 0.7220 - val_auc: 0.6824\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 6s 41us/step - loss: 0.3053 - acc: 0.8997 - auc: 0.6820 - val_loss: 0.4856 - val_acc: 0.7767 - val_auc: 0.6844\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3056 - acc: 0.8997 - auc: 0.6805 - val_loss: 0.4546 - val_acc: 0.8060 - val_auc: 0.6843\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8998 - auc: 0.6805 - val_loss: 0.4651 - val_acc: 0.8008 - val_auc: 0.6840\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3049 - acc: 0.8996 - auc: 0.6843 - val_loss: 0.4605 - val_acc: 0.8073 - val_auc: 0.6838\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3082 - acc: 0.8995 - auc: 0.6752 - val_loss: 0.5384 - val_acc: 0.8995 - val_auc: 0.3246\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3081 - acc: 0.8994 - auc: 0.6737 - val_loss: 0.5256 - val_acc: 0.8995 - val_auc: 0.6583\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3080 - acc: 0.8995 - auc: 0.6757 - val_loss: 0.4061 - val_acc: 0.7920 - val_auc: 0.6874\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 40us/step - loss: 0.3077 - acc: 0.8993 - auc: 0.6774 - val_loss: 0.3259 - val_acc: 0.8995 - val_auc: 0.6854\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3075 - acc: 0.8995 - auc: 0.6750 - val_loss: 0.3623 - val_acc: 0.8995 - val_auc: 0.6844\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3075 - acc: 0.8997 - auc: 0.6756 - val_loss: 0.3700 - val_acc: 0.8996 - val_auc: 0.6857\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3078 - acc: 0.8995 - auc: 0.6744 - val_loss: 0.4964 - val_acc: 0.8995 - val_auc: 0.6828\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3073 - acc: 0.8995 - auc: 0.6757 - val_loss: 0.3106 - val_acc: 0.8995 - val_auc: 0.6821\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3070 - acc: 0.8995 - auc: 0.6770 - val_loss: 0.3058 - val_acc: 0.8995 - val_auc: 0.6865\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3067 - acc: 0.8995 - auc: 0.6772 - val_loss: 0.3154 - val_acc: 0.8995 - val_auc: 0.6873\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3068 - acc: 0.8996 - auc: 0.6773 - val_loss: 0.5279 - val_acc: 0.5894 - val_auc: 0.6856\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3065 - acc: 0.8996 - auc: 0.6791 - val_loss: 0.3921 - val_acc: 0.8995 - val_auc: 0.6869\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3062 - acc: 0.8994 - auc: 0.6802 - val_loss: 0.3055 - val_acc: 0.8995 - val_auc: 0.6865\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3063 - acc: 0.8995 - auc: 0.6792 - val_loss: 0.3312 - val_acc: 0.8998 - val_auc: 0.6840\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3069 - acc: 0.8995 - auc: 0.6761 - val_loss: 0.5588 - val_acc: 0.7074 - val_auc: 0.6864\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3064 - acc: 0.8998 - auc: 0.6780 - val_loss: 0.4414 - val_acc: 0.8147 - val_auc: 0.6869\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3064 - acc: 0.8998 - auc: 0.6782 - val_loss: 0.3900 - val_acc: 0.8786 - val_auc: 0.6883\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3060 - acc: 0.8998 - auc: 0.6793 - val_loss: 1.0949 - val_acc: 0.4001 - val_auc: 0.6875\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3065 - acc: 0.8995 - auc: 0.6782 - val_loss: 0.4042 - val_acc: 0.8656 - val_auc: 0.6873\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6806 - val_loss: 0.3529 - val_acc: 0.8964 - val_auc: 0.6880\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3061 - acc: 0.8996 - auc: 0.6804 - val_loss: 0.6522 - val_acc: 0.6498 - val_auc: 0.6863\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3061 - acc: 0.8995 - auc: 0.6790 - val_loss: 0.3810 - val_acc: 0.8686 - val_auc: 0.6874\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8997 - auc: 0.6816 - val_loss: 0.3717 - val_acc: 0.8939 - val_auc: 0.6878\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3061 - acc: 0.8996 - auc: 0.6794 - val_loss: 0.5264 - val_acc: 0.6337 - val_auc: 0.6567\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3060 - acc: 0.8996 - auc: 0.6802 - val_loss: 0.3371 - val_acc: 0.8984 - val_auc: 0.6876\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8996 - auc: 0.6814 - val_loss: 0.3286 - val_acc: 0.8963 - val_auc: 0.6870\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8998 - auc: 0.6817 - val_loss: 0.4909 - val_acc: 0.6947 - val_auc: 0.6703\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3055 - acc: 0.8997 - auc: 0.6811 - val_loss: 0.3932 - val_acc: 0.8839 - val_auc: 0.6875\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6805 - val_loss: 0.4284 - val_acc: 0.8560 - val_auc: 0.6870\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3056 - acc: 0.8998 - auc: 0.6806 - val_loss: 0.3410 - val_acc: 0.8886 - val_auc: 0.6876\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8999 - auc: 0.6828 - val_loss: 0.5067 - val_acc: 0.8272 - val_auc: 0.6871\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3055 - acc: 0.8997 - auc: 0.6812 - val_loss: 0.5215 - val_acc: 0.6907 - val_auc: 0.6782\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8999 - auc: 0.6803 - val_loss: 0.3615 - val_acc: 0.8778 - val_auc: 0.6881\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6817 - val_loss: 0.3843 - val_acc: 0.8579 - val_auc: 0.6880\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3056 - acc: 0.8995 - auc: 0.6804 - val_loss: 0.3791 - val_acc: 0.8995 - val_auc: 0.6881\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6817 - val_loss: 0.5883 - val_acc: 0.5637 - val_auc: 0.6881\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3051 - acc: 0.8996 - auc: 0.6829 - val_loss: 0.4404 - val_acc: 0.8284 - val_auc: 0.6880\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3076 - acc: 0.8995 - auc: 0.6763 - val_loss: 0.3111 - val_acc: 0.8995 - val_auc: 0.6950\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3079 - acc: 0.8994 - auc: 0.6756 - val_loss: 0.3072 - val_acc: 0.8995 - val_auc: 0.6970\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3076 - acc: 0.8993 - auc: 0.6757 - val_loss: 0.4980 - val_acc: 0.8995 - val_auc: 0.6957\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3077 - acc: 0.8994 - auc: 0.6742 - val_loss: 0.3095 - val_acc: 0.8995 - val_auc: 0.6969\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3076 - acc: 0.8995 - auc: 0.6758 - val_loss: 0.3162 - val_acc: 0.8995 - val_auc: 0.6978\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3072 - acc: 0.8994 - auc: 0.6758 - val_loss: 0.5668 - val_acc: 0.8995 - val_auc: 0.7005\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3071 - acc: 0.8995 - auc: 0.6767 - val_loss: 0.4417 - val_acc: 0.8995 - val_auc: 0.6982\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3071 - acc: 0.8995 - auc: 0.6771 - val_loss: 0.3160 - val_acc: 0.8995 - val_auc: 0.6981\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3073 - acc: 0.8996 - auc: 0.6757 - val_loss: 0.4895 - val_acc: 0.8995 - val_auc: 0.6997\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3072 - acc: 0.8995 - auc: 0.6762 - val_loss: 0.4326 - val_acc: 0.8995 - val_auc: 0.6990\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3070 - acc: 0.8996 - auc: 0.6776 - val_loss: 0.4250 - val_acc: 0.8167 - val_auc: 0.6999\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3068 - acc: 0.8996 - auc: 0.6769 - val_loss: 0.3972 - val_acc: 0.8937 - val_auc: 0.6983\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3064 - acc: 0.8995 - auc: 0.6781 - val_loss: 0.4789 - val_acc: 0.8069 - val_auc: 0.6994\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3061 - acc: 0.8995 - auc: 0.6799 - val_loss: 0.5664 - val_acc: 0.8995 - val_auc: 0.5911\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3062 - acc: 0.8995 - auc: 0.6779 - val_loss: 0.4772 - val_acc: 0.8995 - val_auc: 0.7009\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 6s 41us/step - loss: 0.3065 - acc: 0.8996 - auc: 0.6784 - val_loss: 0.3805 - val_acc: 0.8491 - val_auc: 0.6982\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3064 - acc: 0.8994 - auc: 0.6790 - val_loss: 0.4992 - val_acc: 0.7738 - val_auc: 0.6999\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3060 - acc: 0.8996 - auc: 0.6792 - val_loss: 0.3557 - val_acc: 0.8995 - val_auc: 0.6999\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3062 - acc: 0.8997 - auc: 0.6779 - val_loss: 0.5802 - val_acc: 0.6331 - val_auc: 0.7000\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3062 - acc: 0.8997 - auc: 0.6789 - val_loss: 0.5157 - val_acc: 0.7128 - val_auc: 0.7016\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3060 - acc: 0.9000 - auc: 0.6792 - val_loss: 0.3849 - val_acc: 0.8843 - val_auc: 0.7000\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3059 - acc: 0.8995 - auc: 0.6793 - val_loss: 0.3959 - val_acc: 0.8538 - val_auc: 0.7003\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8996 - auc: 0.6812 - val_loss: 0.3919 - val_acc: 0.8605 - val_auc: 0.6999\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8999 - auc: 0.6816 - val_loss: 0.6415 - val_acc: 0.7184 - val_auc: 0.7006\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3062 - acc: 0.8997 - auc: 0.6791 - val_loss: 0.5071 - val_acc: 0.7250 - val_auc: 0.7016\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6800 - val_loss: 0.4258 - val_acc: 0.8244 - val_auc: 0.7002\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3057 - acc: 0.8998 - auc: 0.6805 - val_loss: 0.4774 - val_acc: 0.8312 - val_auc: 0.7008\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8996 - auc: 0.6783 - val_loss: 0.3691 - val_acc: 0.8948 - val_auc: 0.7014\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8998 - auc: 0.6801 - val_loss: 0.3539 - val_acc: 0.8914 - val_auc: 0.7001\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8997 - auc: 0.6806 - val_loss: 0.3738 - val_acc: 0.8974 - val_auc: 0.7000\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8998 - auc: 0.6807 - val_loss: 0.7073 - val_acc: 0.4944 - val_auc: 0.7009\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3057 - acc: 0.8997 - auc: 0.6795 - val_loss: 0.3219 - val_acc: 0.8996 - val_auc: 0.7001\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 6s 40us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6818 - val_loss: 0.7531 - val_acc: 0.5319 - val_auc: 0.6995\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8995 - auc: 0.6801 - val_loss: 0.3351 - val_acc: 0.8986 - val_auc: 0.7003\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3055 - acc: 0.8997 - auc: 0.6809 - val_loss: 0.4672 - val_acc: 0.8173 - val_auc: 0.7010\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3055 - acc: 0.8997 - auc: 0.6802 - val_loss: 0.5321 - val_acc: 0.7820 - val_auc: 0.7005\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 6s 40us/step - loss: 0.3054 - acc: 0.8999 - auc: 0.6813 - val_loss: 0.4007 - val_acc: 0.8246 - val_auc: 0.7004\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3055 - acc: 0.8998 - auc: 0.6805 - val_loss: 0.3756 - val_acc: 0.8788 - val_auc: 0.7011\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6822 - val_loss: 0.4905 - val_acc: 0.7288 - val_auc: 0.7016\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8997 - auc: 0.6822 - val_loss: 0.3641 - val_acc: 0.8932 - val_auc: 0.7009\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3078 - acc: 0.8994 - auc: 0.6768 - val_loss: 0.3786 - val_acc: 0.8995 - val_auc: 0.6888\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3076 - acc: 0.8995 - auc: 0.6783 - val_loss: 0.4407 - val_acc: 0.8059 - val_auc: 0.6894\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3076 - acc: 0.8996 - auc: 0.6739 - val_loss: 0.3124 - val_acc: 0.8996 - val_auc: 0.6889\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3070 - acc: 0.8995 - auc: 0.6776 - val_loss: 0.3187 - val_acc: 0.8995 - val_auc: 0.6922\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3070 - acc: 0.8996 - auc: 0.6771 - val_loss: 0.3860 - val_acc: 0.8995 - val_auc: 0.6926\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3064 - acc: 0.8995 - auc: 0.6792 - val_loss: 0.9159 - val_acc: 0.1008 - val_auc: 0.6375\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3069 - acc: 0.8993 - auc: 0.6783 - val_loss: 0.4424 - val_acc: 0.8995 - val_auc: 0.6906\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3068 - acc: 0.8995 - auc: 0.6787 - val_loss: 0.3317 - val_acc: 0.8997 - val_auc: 0.6920\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3069 - acc: 0.8995 - auc: 0.6756 - val_loss: 0.3131 - val_acc: 0.8995 - val_auc: 0.6915\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3064 - acc: 0.8994 - auc: 0.6795 - val_loss: 0.4013 - val_acc: 0.8159 - val_auc: 0.6896\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3063 - acc: 0.8997 - auc: 0.6795 - val_loss: 0.3311 - val_acc: 0.8995 - val_auc: 0.6925\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3064 - acc: 0.8995 - auc: 0.6795 - val_loss: 0.8111 - val_acc: 0.4141 - val_auc: 0.6913\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3061 - acc: 0.8997 - auc: 0.6815 - val_loss: 0.4137 - val_acc: 0.8995 - val_auc: 0.6921\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3065 - acc: 0.8996 - auc: 0.6789 - val_loss: 0.5309 - val_acc: 0.8995 - val_auc: 0.6687\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3061 - acc: 0.8994 - auc: 0.6806 - val_loss: 0.3127 - val_acc: 0.9005 - val_auc: 0.6925\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8996 - auc: 0.6808 - val_loss: 0.3919 - val_acc: 0.8487 - val_auc: 0.6929\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8995 - auc: 0.6814 - val_loss: 0.3404 - val_acc: 0.9003 - val_auc: 0.6923\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3061 - acc: 0.8994 - auc: 0.6801 - val_loss: 0.4873 - val_acc: 0.7022 - val_auc: 0.6911\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8995 - auc: 0.6810 - val_loss: 0.3740 - val_acc: 0.8995 - val_auc: 0.6928\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3056 - acc: 0.8995 - auc: 0.6826 - val_loss: 0.3114 - val_acc: 0.8995 - val_auc: 0.6935\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8998 - auc: 0.6818 - val_loss: 0.3751 - val_acc: 0.8925 - val_auc: 0.6915\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3057 - acc: 0.8999 - auc: 0.6804 - val_loss: 0.3208 - val_acc: 0.9007 - val_auc: 0.6928\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3060 - acc: 0.8997 - auc: 0.6806 - val_loss: 0.8419 - val_acc: 0.6155 - val_auc: 0.6871\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3058 - acc: 0.8997 - auc: 0.6809 - val_loss: 0.4133 - val_acc: 0.8716 - val_auc: 0.6912\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8998 - auc: 0.6827 - val_loss: 0.4107 - val_acc: 0.8310 - val_auc: 0.6896\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8999 - auc: 0.6824 - val_loss: 0.3711 - val_acc: 0.8866 - val_auc: 0.6935\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8997 - auc: 0.6821 - val_loss: 0.4311 - val_acc: 0.8765 - val_auc: 0.6932\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3056 - acc: 0.8996 - auc: 0.6817 - val_loss: 0.4251 - val_acc: 0.8396 - val_auc: 0.6893\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8998 - auc: 0.6819 - val_loss: 0.4488 - val_acc: 0.8251 - val_auc: 0.6929\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8999 - auc: 0.6818 - val_loss: 0.3839 - val_acc: 0.8629 - val_auc: 0.6901\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3053 - acc: 0.8997 - auc: 0.6819 - val_loss: 0.3508 - val_acc: 0.8828 - val_auc: 0.6930\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3048 - acc: 0.8998 - auc: 0.6847 - val_loss: 0.4443 - val_acc: 0.8017 - val_auc: 0.6865\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8997 - auc: 0.6829 - val_loss: 0.4106 - val_acc: 0.8464 - val_auc: 0.6938\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3053 - acc: 0.8997 - auc: 0.6814 - val_loss: 0.3413 - val_acc: 0.8995 - val_auc: 0.6940\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8998 - auc: 0.6826 - val_loss: 0.5233 - val_acc: 0.7342 - val_auc: 0.6935\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8999 - auc: 0.6826 - val_loss: 0.4903 - val_acc: 0.7860 - val_auc: 0.6934\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3048 - acc: 0.8998 - auc: 0.6843 - val_loss: 0.6796 - val_acc: 0.6061 - val_auc: 0.6937\n",
      "Epoch 38/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8997 - auc: 0.6825 - val_loss: 0.4330 - val_acc: 0.8168 - val_auc: 0.6930\n",
      "Epoch 39/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3049 - acc: 0.8998 - auc: 0.6840 - val_loss: 0.4068 - val_acc: 0.8442 - val_auc: 0.6932\n",
      "Epoch 40/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3048 - acc: 0.8998 - auc: 0.6840 - val_loss: 0.3492 - val_acc: 0.8907 - val_auc: 0.6932\n",
      "Epoch 41/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3048 - acc: 0.8996 - auc: 0.6853 - val_loss: 0.3099 - val_acc: 0.9008 - val_auc: 0.6937\n",
      "Epoch 42/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3051 - acc: 0.8998 - auc: 0.6831 - val_loss: 0.4233 - val_acc: 0.8337 - val_auc: 0.6917\n",
      "Epoch 43/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3048 - acc: 0.8997 - auc: 0.6844 - val_loss: 0.4969 - val_acc: 0.8066 - val_auc: 0.6933\n",
      "Epoch 44/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8997 - auc: 0.6833 - val_loss: 0.3960 - val_acc: 0.8672 - val_auc: 0.6933\n",
      "Epoch 45/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3052 - acc: 0.8997 - auc: 0.6820 - val_loss: 0.4381 - val_acc: 0.8458 - val_auc: 0.6935\n",
      "Epoch 46/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3049 - acc: 0.8997 - auc: 0.6831 - val_loss: 0.3806 - val_acc: 0.8738 - val_auc: 0.6933\n",
      "Epoch 47/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3049 - acc: 0.8997 - auc: 0.6846 - val_loss: 0.3995 - val_acc: 0.8807 - val_auc: 0.6936\n",
      "Epoch 48/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3048 - acc: 0.8999 - auc: 0.6832 - val_loss: 0.4966 - val_acc: 0.8281 - val_auc: 0.6941\n",
      "Epoch 49/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3045 - acc: 0.8997 - auc: 0.6843 - val_loss: 0.8063 - val_acc: 0.4363 - val_auc: 0.6936\n",
      "Epoch 50/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3050 - acc: 0.8996 - auc: 0.6841 - val_loss: 0.3812 - val_acc: 0.8572 - val_auc: 0.6939\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 5s 37us/step - loss: 0.3072 - acc: 0.8995 - auc: 0.6788 - val_loss: 0.3125 - val_acc: 0.8995 - val_auc: 0.6872\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3067 - acc: 0.8994 - auc: 0.6787 - val_loss: 0.6424 - val_acc: 0.8995 - val_auc: 0.6892\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3064 - acc: 0.8994 - auc: 0.6806 - val_loss: 0.3175 - val_acc: 0.8995 - val_auc: 0.6875\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3069 - acc: 0.8995 - auc: 0.6769 - val_loss: 0.4237 - val_acc: 0.8313 - val_auc: 0.6876\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3072 - acc: 0.8995 - auc: 0.6763 - val_loss: 0.3133 - val_acc: 0.8995 - val_auc: 0.6860\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3075 - acc: 0.8994 - auc: 0.6748 - val_loss: 0.6815 - val_acc: 0.6040 - val_auc: 0.6860\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3066 - acc: 0.8995 - auc: 0.6789 - val_loss: 0.3171 - val_acc: 0.8995 - val_auc: 0.6894\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3065 - acc: 0.8998 - auc: 0.6780 - val_loss: 0.6853 - val_acc: 0.7533 - val_auc: 0.3674\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3063 - acc: 0.8995 - auc: 0.6799 - val_loss: 0.3409 - val_acc: 0.8733 - val_auc: 0.6890\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3063 - acc: 0.8994 - auc: 0.6812 - val_loss: 0.3049 - val_acc: 0.8995 - val_auc: 0.6890\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3063 - acc: 0.8994 - auc: 0.6801 - val_loss: 0.3170 - val_acc: 0.8995 - val_auc: 0.6897\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3061 - acc: 0.8994 - auc: 0.6793 - val_loss: 0.3093 - val_acc: 0.8995 - val_auc: 0.6911\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3065 - acc: 0.8995 - auc: 0.6792 - val_loss: 0.5249 - val_acc: 0.8995 - val_auc: 0.5963\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3062 - acc: 0.8995 - auc: 0.6810 - val_loss: 0.3043 - val_acc: 0.8995 - val_auc: 0.6892\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3059 - acc: 0.8996 - auc: 0.6805 - val_loss: 0.3193 - val_acc: 0.8999 - val_auc: 0.6889\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3060 - acc: 0.8994 - auc: 0.6819 - val_loss: 0.4856 - val_acc: 0.8995 - val_auc: 0.6876\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3059 - acc: 0.8995 - auc: 0.6816 - val_loss: 0.3078 - val_acc: 0.8995 - val_auc: 0.6914\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3058 - acc: 0.8994 - auc: 0.6812 - val_loss: 0.3813 - val_acc: 0.9002 - val_auc: 0.6910\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3059 - acc: 0.8996 - auc: 0.6805 - val_loss: 0.3639 - val_acc: 0.8995 - val_auc: 0.6818\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3064 - acc: 0.8997 - auc: 0.6786 - val_loss: 0.8974 - val_acc: 0.1395 - val_auc: 0.6833\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8997 - auc: 0.6823 - val_loss: 0.4995 - val_acc: 0.7251 - val_auc: 0.6608\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3054 - acc: 0.8995 - auc: 0.6823 - val_loss: 0.4269 - val_acc: 0.7976 - val_auc: 0.6891\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3055 - acc: 0.8995 - auc: 0.6829 - val_loss: 0.3761 - val_acc: 0.8995 - val_auc: 0.6876\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3064 - acc: 0.8994 - auc: 0.6795 - val_loss: 0.5082 - val_acc: 0.9004 - val_auc: 0.6892\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3058 - acc: 0.8994 - auc: 0.6804 - val_loss: 0.4273 - val_acc: 0.8998 - val_auc: 0.6891\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3051 - acc: 0.8995 - auc: 0.6832 - val_loss: 0.4446 - val_acc: 0.7784 - val_auc: 0.6903\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3055 - acc: 0.8995 - auc: 0.6823 - val_loss: 0.6174 - val_acc: 0.8722 - val_auc: 0.6690\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3058 - acc: 0.8994 - auc: 0.6809 - val_loss: 0.5521 - val_acc: 0.8814 - val_auc: 0.6852\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3054 - acc: 0.8996 - auc: 0.6820 - val_loss: 0.6394 - val_acc: 0.7997 - val_auc: 0.6809\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3054 - acc: 0.8995 - auc: 0.6818 - val_loss: 0.4416 - val_acc: 0.8811 - val_auc: 0.6861\n",
      "Epoch 31/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3051 - acc: 0.8995 - auc: 0.6821 - val_loss: 0.3117 - val_acc: 0.8995 - val_auc: 0.6897\n",
      "Epoch 32/50\n",
      "144000/144000 [==============================] - 6s 39us/step - loss: 0.3053 - acc: 0.8996 - auc: 0.6818 - val_loss: 0.4599 - val_acc: 0.7234 - val_auc: 0.6904\n",
      "Epoch 33/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3048 - acc: 0.8996 - auc: 0.6838 - val_loss: 0.4994 - val_acc: 0.8344 - val_auc: 0.6884\n",
      "Epoch 34/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3050 - acc: 0.8996 - auc: 0.6832 - val_loss: 0.3811 - val_acc: 0.8894 - val_auc: 0.6881\n",
      "Epoch 35/50\n",
      "144000/144000 [==============================] - 5s 38us/step - loss: 0.3051 - acc: 0.8994 - auc: 0.6836 - val_loss: 0.3550 - val_acc: 0.9001 - val_auc: 0.6907\n",
      "Epoch 36/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3053 - acc: 0.8998 - auc: 0.6817 - val_loss: 0.3408 - val_acc: 0.8930 - val_auc: 0.6899\n",
      "Epoch 37/50\n",
      "144000/144000 [==============================] - 6s 38us/step - loss: 0.3049 - acc: 0.8997 - auc: 0.6840 - val_loss: 0.4837 - val_acc: 0.7906 - val_auc: 0.6899\n",
      "Run time 19.741335360209145 min\n"
     ]
    }
   ],
   "source": [
    "sequential_nn_model_1_4_var_1 = train_nn(train_polinomial_values_ucm_1_4, train_target_values_ucm_1_4, sequential_nn_model, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 49us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics =  sequential_nn_model_1_4_var_1.evaluate(holdout_test_polinomial_values_ucm_1_4, holdout_test_target_values_ucm_1_4, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48339757457375526, 0.7943749980628491, 0.6942529990401859]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn_ucm_1_2 = train_nn_result_ucm_1_2.predict(test_values_ucm_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn_ucm_1_4_1_2 = sequential_nn_model_min_1_4_1_2_var_1.predict(test_polinomial_values_ucm_1_4_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn_ucm_1_4 = sequential_nn_model_1_4_var_1.predict(test_polinomial_values_ucm_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_nn_ucm_1_2 = pd.DataFrame({'ID_code': ID_code, 'target': prediction_nn_ucm_1_2[:, 0].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_nn_ucm_1_4_1_2 = pd.DataFrame({'ID_code': ID_code, 'target': prediction_nn_ucm_1_4_1_2[:, 0].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_nn_ucm_1_4 = pd.DataFrame({'ID_code': ID_code, 'target': prediction_nn_ucm_1_4[:, 0].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_9_prediction = simply_blend(\n",
    "    [\n",
    "        predictions_df,\n",
    "        predictions_df_ucm_1_4_1_2,\n",
    "        predictions_df_ucm_1_4,\n",
    "        predictions_df_more_1_2,\n",
    "        predictions_df_whole,\n",
    "        predictions_df_less_1_4,\n",
    "        submission_df_nn_ucm_1_2,\n",
    "        submission_df_nn_ucm_1_4_1_2,\n",
    "        submission_df_nn_ucm_1_4\n",
    "    ],\n",
    "    [3, 1, 1, 1, 8, 1, 3, 1, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_9_prediction.to_csv('blended_9_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.269252\n",
       "1    0.276680\n",
       "2    0.239855\n",
       "3    0.191431\n",
       "4    0.168770\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blended_9_prediction)\n",
    "blended_9_prediction['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_9_prediction_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_9_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.269252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.276680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.239855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.191431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.168770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.269252\n",
       "1  test_1  0.276680\n",
       "2  test_2  0.239855\n",
       "3  test_3  0.191431\n",
       "4  test_4  0.168770"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_9_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_9_prediction_df.to_csv('blended_9_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_1_lgb_and_3_nn = simply_blend(\n",
    "    [\n",
    "        predictions_df_whole,\n",
    "        submission_df_nn_ucm_1_2,\n",
    "        submission_df_nn_ucm_1_4_1_2,\n",
    "        submission_df_nn_ucm_1_4\n",
    "    ],\n",
    "    [8, 3, 1, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_1_lgb_and_3_nn_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_1_lgb_and_3_nn['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_1_lgb_and_3_nn_df.to_csv('blended_1_lgb_and_3_nn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.0184 var_81\n",
    "0.0155 var_139\n",
    "0.0148 var_12\n",
    "0.0133 var_53\n",
    "0.0130 var_174\n",
    "0.0128 var_6\n",
    "0.0127 var_110\n",
    "0.0124 var_22\n",
    "0.0123 var_146\n",
    "0.0123 var_26\n",
    "0.0116 var_76\n",
    "0.0112 var_166\n",
    "0.0111 var_99\n",
    "0.0109 var_80\n",
    "0.0109 var_21\n",
    "0.0104 var_13\n",
    "0.0103 var_2\n",
    "0.0103 var_165\n",
    "0.0101 var_190\n",
    "0.0101 var_109\n",
    "0.0101 var_133\n",
    "0.0099 var_0\n",
    "0.0098 var_148\n",
    "0.0098 var_198\n",
    "0.0097 var_34\n",
    "0.0097 var_40\n",
    "0.0095 var_78\n",
    "0.0093 var_1\n",
    "0.0093 var_44\n",
    "0.0089 var_179\n",
    "0.0088 var_164\n",
    "0.0087 var_108\n",
    "0.0086 var_33\n",
    "0.0083 var_92\n",
    "0.0083 var_94\n",
    "0.0082 var_115\n",
    "0.0082 var_184\n",
    "0.0082 var_169\n",
    "0.0081 var_170\n",
    "0.0080 var_154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1      108932\n",
       "var_5      141029\n",
       "var_7      103063\n",
       "var_10     128764\n",
       "var_11     130193\n",
       "var_13     115181\n",
       "var_17     137823\n",
       "var_18     139515\n",
       "var_19     144180\n",
       "var_20     127764\n",
       "var_21     140062\n",
       "var_24     105101\n",
       "var_26     127089\n",
       "var_30     145977\n",
       "var_33     112239\n",
       "var_35     122384\n",
       "var_38     115366\n",
       "var_39     112674\n",
       "var_40     141878\n",
       "var_41     131896\n",
       "var_44     127702\n",
       "var_45     169968\n",
       "var_47     154781\n",
       "var_48     152039\n",
       "var_49     140641\n",
       "var_51     143455\n",
       "var_52     121313\n",
       "var_54     144776\n",
       "var_55     128077\n",
       "var_56     103045\n",
       "            ...  \n",
       "var_149    148504\n",
       "var_151    109667\n",
       "var_154    119342\n",
       "var_155    127457\n",
       "var_157    126534\n",
       "var_158    144556\n",
       "var_159    112830\n",
       "var_160    156274\n",
       "var_163    123168\n",
       "var_164    122744\n",
       "var_165    119403\n",
       "var_167    140954\n",
       "var_170    113720\n",
       "var_171    125914\n",
       "var_172    143366\n",
       "var_173    128120\n",
       "var_174    134945\n",
       "var_176    142521\n",
       "var_178    145235\n",
       "var_180    123477\n",
       "var_182    149195\n",
       "var_183    117529\n",
       "var_184    145184\n",
       "var_185    120747\n",
       "var_187    157031\n",
       "var_188    108813\n",
       "var_190    114959\n",
       "var_193    110557\n",
       "var_196    125560\n",
       "var_199    149430\n",
       "Length: 110, dtype: int64"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impact_features import impact_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_81',\n",
       " 'var_139',\n",
       " 'var_12',\n",
       " 'var_53',\n",
       " 'var_174',\n",
       " 'var_6',\n",
       " 'var_110',\n",
       " 'var_22',\n",
       " 'var_146',\n",
       " 'var_26',\n",
       " 'var_76',\n",
       " 'var_166',\n",
       " 'var_99',\n",
       " 'var_80',\n",
       " 'var_21',\n",
       " 'var_13',\n",
       " 'var_2',\n",
       " 'var_165',\n",
       " 'var_190',\n",
       " 'var_109',\n",
       " 'var_133',\n",
       " 'var_0',\n",
       " 'var_148',\n",
       " 'var_198',\n",
       " 'var_34',\n",
       " 'var_40',\n",
       " 'var_78',\n",
       " 'var_1',\n",
       " 'var_44',\n",
       " 'var_179',\n",
       " 'var_164',\n",
       " 'var_108',\n",
       " 'var_33',\n",
       " 'var_92',\n",
       " 'var_94',\n",
       " 'var_115',\n",
       " 'var_184',\n",
       " 'var_169',\n",
       " 'var_170',\n",
       " 'var_154']"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_2_features = uniques_count_more_1_2.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1',\n",
       " 'var_5',\n",
       " 'var_7',\n",
       " 'var_10',\n",
       " 'var_11',\n",
       " 'var_13',\n",
       " 'var_17',\n",
       " 'var_18',\n",
       " 'var_19',\n",
       " 'var_20',\n",
       " 'var_21',\n",
       " 'var_24',\n",
       " 'var_26',\n",
       " 'var_30',\n",
       " 'var_33',\n",
       " 'var_35',\n",
       " 'var_38',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_41',\n",
       " 'var_44',\n",
       " 'var_45',\n",
       " 'var_47',\n",
       " 'var_48',\n",
       " 'var_49',\n",
       " 'var_51',\n",
       " 'var_52',\n",
       " 'var_54',\n",
       " 'var_55',\n",
       " 'var_56',\n",
       " 'var_58',\n",
       " 'var_60',\n",
       " 'var_61',\n",
       " 'var_65',\n",
       " 'var_67',\n",
       " 'var_69',\n",
       " 'var_70',\n",
       " 'var_72',\n",
       " 'var_73',\n",
       " 'var_74',\n",
       " 'var_75',\n",
       " 'var_76',\n",
       " 'var_77',\n",
       " 'var_80',\n",
       " 'var_82',\n",
       " 'var_83',\n",
       " 'var_84',\n",
       " 'var_85',\n",
       " 'var_86',\n",
       " 'var_87',\n",
       " 'var_89',\n",
       " 'var_90',\n",
       " 'var_92',\n",
       " 'var_96',\n",
       " 'var_97',\n",
       " 'var_100',\n",
       " 'var_101',\n",
       " 'var_102',\n",
       " 'var_107',\n",
       " 'var_109',\n",
       " 'var_110',\n",
       " 'var_113',\n",
       " 'var_117',\n",
       " 'var_118',\n",
       " 'var_119',\n",
       " 'var_120',\n",
       " 'var_122',\n",
       " 'var_123',\n",
       " 'var_129',\n",
       " 'var_134',\n",
       " 'var_135',\n",
       " 'var_136',\n",
       " 'var_137',\n",
       " 'var_138',\n",
       " 'var_139',\n",
       " 'var_140',\n",
       " 'var_141',\n",
       " 'var_142',\n",
       " 'var_145',\n",
       " 'var_147',\n",
       " 'var_149',\n",
       " 'var_151',\n",
       " 'var_154',\n",
       " 'var_155',\n",
       " 'var_157',\n",
       " 'var_158',\n",
       " 'var_159',\n",
       " 'var_160',\n",
       " 'var_163',\n",
       " 'var_164',\n",
       " 'var_165',\n",
       " 'var_167',\n",
       " 'var_170',\n",
       " 'var_171',\n",
       " 'var_172',\n",
       " 'var_173',\n",
       " 'var_174',\n",
       " 'var_176',\n",
       " 'var_178',\n",
       " 'var_180',\n",
       " 'var_182',\n",
       " 'var_183',\n",
       " 'var_184',\n",
       " 'var_185',\n",
       " 'var_187',\n",
       " 'var_188',\n",
       " 'var_190',\n",
       " 'var_193',\n",
       " 'var_196',\n",
       " 'var_199']"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_features_set = set(impact_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_2_features_set = set(uniques_count_more_1_2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_1_2 = impact_features_set.intersection(uniques_count_more_1_2_features_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersect_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_1',\n",
       " 'var_109',\n",
       " 'var_110',\n",
       " 'var_13',\n",
       " 'var_139',\n",
       " 'var_154',\n",
       " 'var_164',\n",
       " 'var_165',\n",
       " 'var_170',\n",
       " 'var_174',\n",
       " 'var_184',\n",
       " 'var_190',\n",
       " 'var_21',\n",
       " 'var_26',\n",
       " 'var_33',\n",
       " 'var_40',\n",
       " 'var_44',\n",
       " 'var_76',\n",
       " 'var_80',\n",
       " 'var_92'}"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_1_4_1_2 = impact_features_set.intersection(uniques_count_more_1_4_less_1_2.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersect_1_4_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_0',\n",
       " 'var_108',\n",
       " 'var_115',\n",
       " 'var_12',\n",
       " 'var_133',\n",
       " 'var_146',\n",
       " 'var_148',\n",
       " 'var_166',\n",
       " 'var_169',\n",
       " 'var_179',\n",
       " 'var_198',\n",
       " 'var_2',\n",
       " 'var_22',\n",
       " 'var_34',\n",
       " 'var_53',\n",
       " 'var_6',\n",
       " 'var_78',\n",
       " 'var_81',\n",
       " 'var_94',\n",
       " 'var_99'}"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_1_4_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_1_4 = impact_features_set.intersection(uniques_count_less_1_4.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersect_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_108',\n",
       " 'var_12',\n",
       " 'var_133',\n",
       " 'var_148',\n",
       " 'var_166',\n",
       " 'var_169',\n",
       " 'var_34',\n",
       " 'var_53',\n",
       " 'var_6'}"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
