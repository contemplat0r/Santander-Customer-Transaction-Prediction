{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import cluster\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras import callbacks\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_id_droped = train_df[train_df.columns.drop('ID_code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94672,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['var_0'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.apply(pd.unique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_dict = {column_name: train_df_id_droped[column_name].unique() for column_name in train_df_id_droped.columns.drop('target').tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_dict_counts = {column_name: uniques.shape[0] for column_name, uniques in uniques_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_counts_series = pd.Series(uniques_dict_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_0     94672\n",
       "var_1    108932\n",
       "var_2     86555\n",
       "var_3     74597\n",
       "var_4     63515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_counts_series.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = plt.figure(figsize=(24, 18))\\nax = fig.add_subplot(111)\\nax.bar(np.arange(200), uniques_counts_series.values.astype(np.int64))\\n#ax.bar(uniques_counts_series)\\nax.set_title('Features uniques values num')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(200), uniques_counts_series.values.astype(np.int64))\n",
    "#ax.bar(uniques_counts_series)\n",
    "ax.set_title('Features uniques values num')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cells execution time: 0.33239564498265584 min\n"
     ]
    }
   ],
   "source": [
    "all_cells_execution_time = time.time() - start_time\n",
    "print(\"all cells execution time: {} min\".format(all_cells_execution_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_id_droped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(24, 18))\\nplt.title(\"Distributon of unqie values per column in the train dataset\")\\n#sns.distplot(train_df_id_droped[train_df_id_droped.columns.drop(\\'target\\').tolist()].unique(), color=\\'green\\', kde=True, bins=200, label=\"train\")\\nsns.distplot(uniques_counts_series.values.astype(np.int64), color=\\'green\\', kde=True, bins=200, label=\"train\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(24, 18))\n",
    "plt.title(\"Distributon of unqie values per column in the train dataset\")\n",
    "#sns.distplot(train_df_id_droped[train_df_id_droped.columns.drop('target').tolist()].unique(), color='green', kde=True, bins=200, label=\"train\")\n",
    "sns.distplot(uniques_counts_series.values.astype(np.int64), color='green', kde=True, bins=200, label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = train_df.columns.values[2:202]\\nplt.figure(figsize=(24, 18))\\nplt.title(\"Distribution of mean values per column in the train and test set\")\\nsns.distplot(train_df[features].mean(axis=0), color=\"magenta\", kde=True,bins=120, label=\\'train\\')\\n#sns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label=\\'test\\')\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.figure(figsize=(24, 18))\n",
    "plt.title(\"Distribution of mean values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].mean(axis=0), color=\"magenta\", kde=True,bins=120, label='train')\n",
    "#sns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(24, 18))\\nfeatures = train_df.columns.values[2:202]\\n#plt.title(\"Distribution of mean values per row in the train and test set\")\\nplt.title(\"Distribution of mean values per row in the train set\")\\nsns.distplot(train_df[features].mean(axis=1), color=\"blue\", kde=True, bins=120, label=\\'train\\')\\n#sns.distplot(test_df[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label=\\'test\\')\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(24, 18))\n",
    "features = train_df.columns.values[2:202]\n",
    "#plt.title(\"Distribution of mean values per row in the train and test set\")\n",
    "plt.title(\"Distribution of mean values per row in the train set\")\n",
    "sns.distplot(train_df[features].mean(axis=1), color=\"blue\", kde=True, bins=120, label='train')\n",
    "#sns.distplot(test_df[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\\noof = np.zeros(len(train_df))\\npredictions = np.zeros(len(test_df))\\nfeature_importance_df = pd.DataFrame()\\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\\n    print(\"Fold {}\".format(fold_))\\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\\n    num_round = 1000000\\n    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\\n    fold_importance_df = pd.DataFrame()\\n    fold_importance_df[\\'Feature\\'] = features\\n    fold_importance_df[\\'importance\\'] = clf.feature_importance()\\n    fold_importance_df[\\'fold\\'] = fold_ + 1\\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['importance'] = clf.feature_importance()\n",
    "    fold_importance_df['fold'] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols = (feature_importance_df[[\"Feature\", \"importance\"]]\\n        .groupby(\"Feature\")\\n        .mean()\\n        .sort_values(by=\"importance\", ascending=False)[:150].index)\\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\\n\\nplt.figure(figsize=(14,28))\\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\\nplt.title(\\'Features importance (averaged/folds)\\')\\nplt.tight_layout()\\nplt.savefig(\\'FI.png\\')\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rows_count = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_rows_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_2 = uniques_counts_series[uniques_counts_series > train_df_rows_count / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_more_1_4_less_1_2 = uniques_counts_series[uniques_counts_series < train_df_rows_count / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniques_count_less_1_2_more_1_4 = uniques_counts_series[\n",
    "#    ((uniques_counts_series < train_df_rows_count / 2).bool() and (uniques_counts_series > train_df_rows_count / 4).bool()).bool()\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_less_1_2_more_1_4 = uniques_count_more_1_4_less_1_2[uniques_count_more_1_4_less_1_2 > train_df_rows_count / 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_more_1_4_less_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_count_less_1_4 = uniques_counts_series[uniques_counts_series < train_df_rows_count / 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_less_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_6     38599\n",
       "var_9     49417\n",
       "var_12     9561\n",
       "var_15    19810\n",
       "var_23    24913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques_count_less_1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniques_count_less_1_4.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, target, features, param, num_round=1000000):\n",
    "    start_time = time.time()\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "    oof = np.zeros(len(train_df))\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    lgb_classifier = None\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "        num_round = num_round\n",
    "        clf = lgb.train(\n",
    "            param,\n",
    "            trn_data,\n",
    "            num_round,\n",
    "            valid_sets=[trn_data, val_data],\n",
    "            verbose_eval=1000,\n",
    "            early_stopping_rounds=3000\n",
    "        )\n",
    "        lgb_classifier = clf\n",
    "        oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['Feature'] = features\n",
    "        fold_importance_df['importance'] = clf.feature_importance()\n",
    "        fold_importance_df['fold'] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    print(\"Total run time {} min:\".format((time.time() - start_time) / 60))\n",
    "    print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "    return oof, predictions, feature_importance_df, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.836449\tvalid_1's auc: 0.819362\n",
      "[2000]\ttraining's auc: 0.845447\tvalid_1's auc: 0.823533\n",
      "[3000]\ttraining's auc: 0.852066\tvalid_1's auc: 0.82583\n",
      "[4000]\ttraining's auc: 0.858253\tvalid_1's auc: 0.826207\n",
      "[5000]\ttraining's auc: 0.864232\tvalid_1's auc: 0.826657\n",
      "[6000]\ttraining's auc: 0.869822\tvalid_1's auc: 0.826773\n",
      "[7000]\ttraining's auc: 0.875256\tvalid_1's auc: 0.826797\n",
      "[8000]\ttraining's auc: 0.880766\tvalid_1's auc: 0.826868\n",
      "[9000]\ttraining's auc: 0.886046\tvalid_1's auc: 0.826551\n",
      "[10000]\ttraining's auc: 0.89129\tvalid_1's auc: 0.826084\n",
      "Early stopping, best iteration is:\n",
      "[7789]\ttraining's auc: 0.879598\tvalid_1's auc: 0.826957\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837076\tvalid_1's auc: 0.81285\n",
      "[2000]\ttraining's auc: 0.845801\tvalid_1's auc: 0.817226\n",
      "[3000]\ttraining's auc: 0.852524\tvalid_1's auc: 0.819153\n",
      "[4000]\ttraining's auc: 0.858646\tvalid_1's auc: 0.820293\n",
      "[5000]\ttraining's auc: 0.86449\tvalid_1's auc: 0.820602\n",
      "[6000]\ttraining's auc: 0.870205\tvalid_1's auc: 0.820765\n",
      "[7000]\ttraining's auc: 0.875586\tvalid_1's auc: 0.821063\n",
      "[8000]\ttraining's auc: 0.881104\tvalid_1's auc: 0.820872\n",
      "[9000]\ttraining's auc: 0.886385\tvalid_1's auc: 0.82061\n",
      "[10000]\ttraining's auc: 0.89155\tvalid_1's auc: 0.820347\n",
      "Early stopping, best iteration is:\n",
      "[7150]\ttraining's auc: 0.876402\tvalid_1's auc: 0.821213\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838141\tvalid_1's auc: 0.807929\n",
      "[2000]\ttraining's auc: 0.846529\tvalid_1's auc: 0.811863\n",
      "[3000]\ttraining's auc: 0.853191\tvalid_1's auc: 0.813311\n",
      "[4000]\ttraining's auc: 0.859342\tvalid_1's auc: 0.814044\n",
      "[5000]\ttraining's auc: 0.865203\tvalid_1's auc: 0.814173\n",
      "[6000]\ttraining's auc: 0.870852\tvalid_1's auc: 0.813993\n",
      "[7000]\ttraining's auc: 0.876352\tvalid_1's auc: 0.813619\n",
      "[8000]\ttraining's auc: 0.881739\tvalid_1's auc: 0.813524\n",
      "Early stopping, best iteration is:\n",
      "[5294]\ttraining's auc: 0.866862\tvalid_1's auc: 0.814361\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83737\tvalid_1's auc: 0.814511\n",
      "[2000]\ttraining's auc: 0.84593\tvalid_1's auc: 0.818681\n",
      "[3000]\ttraining's auc: 0.852735\tvalid_1's auc: 0.820327\n",
      "[4000]\ttraining's auc: 0.858933\tvalid_1's auc: 0.821008\n",
      "[5000]\ttraining's auc: 0.864774\tvalid_1's auc: 0.821135\n",
      "[6000]\ttraining's auc: 0.870494\tvalid_1's auc: 0.82112\n",
      "[7000]\ttraining's auc: 0.875947\tvalid_1's auc: 0.821159\n",
      "[8000]\ttraining's auc: 0.881307\tvalid_1's auc: 0.820649\n",
      "[9000]\ttraining's auc: 0.886576\tvalid_1's auc: 0.820463\n",
      "Early stopping, best iteration is:\n",
      "[6494]\ttraining's auc: 0.873253\tvalid_1's auc: 0.821365\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837201\tvalid_1's auc: 0.815883\n",
      "[2000]\ttraining's auc: 0.845801\tvalid_1's auc: 0.818807\n",
      "[3000]\ttraining's auc: 0.852523\tvalid_1's auc: 0.82041\n",
      "[4000]\ttraining's auc: 0.858805\tvalid_1's auc: 0.820887\n",
      "[5000]\ttraining's auc: 0.864648\tvalid_1's auc: 0.820858\n",
      "[6000]\ttraining's auc: 0.870328\tvalid_1's auc: 0.820962\n",
      "[7000]\ttraining's auc: 0.875798\tvalid_1's auc: 0.820743\n",
      "Early stopping, best iteration is:\n",
      "[4169]\ttraining's auc: 0.859817\tvalid_1's auc: 0.821108\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.836614\tvalid_1's auc: 0.816979\n",
      "[2000]\ttraining's auc: 0.845298\tvalid_1's auc: 0.8223\n",
      "[3000]\ttraining's auc: 0.852074\tvalid_1's auc: 0.823567\n",
      "[4000]\ttraining's auc: 0.85838\tvalid_1's auc: 0.824654\n",
      "[5000]\ttraining's auc: 0.864291\tvalid_1's auc: 0.825168\n",
      "[6000]\ttraining's auc: 0.870026\tvalid_1's auc: 0.825245\n",
      "[7000]\ttraining's auc: 0.875607\tvalid_1's auc: 0.824881\n",
      "[8000]\ttraining's auc: 0.880936\tvalid_1's auc: 0.824322\n",
      "Early stopping, best iteration is:\n",
      "[5646]\ttraining's auc: 0.868012\tvalid_1's auc: 0.825416\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837153\tvalid_1's auc: 0.816308\n",
      "[2000]\ttraining's auc: 0.845773\tvalid_1's auc: 0.819828\n",
      "[3000]\ttraining's auc: 0.852615\tvalid_1's auc: 0.821906\n",
      "[4000]\ttraining's auc: 0.858637\tvalid_1's auc: 0.822926\n",
      "[5000]\ttraining's auc: 0.8646\tvalid_1's auc: 0.82323\n",
      "[6000]\ttraining's auc: 0.87036\tvalid_1's auc: 0.823403\n",
      "[7000]\ttraining's auc: 0.875825\tvalid_1's auc: 0.823228\n",
      "[8000]\ttraining's auc: 0.881214\tvalid_1's auc: 0.823043\n",
      "Early stopping, best iteration is:\n",
      "[5996]\ttraining's auc: 0.870341\tvalid_1's auc: 0.823436\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837297\tvalid_1's auc: 0.814775\n",
      "[2000]\ttraining's auc: 0.845852\tvalid_1's auc: 0.818869\n",
      "[3000]\ttraining's auc: 0.852618\tvalid_1's auc: 0.820686\n",
      "[4000]\ttraining's auc: 0.858746\tvalid_1's auc: 0.820824\n",
      "[5000]\ttraining's auc: 0.864679\tvalid_1's auc: 0.82129\n",
      "[6000]\ttraining's auc: 0.870403\tvalid_1's auc: 0.821242\n",
      "[7000]\ttraining's auc: 0.875887\tvalid_1's auc: 0.821146\n",
      "[8000]\ttraining's auc: 0.881266\tvalid_1's auc: 0.821139\n",
      "Early stopping, best iteration is:\n",
      "[5110]\ttraining's auc: 0.865289\tvalid_1's auc: 0.821403\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837407\tvalid_1's auc: 0.818679\n",
      "[2000]\ttraining's auc: 0.845927\tvalid_1's auc: 0.822556\n",
      "[3000]\ttraining's auc: 0.852328\tvalid_1's auc: 0.823827\n",
      "[4000]\ttraining's auc: 0.858727\tvalid_1's auc: 0.824384\n",
      "[5000]\ttraining's auc: 0.864571\tvalid_1's auc: 0.824331\n",
      "[6000]\ttraining's auc: 0.870117\tvalid_1's auc: 0.824362\n",
      "[7000]\ttraining's auc: 0.875658\tvalid_1's auc: 0.824355\n",
      "Early stopping, best iteration is:\n",
      "[4415]\ttraining's auc: 0.861206\tvalid_1's auc: 0.824684\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.837504\tvalid_1's auc: 0.81507\n",
      "[2000]\ttraining's auc: 0.846349\tvalid_1's auc: 0.818156\n",
      "[3000]\ttraining's auc: 0.852866\tvalid_1's auc: 0.819337\n",
      "[4000]\ttraining's auc: 0.859122\tvalid_1's auc: 0.819734\n",
      "[5000]\ttraining's auc: 0.864944\tvalid_1's auc: 0.820142\n",
      "[6000]\ttraining's auc: 0.870478\tvalid_1's auc: 0.819976\n",
      "[7000]\ttraining's auc: 0.876074\tvalid_1's auc: 0.819546\n",
      "[8000]\ttraining's auc: 0.881559\tvalid_1's auc: 0.819124\n",
      "Early stopping, best iteration is:\n",
      "[5267]\ttraining's auc: 0.866477\tvalid_1's auc: 0.820232\n",
      "Total run time 18.519540925820667 min:\n",
      "CV score: 0.82181 \n"
     ]
    }
   ],
   "source": [
    "train_results_more_1_2 = train(train_df, test_df, target, uniques_count_more_1_2.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772379\tvalid_1's auc: 0.741305\n",
      "[2000]\ttraining's auc: 0.778907\tvalid_1's auc: 0.742285\n",
      "[3000]\ttraining's auc: 0.78477\tvalid_1's auc: 0.742419\n",
      "[4000]\ttraining's auc: 0.790565\tvalid_1's auc: 0.742499\n",
      "[5000]\ttraining's auc: 0.796234\tvalid_1's auc: 0.742592\n",
      "Early stopping, best iteration is:\n",
      "[2500]\ttraining's auc: 0.782039\tvalid_1's auc: 0.742856\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771593\tvalid_1's auc: 0.748627\n",
      "[2000]\ttraining's auc: 0.778487\tvalid_1's auc: 0.749908\n",
      "[3000]\ttraining's auc: 0.784376\tvalid_1's auc: 0.749326\n",
      "[4000]\ttraining's auc: 0.790141\tvalid_1's auc: 0.74907\n",
      "[5000]\ttraining's auc: 0.795899\tvalid_1's auc: 0.749057\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's auc: 0.779966\tvalid_1's auc: 0.750254\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772997\tvalid_1's auc: 0.737963\n",
      "[2000]\ttraining's auc: 0.779626\tvalid_1's auc: 0.739392\n",
      "[3000]\ttraining's auc: 0.785579\tvalid_1's auc: 0.73971\n",
      "[4000]\ttraining's auc: 0.791248\tvalid_1's auc: 0.73936\n",
      "[5000]\ttraining's auc: 0.796893\tvalid_1's auc: 0.739274\n",
      "[6000]\ttraining's auc: 0.80269\tvalid_1's auc: 0.739035\n",
      "Early stopping, best iteration is:\n",
      "[3161]\ttraining's auc: 0.786431\tvalid_1's auc: 0.739781\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771872\tvalid_1's auc: 0.747499\n",
      "[2000]\ttraining's auc: 0.778401\tvalid_1's auc: 0.748093\n",
      "[3000]\ttraining's auc: 0.784342\tvalid_1's auc: 0.74764\n",
      "[4000]\ttraining's auc: 0.790019\tvalid_1's auc: 0.74776\n",
      "Early stopping, best iteration is:\n",
      "[1744]\ttraining's auc: 0.776637\tvalid_1's auc: 0.748236\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771952\tvalid_1's auc: 0.74676\n",
      "[2000]\ttraining's auc: 0.778441\tvalid_1's auc: 0.748555\n",
      "[3000]\ttraining's auc: 0.784194\tvalid_1's auc: 0.749124\n",
      "[4000]\ttraining's auc: 0.790029\tvalid_1's auc: 0.749077\n",
      "[5000]\ttraining's auc: 0.795629\tvalid_1's auc: 0.749408\n",
      "[6000]\ttraining's auc: 0.801543\tvalid_1's auc: 0.749246\n",
      "[7000]\ttraining's auc: 0.807335\tvalid_1's auc: 0.74886\n",
      "[8000]\ttraining's auc: 0.812987\tvalid_1's auc: 0.748721\n",
      "Early stopping, best iteration is:\n",
      "[5634]\ttraining's auc: 0.799409\tvalid_1's auc: 0.749554\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771907\tvalid_1's auc: 0.748371\n",
      "[2000]\ttraining's auc: 0.778453\tvalid_1's auc: 0.749848\n",
      "[3000]\ttraining's auc: 0.784327\tvalid_1's auc: 0.749354\n",
      "[4000]\ttraining's auc: 0.790126\tvalid_1's auc: 0.748775\n",
      "Early stopping, best iteration is:\n",
      "[1722]\ttraining's auc: 0.776629\tvalid_1's auc: 0.750204\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772484\tvalid_1's auc: 0.741211\n",
      "[2000]\ttraining's auc: 0.778999\tvalid_1's auc: 0.74236\n",
      "[3000]\ttraining's auc: 0.784811\tvalid_1's auc: 0.742919\n",
      "[4000]\ttraining's auc: 0.790679\tvalid_1's auc: 0.742781\n",
      "[5000]\ttraining's auc: 0.796364\tvalid_1's auc: 0.74281\n",
      "[6000]\ttraining's auc: 0.802233\tvalid_1's auc: 0.74233\n",
      "Early stopping, best iteration is:\n",
      "[3573]\ttraining's auc: 0.788257\tvalid_1's auc: 0.743142\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772164\tvalid_1's auc: 0.74432\n",
      "[2000]\ttraining's auc: 0.77872\tvalid_1's auc: 0.744878\n",
      "[3000]\ttraining's auc: 0.784661\tvalid_1's auc: 0.744347\n",
      "[4000]\ttraining's auc: 0.790484\tvalid_1's auc: 0.743797\n",
      "Early stopping, best iteration is:\n",
      "[1746]\ttraining's auc: 0.777203\tvalid_1's auc: 0.745094\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.771936\tvalid_1's auc: 0.750562\n",
      "[2000]\ttraining's auc: 0.778404\tvalid_1's auc: 0.7509\n",
      "[3000]\ttraining's auc: 0.784202\tvalid_1's auc: 0.751218\n",
      "[4000]\ttraining's auc: 0.789994\tvalid_1's auc: 0.750821\n",
      "[5000]\ttraining's auc: 0.795768\tvalid_1's auc: 0.750642\n",
      "[6000]\ttraining's auc: 0.801562\tvalid_1's auc: 0.749857\n",
      "Early stopping, best iteration is:\n",
      "[3051]\ttraining's auc: 0.784434\tvalid_1's auc: 0.751275\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.772258\tvalid_1's auc: 0.747536\n",
      "[2000]\ttraining's auc: 0.778676\tvalid_1's auc: 0.748527\n",
      "[3000]\ttraining's auc: 0.78447\tvalid_1's auc: 0.748814\n",
      "[4000]\ttraining's auc: 0.79024\tvalid_1's auc: 0.74886\n",
      "[5000]\ttraining's auc: 0.795989\tvalid_1's auc: 0.748595\n",
      "Early stopping, best iteration is:\n",
      "[2636]\ttraining's auc: 0.782482\tvalid_1's auc: 0.749035\n",
      "Total run time 11.460956879456837 min:\n",
      "CV score: 0.74490 \n"
     ]
    }
   ],
   "source": [
    "train_results_less_1_2_more_1_4 = train(train_df, test_df, target, uniques_count_less_1_2_more_1_4.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744883\tvalid_1's auc: 0.710591\n",
      "[2000]\ttraining's auc: 0.750561\tvalid_1's auc: 0.712807\n",
      "[3000]\ttraining's auc: 0.753888\tvalid_1's auc: 0.713001\n",
      "[4000]\ttraining's auc: 0.75647\tvalid_1's auc: 0.712625\n",
      "Early stopping, best iteration is:\n",
      "[1837]\ttraining's auc: 0.750068\tvalid_1's auc: 0.713563\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744471\tvalid_1's auc: 0.712185\n",
      "[2000]\ttraining's auc: 0.749998\tvalid_1's auc: 0.715383\n",
      "[3000]\ttraining's auc: 0.75323\tvalid_1's auc: 0.716157\n",
      "[4000]\ttraining's auc: 0.755847\tvalid_1's auc: 0.715947\n",
      "[5000]\ttraining's auc: 0.758416\tvalid_1's auc: 0.715308\n",
      "[6000]\ttraining's auc: 0.760556\tvalid_1's auc: 0.714514\n",
      "Early stopping, best iteration is:\n",
      "[3082]\ttraining's auc: 0.753392\tvalid_1's auc: 0.71638\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744833\tvalid_1's auc: 0.71363\n",
      "[2000]\ttraining's auc: 0.750203\tvalid_1's auc: 0.715187\n",
      "[3000]\ttraining's auc: 0.753513\tvalid_1's auc: 0.715357\n",
      "[4000]\ttraining's auc: 0.756268\tvalid_1's auc: 0.714718\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's auc: 0.749507\tvalid_1's auc: 0.716002\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.745151\tvalid_1's auc: 0.714864\n",
      "[2000]\ttraining's auc: 0.750299\tvalid_1's auc: 0.716888\n",
      "[3000]\ttraining's auc: 0.753618\tvalid_1's auc: 0.71749\n",
      "[4000]\ttraining's auc: 0.756363\tvalid_1's auc: 0.716579\n",
      "[5000]\ttraining's auc: 0.758952\tvalid_1's auc: 0.715651\n",
      "[6000]\ttraining's auc: 0.76138\tvalid_1's auc: 0.714836\n",
      "Early stopping, best iteration is:\n",
      "[3251]\ttraining's auc: 0.754277\tvalid_1's auc: 0.717792\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744609\tvalid_1's auc: 0.719996\n",
      "[2000]\ttraining's auc: 0.749666\tvalid_1's auc: 0.720711\n",
      "[3000]\ttraining's auc: 0.752933\tvalid_1's auc: 0.720733\n",
      "[4000]\ttraining's auc: 0.755554\tvalid_1's auc: 0.720477\n",
      "Early stopping, best iteration is:\n",
      "[1618]\ttraining's auc: 0.748468\tvalid_1's auc: 0.721845\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744326\tvalid_1's auc: 0.719381\n",
      "[2000]\ttraining's auc: 0.749394\tvalid_1's auc: 0.721236\n",
      "[3000]\ttraining's auc: 0.752783\tvalid_1's auc: 0.72188\n",
      "[4000]\ttraining's auc: 0.755488\tvalid_1's auc: 0.721261\n",
      "[5000]\ttraining's auc: 0.758121\tvalid_1's auc: 0.720766\n",
      "Early stopping, best iteration is:\n",
      "[2191]\ttraining's auc: 0.750008\tvalid_1's auc: 0.722064\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.745271\tvalid_1's auc: 0.714455\n",
      "[2000]\ttraining's auc: 0.75028\tvalid_1's auc: 0.716878\n",
      "[3000]\ttraining's auc: 0.75365\tvalid_1's auc: 0.717483\n",
      "[4000]\ttraining's auc: 0.756258\tvalid_1's auc: 0.716911\n",
      "[5000]\ttraining's auc: 0.758948\tvalid_1's auc: 0.716131\n",
      "Early stopping, best iteration is:\n",
      "[2513]\ttraining's auc: 0.751983\tvalid_1's auc: 0.717691\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744869\tvalid_1's auc: 0.71634\n",
      "[2000]\ttraining's auc: 0.749753\tvalid_1's auc: 0.717663\n",
      "[3000]\ttraining's auc: 0.752987\tvalid_1's auc: 0.716878\n",
      "[4000]\ttraining's auc: 0.755709\tvalid_1's auc: 0.716438\n",
      "[5000]\ttraining's auc: 0.758333\tvalid_1's auc: 0.71611\n",
      "Early stopping, best iteration is:\n",
      "[2025]\ttraining's auc: 0.749834\tvalid_1's auc: 0.71783\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744513\tvalid_1's auc: 0.721857\n",
      "[2000]\ttraining's auc: 0.750086\tvalid_1's auc: 0.723495\n",
      "[3000]\ttraining's auc: 0.753296\tvalid_1's auc: 0.722767\n",
      "[4000]\ttraining's auc: 0.755936\tvalid_1's auc: 0.721734\n",
      "[5000]\ttraining's auc: 0.758412\tvalid_1's auc: 0.720454\n",
      "Early stopping, best iteration is:\n",
      "[2360]\ttraining's auc: 0.751117\tvalid_1's auc: 0.723748\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.744753\tvalid_1's auc: 0.714829\n",
      "[2000]\ttraining's auc: 0.750212\tvalid_1's auc: 0.717169\n",
      "[3000]\ttraining's auc: 0.753564\tvalid_1's auc: 0.717526\n",
      "[4000]\ttraining's auc: 0.756157\tvalid_1's auc: 0.716683\n",
      "Early stopping, best iteration is:\n",
      "[1813]\ttraining's auc: 0.749579\tvalid_1's auc: 0.717868\n",
      "Total run time 10.562069928646087 min:\n",
      "CV score: 0.71718 \n"
     ]
    }
   ],
   "source": [
    "train_results_less_1_4 = train(train_df, test_df, target, uniques_count_less_1_4.index.tolist(), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_features_maker = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_feature_name(feature_name):\n",
    "    if '^' in feature_name:\n",
    "        return '_'.join(feature_name.split('^'))\n",
    "    elif ' ' in feature_name:\n",
    "        return '_'.join(feature_name.split())\n",
    "    else:\n",
    "        return feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised_feature_names = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(['var0', 'var1', 'var2', 'var3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\\n    #scaled_train_values,\\n    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\\n    target_values,\\n    test_size=0.2,\\n    random_state=0\\n)\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_more_1_2 = train_df[uniques_count_more_1_2.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_more_1_4_less_1_2 = train_df[uniques_count_more_1_4_less_1_2.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_uniques_count_less_1_4 = train_df[uniques_count_less_1_4.index].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'target' in train_df_uniques_count_less_1_4.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_more_1_2 = polinomial_features_maker.fit_transform(train_df_uniques_count_more_1_2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_polinomial_values_uniques_count_more_1_2 = standard_scaler.fit_transform(polinomial_values_uniques_count_more_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_more_1_2 = [\n",
    "    normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_more_1_2.columns.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6215"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_feature_names_uniques_count_more_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_2, holdout_test_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, holdout_test_target_values_ucm_1_2 = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    scaled_polinomial_values_uniques_count_more_1_2,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_polinomial_df_ucm_1_2 = reduce_mem_usage(pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2\n",
    "))\n",
    "'''\n",
    "train_polinomial_df_ucm_1_2 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_df_ucm_1_2 = pd.DataFrame(data=train_target_values_ucm_1_2, columns=['target'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_df_ucm_1_2.values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_2 = pd.Series(train_target_values_ucm_1_2, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_target_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 6215)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polinomial_df_ucm_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_2</th>\n",
       "      <th>var_190_var_193</th>\n",
       "      <th>var_190_var_196</th>\n",
       "      <th>var_190_var_199</th>\n",
       "      <th>var_193_2</th>\n",
       "      <th>var_193_var_196</th>\n",
       "      <th>var_193_var_199</th>\n",
       "      <th>var_196_2</th>\n",
       "      <th>var_196_var_199</th>\n",
       "      <th>var_199_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.4003</td>\n",
       "      <td>-15.1480</td>\n",
       "      <td>23.001101</td>\n",
       "      <td>-12.8277</td>\n",
       "      <td>-11.9705</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>-13.7352</td>\n",
       "      <td>8.9064</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>2.9975</td>\n",
       "      <td>...</td>\n",
       "      <td>97.253128</td>\n",
       "      <td>103.938377</td>\n",
       "      <td>63.965946</td>\n",
       "      <td>-21.822956</td>\n",
       "      <td>111.083176</td>\n",
       "      <td>68.363007</td>\n",
       "      <td>-23.323080</td>\n",
       "      <td>42.072086</td>\n",
       "      <td>-14.353533</td>\n",
       "      <td>4.896926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.3055</td>\n",
       "      <td>-3.9362</td>\n",
       "      <td>20.108700</td>\n",
       "      <td>-2.1613</td>\n",
       "      <td>2.0213</td>\n",
       "      <td>12.1363</td>\n",
       "      <td>-11.3936</td>\n",
       "      <td>2.4146</td>\n",
       "      <td>12.208200</td>\n",
       "      <td>18.9734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180540</td>\n",
       "      <td>-1.965333</td>\n",
       "      <td>-0.716424</td>\n",
       "      <td>7.052490</td>\n",
       "      <td>21.394325</td>\n",
       "      <td>7.798887</td>\n",
       "      <td>-76.772385</td>\n",
       "      <td>2.842933</td>\n",
       "      <td>-27.985888</td>\n",
       "      <td>275.493591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0901</td>\n",
       "      <td>-19.5462</td>\n",
       "      <td>16.896999</td>\n",
       "      <td>-9.5860</td>\n",
       "      <td>-2.1832</td>\n",
       "      <td>8.4016</td>\n",
       "      <td>-3.2487</td>\n",
       "      <td>11.4263</td>\n",
       "      <td>13.995400</td>\n",
       "      <td>15.6798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587348</td>\n",
       "      <td>8.172215</td>\n",
       "      <td>-1.094097</td>\n",
       "      <td>13.587013</td>\n",
       "      <td>42.073387</td>\n",
       "      <td>-5.632790</td>\n",
       "      <td>69.950638</td>\n",
       "      <td>0.754119</td>\n",
       "      <td>-9.364999</td>\n",
       "      <td>116.298965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8913</td>\n",
       "      <td>-14.9898</td>\n",
       "      <td>21.246300</td>\n",
       "      <td>7.0288</td>\n",
       "      <td>2.4824</td>\n",
       "      <td>-0.0570</td>\n",
       "      <td>-5.4731</td>\n",
       "      <td>7.6422</td>\n",
       "      <td>12.221700</td>\n",
       "      <td>4.5632</td>\n",
       "      <td>...</td>\n",
       "      <td>138.525833</td>\n",
       "      <td>105.143440</td>\n",
       "      <td>-12.135738</td>\n",
       "      <td>70.626442</td>\n",
       "      <td>79.805641</td>\n",
       "      <td>-9.211229</td>\n",
       "      <td>53.606655</td>\n",
       "      <td>1.063167</td>\n",
       "      <td>-6.187322</td>\n",
       "      <td>36.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1761</td>\n",
       "      <td>-17.0776</td>\n",
       "      <td>16.811001</td>\n",
       "      <td>4.6831</td>\n",
       "      <td>-2.1157</td>\n",
       "      <td>16.5910</td>\n",
       "      <td>-8.8183</td>\n",
       "      <td>23.8480</td>\n",
       "      <td>23.709801</td>\n",
       "      <td>15.3342</td>\n",
       "      <td>...</td>\n",
       "      <td>16.612961</td>\n",
       "      <td>36.816788</td>\n",
       "      <td>20.045683</td>\n",
       "      <td>-83.176071</td>\n",
       "      <td>81.591469</td>\n",
       "      <td>44.424210</td>\n",
       "      <td>-184.330536</td>\n",
       "      <td>24.187706</td>\n",
       "      <td>-100.362679</td>\n",
       "      <td>416.437469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_1    var_5      var_7   var_10   var_11   var_13   var_17   var_18  \\\n",
       "0 -1.4003 -15.1480  23.001101 -12.8277 -11.9705   0.9585 -13.7352   8.9064   \n",
       "1 -2.3055  -3.9362  20.108700  -2.1613   2.0213  12.1363 -11.3936   2.4146   \n",
       "2  2.0901 -19.5462  16.896999  -9.5860  -2.1832   8.4016  -3.2487  11.4263   \n",
       "3  1.8913 -14.9898  21.246300   7.0288   2.4824  -0.0570  -5.4731   7.6422   \n",
       "4  2.1761 -17.0776  16.811001   4.6831  -2.1157  16.5910  -8.8183  23.8480   \n",
       "\n",
       "      var_19   var_20     ...       var_190_2  var_190_var_193  \\\n",
       "0   0.698000   2.9975     ...       97.253128       103.938377   \n",
       "1  12.208200  18.9734     ...        0.180540        -1.965333   \n",
       "2  13.995400  15.6798     ...        1.587348         8.172215   \n",
       "3  12.221700   4.5632     ...      138.525833       105.143440   \n",
       "4  23.709801  15.3342     ...       16.612961        36.816788   \n",
       "\n",
       "   var_190_var_196  var_190_var_199   var_193_2  var_193_var_196  \\\n",
       "0        63.965946       -21.822956  111.083176        68.363007   \n",
       "1        -0.716424         7.052490   21.394325         7.798887   \n",
       "2        -1.094097        13.587013   42.073387        -5.632790   \n",
       "3       -12.135738        70.626442   79.805641        -9.211229   \n",
       "4        20.045683       -83.176071   81.591469        44.424210   \n",
       "\n",
       "   var_193_var_199  var_196_2  var_196_var_199   var_199_2  \n",
       "0       -23.323080  42.072086       -14.353533    4.896926  \n",
       "1       -76.772385   2.842933       -27.985888  275.493591  \n",
       "2        69.950638   0.754119        -9.364999  116.298965  \n",
       "3        53.606655   1.063167        -6.187322   36.008400  \n",
       "4      -184.330536  24.187706      -100.362679  416.437469  \n",
       "\n",
       "[5 rows x 6215 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polinomial_df_ucm_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values_ucm_1_2 = polinomial_features_maker.fit_transform(test_df[uniques_count_more_1_2.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_2 = pd.DataFrame(\n",
    "    data=test_values_ucm_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_values_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del polinomial_values_uniques_count_more_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838762\tvalid_1's auc: 0.802518\n",
      "[2000]\ttraining's auc: 0.864215\tvalid_1's auc: 0.811186\n",
      "[3000]\ttraining's auc: 0.882027\tvalid_1's auc: 0.812682\n",
      "[4000]\ttraining's auc: 0.898256\tvalid_1's auc: 0.812993\n",
      "[5000]\ttraining's auc: 0.913146\tvalid_1's auc: 0.812344\n",
      "[6000]\ttraining's auc: 0.926696\tvalid_1's auc: 0.812159\n",
      "Early stopping, best iteration is:\n",
      "[3874]\ttraining's auc: 0.896196\tvalid_1's auc: 0.813274\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838786\tvalid_1's auc: 0.802206\n",
      "[2000]\ttraining's auc: 0.863654\tvalid_1's auc: 0.812419\n",
      "[3000]\ttraining's auc: 0.881227\tvalid_1's auc: 0.815243\n",
      "[4000]\ttraining's auc: 0.897331\tvalid_1's auc: 0.816398\n",
      "[5000]\ttraining's auc: 0.912293\tvalid_1's auc: 0.816428\n",
      "[6000]\ttraining's auc: 0.925757\tvalid_1's auc: 0.816328\n",
      "[7000]\ttraining's auc: 0.938058\tvalid_1's auc: 0.81598\n",
      "Early stopping, best iteration is:\n",
      "[4563]\ttraining's auc: 0.905992\tvalid_1's auc: 0.816707\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838071\tvalid_1's auc: 0.809383\n",
      "[2000]\ttraining's auc: 0.86336\tvalid_1's auc: 0.818606\n",
      "[3000]\ttraining's auc: 0.881368\tvalid_1's auc: 0.819967\n",
      "[4000]\ttraining's auc: 0.897395\tvalid_1's auc: 0.820065\n",
      "[5000]\ttraining's auc: 0.912531\tvalid_1's auc: 0.81987\n",
      "[6000]\ttraining's auc: 0.926124\tvalid_1's auc: 0.819698\n",
      "[7000]\ttraining's auc: 0.938423\tvalid_1's auc: 0.819576\n",
      "Early stopping, best iteration is:\n",
      "[4016]\ttraining's auc: 0.897645\tvalid_1's auc: 0.820173\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83821\tvalid_1's auc: 0.809438\n",
      "[2000]\ttraining's auc: 0.86321\tvalid_1's auc: 0.819368\n",
      "[3000]\ttraining's auc: 0.881006\tvalid_1's auc: 0.821936\n",
      "[4000]\ttraining's auc: 0.897131\tvalid_1's auc: 0.822499\n",
      "[5000]\ttraining's auc: 0.911879\tvalid_1's auc: 0.82282\n",
      "[6000]\ttraining's auc: 0.92562\tvalid_1's auc: 0.823172\n",
      "[7000]\ttraining's auc: 0.937801\tvalid_1's auc: 0.822963\n",
      "[8000]\ttraining's auc: 0.948581\tvalid_1's auc: 0.822633\n",
      "[9000]\ttraining's auc: 0.957718\tvalid_1's auc: 0.821821\n",
      "Early stopping, best iteration is:\n",
      "[6007]\ttraining's auc: 0.925733\tvalid_1's auc: 0.823204\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.839185\tvalid_1's auc: 0.805585\n",
      "[2000]\ttraining's auc: 0.863926\tvalid_1's auc: 0.815801\n",
      "[3000]\ttraining's auc: 0.881486\tvalid_1's auc: 0.817704\n",
      "[4000]\ttraining's auc: 0.897704\tvalid_1's auc: 0.817464\n",
      "[5000]\ttraining's auc: 0.912498\tvalid_1's auc: 0.81786\n",
      "[6000]\ttraining's auc: 0.926144\tvalid_1's auc: 0.817553\n",
      "[7000]\ttraining's auc: 0.938247\tvalid_1's auc: 0.817042\n",
      "Early stopping, best iteration is:\n",
      "[4727]\ttraining's auc: 0.908605\tvalid_1's auc: 0.817979\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83942\tvalid_1's auc: 0.797128\n",
      "[2000]\ttraining's auc: 0.864591\tvalid_1's auc: 0.806734\n",
      "[3000]\ttraining's auc: 0.882115\tvalid_1's auc: 0.809022\n",
      "[4000]\ttraining's auc: 0.898067\tvalid_1's auc: 0.809662\n",
      "[5000]\ttraining's auc: 0.912624\tvalid_1's auc: 0.80983\n",
      "[6000]\ttraining's auc: 0.92629\tvalid_1's auc: 0.809578\n",
      "[7000]\ttraining's auc: 0.938296\tvalid_1's auc: 0.809112\n",
      "[8000]\ttraining's auc: 0.94887\tvalid_1's auc: 0.809175\n",
      "Early stopping, best iteration is:\n",
      "[5433]\ttraining's auc: 0.918789\tvalid_1's auc: 0.809953\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838826\tvalid_1's auc: 0.798452\n",
      "[2000]\ttraining's auc: 0.864251\tvalid_1's auc: 0.809565\n",
      "[3000]\ttraining's auc: 0.881883\tvalid_1's auc: 0.811075\n",
      "[4000]\ttraining's auc: 0.898102\tvalid_1's auc: 0.811875\n",
      "[5000]\ttraining's auc: 0.912852\tvalid_1's auc: 0.812476\n",
      "[6000]\ttraining's auc: 0.926231\tvalid_1's auc: 0.81229\n",
      "[7000]\ttraining's auc: 0.938218\tvalid_1's auc: 0.812081\n",
      "[8000]\ttraining's auc: 0.948838\tvalid_1's auc: 0.811973\n",
      "Early stopping, best iteration is:\n",
      "[5241]\ttraining's auc: 0.916196\tvalid_1's auc: 0.812793\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838208\tvalid_1's auc: 0.80803\n",
      "[2000]\ttraining's auc: 0.863463\tvalid_1's auc: 0.817872\n",
      "[3000]\ttraining's auc: 0.88124\tvalid_1's auc: 0.819231\n",
      "[4000]\ttraining's auc: 0.897286\tvalid_1's auc: 0.819254\n",
      "[5000]\ttraining's auc: 0.912181\tvalid_1's auc: 0.819314\n",
      "[6000]\ttraining's auc: 0.925699\tvalid_1's auc: 0.818978\n",
      "[7000]\ttraining's auc: 0.937965\tvalid_1's auc: 0.818554\n",
      "Early stopping, best iteration is:\n",
      "[4392]\ttraining's auc: 0.903324\tvalid_1's auc: 0.819676\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838555\tvalid_1's auc: 0.812231\n",
      "[2000]\ttraining's auc: 0.863825\tvalid_1's auc: 0.820539\n",
      "[3000]\ttraining's auc: 0.881444\tvalid_1's auc: 0.821546\n",
      "[4000]\ttraining's auc: 0.897503\tvalid_1's auc: 0.821649\n",
      "[5000]\ttraining's auc: 0.91227\tvalid_1's auc: 0.821277\n",
      "[6000]\ttraining's auc: 0.92582\tvalid_1's auc: 0.820819\n",
      "Early stopping, best iteration is:\n",
      "[3757]\ttraining's auc: 0.89367\tvalid_1's auc: 0.821993\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.838625\tvalid_1's auc: 0.805455\n",
      "[2000]\ttraining's auc: 0.864076\tvalid_1's auc: 0.814822\n",
      "[3000]\ttraining's auc: 0.881819\tvalid_1's auc: 0.816536\n",
      "[4000]\ttraining's auc: 0.897938\tvalid_1's auc: 0.816276\n",
      "[5000]\ttraining's auc: 0.912877\tvalid_1's auc: 0.815507\n",
      "[6000]\ttraining's auc: 0.926537\tvalid_1's auc: 0.8154\n",
      "Early stopping, best iteration is:\n",
      "[3254]\ttraining's auc: 0.885929\tvalid_1's auc: 0.816673\n",
      "Total run time 84.49654633204142 min:\n",
      "CV score: 0.81718 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_2 = train(\n",
    "    train_polinomial_df_ucm_1_2,\n",
    "    test_polinomial_df_ucm_1_2,\n",
    "    train_target_series_ucm_1_2,\n",
    "    train_polinomial_df_ucm_1_2.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof, predictions, feature_importance_df, clf = train_results_polinomial_ucm_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(predictions)\n",
    "predictions_df = pd.DataFrame(data=predictions, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_2.to_csv('train_polinomial_data_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_2.to_csv('test_polinomial_data_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_2.to_csv('train_target_ucm_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_2\n",
    "del test_polinomial_df_ucm_1_2\n",
    "del train_target_series_ucm_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('lgbm_ucf_1_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_more_1_4_less_1_2 = polinomial_features_maker.fit_transform(train_df_uniques_count_more_1_4_less_1_2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_values_uniques_count_more_1_4_less_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_more_1_4_less_1_2 = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_more_1_4_less_1_2.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_4_1_2, holdout_test_polinomial_values_ucm_1_4_1_2, train_target_values_ucm_1_4_1_2, holdout_test_target_values_ucm_1_4_1_2 = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    polinomial_values_uniques_count_more_1_4_less_1_2,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4_1_2 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_4_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_4_less_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4_1_2 = pd.Series(train_target_values_ucm_1_4_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4_1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4_1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_values_ucm_1_4_1_2 = polinomial_features_maker.fit_transform(test_df[uniques_count_more_1_4_less_1_2.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4_1_2 = pd.DataFrame(\n",
    "    data=test_polinomial_values_ucm_1_4_1_2,\n",
    "    columns=polinomial_feature_names_uniques_count_more_1_4_less_1_2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del polinomial_values_uniques_count_more_1_4_less_1_2\n",
    "del train_polinomial_values_ucm_1_4_1_2\n",
    "del test_polinomial_values_ucm_1_4_1_2\n",
    "del train_target_values_ucm_1_4_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83246\tvalid_1's auc: 0.801038\n",
      "[2000]\ttraining's auc: 0.854414\tvalid_1's auc: 0.805477\n",
      "[3000]\ttraining's auc: 0.871523\tvalid_1's auc: 0.806123\n",
      "[4000]\ttraining's auc: 0.887375\tvalid_1's auc: 0.805903\n",
      "[5000]\ttraining's auc: 0.902057\tvalid_1's auc: 0.806144\n",
      "Early stopping, best iteration is:\n",
      "[2842]\ttraining's auc: 0.868851\tvalid_1's auc: 0.80622\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831354\tvalid_1's auc: 0.807533\n",
      "[2000]\ttraining's auc: 0.853586\tvalid_1's auc: 0.814413\n",
      "[3000]\ttraining's auc: 0.871036\tvalid_1's auc: 0.815046\n",
      "[4000]\ttraining's auc: 0.887196\tvalid_1's auc: 0.814766\n",
      "[5000]\ttraining's auc: 0.90206\tvalid_1's auc: 0.814434\n",
      "[6000]\ttraining's auc: 0.915315\tvalid_1's auc: 0.814192\n",
      "Early stopping, best iteration is:\n",
      "[3584]\ttraining's auc: 0.880639\tvalid_1's auc: 0.815199\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832987\tvalid_1's auc: 0.787713\n",
      "[2000]\ttraining's auc: 0.854887\tvalid_1's auc: 0.796167\n",
      "[3000]\ttraining's auc: 0.871821\tvalid_1's auc: 0.798036\n",
      "[4000]\ttraining's auc: 0.887704\tvalid_1's auc: 0.797854\n",
      "[5000]\ttraining's auc: 0.902365\tvalid_1's auc: 0.797431\n",
      "[6000]\ttraining's auc: 0.915516\tvalid_1's auc: 0.796584\n",
      "Early stopping, best iteration is:\n",
      "[3588]\ttraining's auc: 0.88123\tvalid_1's auc: 0.798177\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.83157\tvalid_1's auc: 0.804276\n",
      "[2000]\ttraining's auc: 0.853535\tvalid_1's auc: 0.812183\n",
      "[3000]\ttraining's auc: 0.870667\tvalid_1's auc: 0.813517\n",
      "[4000]\ttraining's auc: 0.886516\tvalid_1's auc: 0.81351\n",
      "[5000]\ttraining's auc: 0.901362\tvalid_1's auc: 0.813701\n",
      "[6000]\ttraining's auc: 0.914925\tvalid_1's auc: 0.812733\n",
      "[7000]\ttraining's auc: 0.92705\tvalid_1's auc: 0.81272\n",
      "Early stopping, best iteration is:\n",
      "[4670]\ttraining's auc: 0.896781\tvalid_1's auc: 0.813876\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832125\tvalid_1's auc: 0.799563\n",
      "[2000]\ttraining's auc: 0.853766\tvalid_1's auc: 0.806429\n",
      "[3000]\ttraining's auc: 0.870873\tvalid_1's auc: 0.807988\n",
      "[4000]\ttraining's auc: 0.886879\tvalid_1's auc: 0.808158\n",
      "[5000]\ttraining's auc: 0.90159\tvalid_1's auc: 0.807828\n",
      "[6000]\ttraining's auc: 0.915042\tvalid_1's auc: 0.80758\n",
      "Early stopping, best iteration is:\n",
      "[3935]\ttraining's auc: 0.88583\tvalid_1's auc: 0.808242\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831351\tvalid_1's auc: 0.811016\n",
      "[2000]\ttraining's auc: 0.853406\tvalid_1's auc: 0.818441\n",
      "[3000]\ttraining's auc: 0.870881\tvalid_1's auc: 0.819958\n",
      "[4000]\ttraining's auc: 0.886907\tvalid_1's auc: 0.820278\n",
      "[5000]\ttraining's auc: 0.901431\tvalid_1's auc: 0.819977\n",
      "[6000]\ttraining's auc: 0.915073\tvalid_1's auc: 0.819888\n",
      "[7000]\ttraining's auc: 0.927059\tvalid_1's auc: 0.819745\n",
      "Early stopping, best iteration is:\n",
      "[4146]\ttraining's auc: 0.889148\tvalid_1's auc: 0.820399\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832273\tvalid_1's auc: 0.798405\n",
      "[2000]\ttraining's auc: 0.8543\tvalid_1's auc: 0.806109\n",
      "[3000]\ttraining's auc: 0.871403\tvalid_1's auc: 0.80715\n",
      "[4000]\ttraining's auc: 0.887216\tvalid_1's auc: 0.807956\n",
      "[5000]\ttraining's auc: 0.901963\tvalid_1's auc: 0.807674\n",
      "[6000]\ttraining's auc: 0.915062\tvalid_1's auc: 0.807656\n",
      "[7000]\ttraining's auc: 0.927253\tvalid_1's auc: 0.807556\n",
      "[8000]\ttraining's auc: 0.938083\tvalid_1's auc: 0.806961\n",
      "[9000]\ttraining's auc: 0.947545\tvalid_1's auc: 0.806782\n",
      "Early stopping, best iteration is:\n",
      "[6221]\ttraining's auc: 0.918006\tvalid_1's auc: 0.807967\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.832335\tvalid_1's auc: 0.79963\n",
      "[2000]\ttraining's auc: 0.854273\tvalid_1's auc: 0.80552\n",
      "[3000]\ttraining's auc: 0.871351\tvalid_1's auc: 0.806012\n",
      "[4000]\ttraining's auc: 0.887247\tvalid_1's auc: 0.805516\n",
      "[5000]\ttraining's auc: 0.901805\tvalid_1's auc: 0.805131\n",
      "Early stopping, best iteration is:\n",
      "[2897]\ttraining's auc: 0.869676\tvalid_1's auc: 0.806269\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831371\tvalid_1's auc: 0.807862\n",
      "[2000]\ttraining's auc: 0.85343\tvalid_1's auc: 0.812993\n",
      "[3000]\ttraining's auc: 0.870821\tvalid_1's auc: 0.813938\n",
      "[4000]\ttraining's auc: 0.886624\tvalid_1's auc: 0.81392\n",
      "[5000]\ttraining's auc: 0.901593\tvalid_1's auc: 0.813434\n",
      "[6000]\ttraining's auc: 0.91483\tvalid_1's auc: 0.813018\n",
      "Early stopping, best iteration is:\n",
      "[3335]\ttraining's auc: 0.876231\tvalid_1's auc: 0.814166\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.831903\tvalid_1's auc: 0.801807\n",
      "[2000]\ttraining's auc: 0.853965\tvalid_1's auc: 0.80871\n",
      "[3000]\ttraining's auc: 0.871177\tvalid_1's auc: 0.809762\n",
      "[4000]\ttraining's auc: 0.887158\tvalid_1's auc: 0.809797\n",
      "[5000]\ttraining's auc: 0.901809\tvalid_1's auc: 0.809146\n",
      "[6000]\ttraining's auc: 0.915162\tvalid_1's auc: 0.809073\n",
      "Early stopping, best iteration is:\n",
      "[3338]\ttraining's auc: 0.876738\tvalid_1's auc: 0.810069\n",
      "Total run time 56.124856078624724 min:\n",
      "CV score: 0.80998 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_4_1_2 = train(\n",
    "    train_polinomial_df_ucm_1_4_1_2,\n",
    "    test_polinomial_df_ucm_1_4_1_2,\n",
    "    train_target_series_ucm_1_4_1_2,\n",
    "    train_polinomial_df_ucm_1_4_1_2.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_1_4_1_2, predictions_ucm_1_4_1_2, feature_importance_df_ucm_1_4_1_2, clf_ucm_1_4_1_2 = train_results_polinomial_ucm_1_4_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(oof_ucm_1_4_1_2)\n",
    "predictions_df_ucm_1_4_1_2 = pd.DataFrame(data=predictions_ucm_1_4_1_2, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4_1_2.to_csv('predictions_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4_1_2.to_csv('train_polinomial_data_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4_1_2.to_csv('test_polinomial_data_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4_1_2.to_csv('train_target_ucm_1_4_1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_4_1_2\n",
    "del test_polinomial_df_ucm_1_4_1_2\n",
    "del train_target_series_ucm_1_4_1_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ucm_1_4_1_2.save_model('lgbm_ucm_1_4_1_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_values_uniques_count_less_1_4 = polinomial_features_maker.fit_transform(train_df_uniques_count_less_1_4).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 819)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polinomial_values_uniques_count_less_1_4)\n",
    "polinomial_values_uniques_count_less_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_feature_names_uniques_count_less_1_4 = [normalise_feature_name(feature_name) for feature_name in polinomial_features_maker.get_feature_names(train_df_uniques_count_less_1_4.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_values_ucm_1_4, holdout_test_polinomial_values_ucm_1_4, train_target_values_ucm_1_4, holdout_test_target_values_ucm_1_4 = train_test_split(\n",
    "    polinomial_values_uniques_count_less_1_4,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4 = pd.DataFrame(\n",
    "    data=train_polinomial_values_ucm_1_4,\n",
    "    columns=polinomial_feature_names_uniques_count_less_1_4,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4 = pd.Series(train_target_values_ucm_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_series_ucm_1_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_values_ucm_1_4 = polinomial_features_maker.fit_transform(test_df[uniques_count_less_1_4.index]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4 = pd.DataFrame(\n",
    "    data=test_values_ucm_1_4,\n",
    "    columns=polinomial_feature_names_uniques_count_less_1_4,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del polinomial_values_uniques_count_less_1_4\n",
    "#del train_polinomial_values_ucm_1_4\n",
    "del test_polinomial_values_ucm_1_4\n",
    "del train_target_values_ucm_1_4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.750146\tvalid_1's auc: 0.706936\n",
      "[2000]\ttraining's auc: 0.773966\tvalid_1's auc: 0.707595\n",
      "[3000]\ttraining's auc: 0.796843\tvalid_1's auc: 0.706173\n",
      "[4000]\ttraining's auc: 0.817903\tvalid_1's auc: 0.705203\n",
      "Early stopping, best iteration is:\n",
      "[1548]\ttraining's auc: 0.763514\tvalid_1's auc: 0.70773\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748817\tvalid_1's auc: 0.719931\n",
      "[2000]\ttraining's auc: 0.773467\tvalid_1's auc: 0.720096\n",
      "[3000]\ttraining's auc: 0.7964\tvalid_1's auc: 0.718983\n",
      "[4000]\ttraining's auc: 0.816975\tvalid_1's auc: 0.718124\n",
      "Early stopping, best iteration is:\n",
      "[1220]\ttraining's auc: 0.754455\tvalid_1's auc: 0.721226\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749849\tvalid_1's auc: 0.706014\n",
      "[2000]\ttraining's auc: 0.773877\tvalid_1's auc: 0.708997\n",
      "[3000]\ttraining's auc: 0.796516\tvalid_1's auc: 0.70895\n",
      "[4000]\ttraining's auc: 0.81705\tvalid_1's auc: 0.708867\n",
      "[5000]\ttraining's auc: 0.836355\tvalid_1's auc: 0.708074\n",
      "[6000]\ttraining's auc: 0.853892\tvalid_1's auc: 0.706934\n",
      "Early stopping, best iteration is:\n",
      "[3242]\ttraining's auc: 0.801658\tvalid_1's auc: 0.709186\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748514\tvalid_1's auc: 0.719323\n",
      "[2000]\ttraining's auc: 0.773032\tvalid_1's auc: 0.720864\n",
      "[3000]\ttraining's auc: 0.796123\tvalid_1's auc: 0.720432\n",
      "[4000]\ttraining's auc: 0.816791\tvalid_1's auc: 0.71999\n",
      "Early stopping, best iteration is:\n",
      "[1815]\ttraining's auc: 0.768745\tvalid_1's auc: 0.721344\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.747734\tvalid_1's auc: 0.730777\n",
      "[2000]\ttraining's auc: 0.772388\tvalid_1's auc: 0.731844\n",
      "[3000]\ttraining's auc: 0.795545\tvalid_1's auc: 0.731315\n",
      "[4000]\ttraining's auc: 0.816848\tvalid_1's auc: 0.730588\n",
      "Early stopping, best iteration is:\n",
      "[1730]\ttraining's auc: 0.765903\tvalid_1's auc: 0.732473\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748986\tvalid_1's auc: 0.719056\n",
      "[2000]\ttraining's auc: 0.773019\tvalid_1's auc: 0.721977\n",
      "[3000]\ttraining's auc: 0.796138\tvalid_1's auc: 0.721909\n",
      "[4000]\ttraining's auc: 0.817114\tvalid_1's auc: 0.721614\n",
      "[5000]\ttraining's auc: 0.83643\tvalid_1's auc: 0.720305\n",
      "Early stopping, best iteration is:\n",
      "[2402]\ttraining's auc: 0.782434\tvalid_1's auc: 0.7223\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748927\tvalid_1's auc: 0.725424\n",
      "[2000]\ttraining's auc: 0.772999\tvalid_1's auc: 0.72615\n",
      "[3000]\ttraining's auc: 0.795584\tvalid_1's auc: 0.725309\n",
      "[4000]\ttraining's auc: 0.816672\tvalid_1's auc: 0.724426\n",
      "Early stopping, best iteration is:\n",
      "[1397]\ttraining's auc: 0.758519\tvalid_1's auc: 0.726685\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749575\tvalid_1's auc: 0.712295\n",
      "[2000]\ttraining's auc: 0.773407\tvalid_1's auc: 0.713449\n",
      "[3000]\ttraining's auc: 0.796533\tvalid_1's auc: 0.713512\n",
      "[4000]\ttraining's auc: 0.817448\tvalid_1's auc: 0.713536\n",
      "[5000]\ttraining's auc: 0.836752\tvalid_1's auc: 0.712608\n",
      "[6000]\ttraining's auc: 0.85448\tvalid_1's auc: 0.711863\n",
      "[7000]\ttraining's auc: 0.870511\tvalid_1's auc: 0.711157\n",
      "Early stopping, best iteration is:\n",
      "[4060]\ttraining's auc: 0.818768\tvalid_1's auc: 0.713807\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.748423\tvalid_1's auc: 0.728226\n",
      "[2000]\ttraining's auc: 0.772738\tvalid_1's auc: 0.728536\n",
      "[3000]\ttraining's auc: 0.795657\tvalid_1's auc: 0.727199\n",
      "[4000]\ttraining's auc: 0.816851\tvalid_1's auc: 0.726828\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's auc: 0.757013\tvalid_1's auc: 0.729147\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.749738\tvalid_1's auc: 0.715395\n",
      "[2000]\ttraining's auc: 0.77371\tvalid_1's auc: 0.716612\n",
      "[3000]\ttraining's auc: 0.796409\tvalid_1's auc: 0.71626\n",
      "[4000]\ttraining's auc: 0.817618\tvalid_1's auc: 0.715617\n",
      "[5000]\ttraining's auc: 0.836863\tvalid_1's auc: 0.715057\n",
      "Early stopping, best iteration is:\n",
      "[2348]\ttraining's auc: 0.781765\tvalid_1's auc: 0.716939\n",
      "Total run time 15.038687678178151 min:\n",
      "CV score: 0.71978 \n"
     ]
    }
   ],
   "source": [
    "train_results_polinomial_ucm_1_4 = train(\n",
    "    train_polinomial_df_ucm_1_4,\n",
    "    test_polinomial_df_ucm_1_4,\n",
    "    train_target_series_ucm_1_4,\n",
    "    train_polinomial_df_ucm_1_4.columns.tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_1_4, predictions_ucm_1_4, feature_importance_df_ucm_1_4, clf_ucm_1_4 = train_results_polinomial_ucm_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4 = pd.DataFrame(data=predictions_ucm_1_4, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_ucm_1_4.to_csv('predictions_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polinomial_df_ucm_1_4.to_csv('train_polinomial_data_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polinomial_df_ucm_1_4.to_csv('test_polinomial_data_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_series_ucm_1_4.to_csv('train_target_ucm_1_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_polinomial_df_ucm_1_4\n",
    "del test_polinomial_df_ucm_1_4\n",
    "del train_target_series_ucm_1_4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ucm_1_4.save_model('lgbm_ucm_1_4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions_df.head())\n",
    "#print(predictions_df.shape)\n",
    "#print(predictions_df_ucm_1_4_1_2.head())\n",
    "#print(predictions_df_ucm_1_4_1_2.shape)\n",
    "#print(predictions_df_ucm_1_4.head())\n",
    "#print(predictions_df_ucm_1_4.shape)\n",
    "#predictions_df.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simply_blend(prediction_dataframes, weights, target_column_name='target'):\n",
    "    blended_prediction_df = pd.DataFrame(data=np.zeros(prediction_dataframes[0].shape[0]), columns=[target_column_name])\n",
    "    for prediction_df, weight in zip(prediction_dataframes, weights):\n",
    "        blended_prediction_df[target_column_name] = blended_prediction_df[target_column_name] + weight * prediction_df[target_column_name]\n",
    "        #blended_prediction_df.add(weight * prediction_df)\n",
    "    return blended_prediction_df / sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_polinomial_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4],\n",
    "    [1, 1, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_polinomial_prediction.head()\n",
    "blended_polinomial_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_code = test_df['ID_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_polinomial_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('simply_blended_polinom_lgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_more_1_2, predictions_more_1_2, feature_importance_df_more_1_2, clf_more_1_2 = train_results_more_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_more_1_2 = pd.DataFrame(data=predictions_more_1_2, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_4_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2],\n",
    "    [1, 1, 1, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_4_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_4_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_4_df.to_csv('blended_4_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.89904\tvalid_1's auc: 0.880364\n",
      "[2000]\ttraining's auc: 0.911204\tvalid_1's auc: 0.888868\n",
      "[3000]\ttraining's auc: 0.91903\tvalid_1's auc: 0.893151\n",
      "[4000]\ttraining's auc: 0.924854\tvalid_1's auc: 0.896012\n",
      "[5000]\ttraining's auc: 0.929701\tvalid_1's auc: 0.897714\n",
      "[6000]\ttraining's auc: 0.933934\tvalid_1's auc: 0.898494\n",
      "[7000]\ttraining's auc: 0.93786\tvalid_1's auc: 0.898994\n",
      "[8000]\ttraining's auc: 0.941613\tvalid_1's auc: 0.89928\n",
      "[9000]\ttraining's auc: 0.945152\tvalid_1's auc: 0.899671\n",
      "[10000]\ttraining's auc: 0.948466\tvalid_1's auc: 0.899878\n",
      "[11000]\ttraining's auc: 0.951758\tvalid_1's auc: 0.900177\n",
      "[12000]\ttraining's auc: 0.954863\tvalid_1's auc: 0.899992\n",
      "[13000]\ttraining's auc: 0.957793\tvalid_1's auc: 0.899881\n",
      "[14000]\ttraining's auc: 0.96065\tvalid_1's auc: 0.899628\n",
      "Early stopping, best iteration is:\n",
      "[11045]\ttraining's auc: 0.951908\tvalid_1's auc: 0.900223\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898872\tvalid_1's auc: 0.881324\n",
      "[2000]\ttraining's auc: 0.911092\tvalid_1's auc: 0.890141\n",
      "[3000]\ttraining's auc: 0.918887\tvalid_1's auc: 0.894037\n",
      "[4000]\ttraining's auc: 0.924725\tvalid_1's auc: 0.896563\n",
      "[5000]\ttraining's auc: 0.929615\tvalid_1's auc: 0.898167\n",
      "[6000]\ttraining's auc: 0.933852\tvalid_1's auc: 0.898875\n",
      "[7000]\ttraining's auc: 0.937735\tvalid_1's auc: 0.89924\n",
      "[8000]\ttraining's auc: 0.941427\tvalid_1's auc: 0.899545\n",
      "[9000]\ttraining's auc: 0.945019\tvalid_1's auc: 0.899597\n",
      "[10000]\ttraining's auc: 0.948402\tvalid_1's auc: 0.899566\n",
      "[11000]\ttraining's auc: 0.951631\tvalid_1's auc: 0.899664\n",
      "[12000]\ttraining's auc: 0.954666\tvalid_1's auc: 0.899486\n",
      "[13000]\ttraining's auc: 0.957626\tvalid_1's auc: 0.89939\n",
      "Early stopping, best iteration is:\n",
      "[10577]\ttraining's auc: 0.950291\tvalid_1's auc: 0.899729\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.899456\tvalid_1's auc: 0.875464\n",
      "[2000]\ttraining's auc: 0.911636\tvalid_1's auc: 0.88445\n",
      "[3000]\ttraining's auc: 0.919401\tvalid_1's auc: 0.889283\n",
      "[4000]\ttraining's auc: 0.925163\tvalid_1's auc: 0.891698\n",
      "[5000]\ttraining's auc: 0.930008\tvalid_1's auc: 0.893217\n",
      "[6000]\ttraining's auc: 0.934161\tvalid_1's auc: 0.894368\n",
      "[7000]\ttraining's auc: 0.938011\tvalid_1's auc: 0.894915\n",
      "[8000]\ttraining's auc: 0.941698\tvalid_1's auc: 0.895107\n",
      "[9000]\ttraining's auc: 0.945271\tvalid_1's auc: 0.89496\n",
      "[10000]\ttraining's auc: 0.948626\tvalid_1's auc: 0.894985\n",
      "Early stopping, best iteration is:\n",
      "[7863]\ttraining's auc: 0.941219\tvalid_1's auc: 0.895159\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898755\tvalid_1's auc: 0.880937\n",
      "[2000]\ttraining's auc: 0.910972\tvalid_1's auc: 0.890718\n",
      "[3000]\ttraining's auc: 0.918966\tvalid_1's auc: 0.894582\n",
      "[4000]\ttraining's auc: 0.924802\tvalid_1's auc: 0.896677\n",
      "[5000]\ttraining's auc: 0.929742\tvalid_1's auc: 0.897598\n",
      "[6000]\ttraining's auc: 0.933987\tvalid_1's auc: 0.898084\n",
      "[7000]\ttraining's auc: 0.937911\tvalid_1's auc: 0.898305\n",
      "[8000]\ttraining's auc: 0.941628\tvalid_1's auc: 0.898558\n",
      "[9000]\ttraining's auc: 0.945165\tvalid_1's auc: 0.898465\n",
      "[10000]\ttraining's auc: 0.948493\tvalid_1's auc: 0.898567\n",
      "[11000]\ttraining's auc: 0.951717\tvalid_1's auc: 0.898491\n",
      "[12000]\ttraining's auc: 0.954791\tvalid_1's auc: 0.898268\n",
      "Early stopping, best iteration is:\n",
      "[9716]\ttraining's auc: 0.947579\tvalid_1's auc: 0.898615\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898756\tvalid_1's auc: 0.880866\n",
      "[2000]\ttraining's auc: 0.910845\tvalid_1's auc: 0.890799\n",
      "[3000]\ttraining's auc: 0.918796\tvalid_1's auc: 0.895208\n",
      "[4000]\ttraining's auc: 0.924658\tvalid_1's auc: 0.897531\n",
      "[5000]\ttraining's auc: 0.929576\tvalid_1's auc: 0.898924\n",
      "[6000]\ttraining's auc: 0.933837\tvalid_1's auc: 0.899703\n",
      "[7000]\ttraining's auc: 0.937772\tvalid_1's auc: 0.900308\n",
      "[8000]\ttraining's auc: 0.941416\tvalid_1's auc: 0.900431\n",
      "[9000]\ttraining's auc: 0.944971\tvalid_1's auc: 0.900233\n",
      "[10000]\ttraining's auc: 0.948268\tvalid_1's auc: 0.900028\n",
      "[11000]\ttraining's auc: 0.951548\tvalid_1's auc: 0.900111\n",
      "Early stopping, best iteration is:\n",
      "[8031]\ttraining's auc: 0.941528\tvalid_1's auc: 0.900462\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898106\tvalid_1's auc: 0.886226\n",
      "[2000]\ttraining's auc: 0.910525\tvalid_1's auc: 0.894652\n",
      "[3000]\ttraining's auc: 0.918514\tvalid_1's auc: 0.898661\n",
      "[4000]\ttraining's auc: 0.924481\tvalid_1's auc: 0.900751\n",
      "[5000]\ttraining's auc: 0.929454\tvalid_1's auc: 0.902105\n",
      "[6000]\ttraining's auc: 0.933804\tvalid_1's auc: 0.902821\n",
      "[7000]\ttraining's auc: 0.937765\tvalid_1's auc: 0.902995\n",
      "[8000]\ttraining's auc: 0.941446\tvalid_1's auc: 0.903154\n",
      "[9000]\ttraining's auc: 0.944993\tvalid_1's auc: 0.903363\n",
      "[10000]\ttraining's auc: 0.948314\tvalid_1's auc: 0.9034\n",
      "[11000]\ttraining's auc: 0.951562\tvalid_1's auc: 0.903391\n",
      "[12000]\ttraining's auc: 0.954655\tvalid_1's auc: 0.903289\n",
      "[13000]\ttraining's auc: 0.957648\tvalid_1's auc: 0.903262\n",
      "Early stopping, best iteration is:\n",
      "[10229]\ttraining's auc: 0.949078\tvalid_1's auc: 0.903449\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898631\tvalid_1's auc: 0.883448\n",
      "[2000]\ttraining's auc: 0.91088\tvalid_1's auc: 0.892046\n",
      "[3000]\ttraining's auc: 0.918802\tvalid_1's auc: 0.896592\n",
      "[4000]\ttraining's auc: 0.924723\tvalid_1's auc: 0.898649\n",
      "[5000]\ttraining's auc: 0.929617\tvalid_1's auc: 0.899721\n",
      "[6000]\ttraining's auc: 0.933906\tvalid_1's auc: 0.900308\n",
      "[7000]\ttraining's auc: 0.937832\tvalid_1's auc: 0.900717\n",
      "[8000]\ttraining's auc: 0.941555\tvalid_1's auc: 0.900916\n",
      "[9000]\ttraining's auc: 0.94506\tvalid_1's auc: 0.900607\n",
      "[10000]\ttraining's auc: 0.948425\tvalid_1's auc: 0.900518\n",
      "Early stopping, best iteration is:\n",
      "[7475]\ttraining's auc: 0.939642\tvalid_1's auc: 0.900965\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898676\tvalid_1's auc: 0.880199\n",
      "[2000]\ttraining's auc: 0.911049\tvalid_1's auc: 0.889752\n",
      "[3000]\ttraining's auc: 0.918968\tvalid_1's auc: 0.894568\n",
      "[4000]\ttraining's auc: 0.924842\tvalid_1's auc: 0.897449\n",
      "[5000]\ttraining's auc: 0.929663\tvalid_1's auc: 0.89896\n",
      "[6000]\ttraining's auc: 0.933875\tvalid_1's auc: 0.899934\n",
      "[7000]\ttraining's auc: 0.937866\tvalid_1's auc: 0.90027\n",
      "[8000]\ttraining's auc: 0.941586\tvalid_1's auc: 0.900556\n",
      "[9000]\ttraining's auc: 0.945083\tvalid_1's auc: 0.900757\n",
      "[10000]\ttraining's auc: 0.948416\tvalid_1's auc: 0.900799\n",
      "[11000]\ttraining's auc: 0.951675\tvalid_1's auc: 0.900676\n",
      "[12000]\ttraining's auc: 0.954768\tvalid_1's auc: 0.900403\n",
      "[13000]\ttraining's auc: 0.95775\tvalid_1's auc: 0.900246\n",
      "Early stopping, best iteration is:\n",
      "[10038]\ttraining's auc: 0.948551\tvalid_1's auc: 0.900819\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.89779\tvalid_1's auc: 0.888166\n",
      "[2000]\ttraining's auc: 0.910458\tvalid_1's auc: 0.896618\n",
      "[3000]\ttraining's auc: 0.918615\tvalid_1's auc: 0.900943\n",
      "[4000]\ttraining's auc: 0.924387\tvalid_1's auc: 0.903001\n",
      "[5000]\ttraining's auc: 0.9293\tvalid_1's auc: 0.904178\n",
      "[6000]\ttraining's auc: 0.933534\tvalid_1's auc: 0.904738\n",
      "[7000]\ttraining's auc: 0.937463\tvalid_1's auc: 0.905103\n",
      "[8000]\ttraining's auc: 0.94117\tvalid_1's auc: 0.905392\n",
      "[9000]\ttraining's auc: 0.944675\tvalid_1's auc: 0.905481\n",
      "[10000]\ttraining's auc: 0.948106\tvalid_1's auc: 0.905589\n",
      "[11000]\ttraining's auc: 0.951319\tvalid_1's auc: 0.90545\n",
      "[12000]\ttraining's auc: 0.954441\tvalid_1's auc: 0.905497\n",
      "[13000]\ttraining's auc: 0.957453\tvalid_1's auc: 0.905272\n",
      "Early stopping, best iteration is:\n",
      "[10232]\ttraining's auc: 0.948883\tvalid_1's auc: 0.905628\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.898783\tvalid_1's auc: 0.883983\n",
      "[2000]\ttraining's auc: 0.911112\tvalid_1's auc: 0.891819\n",
      "[3000]\ttraining's auc: 0.919056\tvalid_1's auc: 0.896176\n",
      "[4000]\ttraining's auc: 0.924853\tvalid_1's auc: 0.89825\n",
      "[5000]\ttraining's auc: 0.929797\tvalid_1's auc: 0.899577\n",
      "[6000]\ttraining's auc: 0.934085\tvalid_1's auc: 0.900182\n",
      "[7000]\ttraining's auc: 0.937978\tvalid_1's auc: 0.900687\n",
      "[8000]\ttraining's auc: 0.941648\tvalid_1's auc: 0.900745\n",
      "[9000]\ttraining's auc: 0.945235\tvalid_1's auc: 0.900773\n",
      "[10000]\ttraining's auc: 0.94862\tvalid_1's auc: 0.900838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000]\ttraining's auc: 0.951843\tvalid_1's auc: 0.900587\n",
      "[12000]\ttraining's auc: 0.954894\tvalid_1's auc: 0.900639\n",
      "Early stopping, best iteration is:\n",
      "[9691]\ttraining's auc: 0.947612\tvalid_1's auc: 0.900898\n",
      "Total run time 32.88335924545924 min:\n",
      "CV score: 0.90053 \n"
     ]
    }
   ],
   "source": [
    "train_results_whole = train(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    train_df['target'],\n",
    "    train_df.columns.drop(['ID_code', 'target']).tolist(),\n",
    "    param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_whole, predictions_whole, feature_importance_whole, clf_ucm_whole = train_results_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_whole = pd.DataFrame(data=predictions_whole, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_5_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2, predictions_df_whole],\n",
    "    [1, 1, 1, 2, 3]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_5_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_5_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_5_df.to_csv('blended_5_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_ucm_less_1_4, predictions_less_1_4, feature_importance_less_1_4, clf_less_1_4 = train_results_less_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_less_1_4 = pd.DataFrame(data=predictions_less_1_4, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_6_var_1_prediction = simply_blend(\n",
    "    [predictions_df, predictions_df_ucm_1_4_1_2, predictions_df_ucm_1_4, predictions_df_more_1_2, predictions_df_whole, predictions_df_less_1_4],\n",
    "    [1, 1, 1, 1, 4, 1]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_6_var_1_df = pd.DataFrame({'ID_code': ID_code, 'target': blended_6_var_1_prediction['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_blended_6_var_1_df.to_csv('blended_6_var_1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_whole_only_df = pd.DataFrame({'ID_code': ID_code, 'target': predictions_df_whole['target'].values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_whole_only_df.to_csv('submission_whole_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(train_features, train_targets, model, batch_size, epochs, n_splits):\n",
    "    loss_history = LossHistory()\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [EarlyStopping(monitor='val_auc', patience=20, mode='max'), loss_history, annealer]\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits)\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in sss.split(train_features, train_targets):\n",
    "        X_train, X_val = train_features[train_index], train_features[test_index]\n",
    "        Y_train, Y_val = train_targets[train_index], train_targets[test_index]\n",
    "        #X_tr, Y_tr = augment(X_train, Y_train)\n",
    "        #print(\"{} iteration\".format(i+1))\n",
    "        history= model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "        #history= sequential_nn_model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "        del X_train, X_val, Y_train, Y_val\n",
    "        gc.collect()\n",
    "    print(\"Run time {} min\".format((time.time() - start_time) / 60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer=regularizers.l2(0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_polinomial_values_ucm_1_2.shape[1],)))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, input_shape=(train_polinomial_values_ucm_1_2.shape[1] / 2, ), activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, input_shape=(train_polinomial_values_ucm_1_2.shape[1] / 4, ), activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "#def auc(y_pred, y_true):\n",
    "    #print(y_true[:5])\n",
    "    #print(y_pred[:5])  \n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 10s 71us/step - loss: 0.3273 - acc: 0.8830 - auc: 0.6907 - val_loss: 0.2801 - val_acc: 0.9012 - val_auc: 0.7700\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2842 - acc: 0.8997 - auc: 0.7627 - val_loss: 0.2769 - val_acc: 0.9036 - val_auc: 0.7740\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2805 - acc: 0.9000 - auc: 0.7732 - val_loss: 0.2771 - val_acc: 0.9014 - val_auc: 0.7752\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2783 - acc: 0.9003 - auc: 0.7787 - val_loss: 0.2769 - val_acc: 0.9026 - val_auc: 0.7759\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2765 - acc: 0.9007 - auc: 0.7827 - val_loss: 0.2744 - val_acc: 0.9031 - val_auc: 0.7804\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2753 - acc: 0.9007 - auc: 0.7861 - val_loss: 0.2768 - val_acc: 0.9028 - val_auc: 0.7797\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2728 - acc: 0.9013 - auc: 0.7911 - val_loss: 0.2747 - val_acc: 0.9033 - val_auc: 0.7806\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2708 - acc: 0.9018 - auc: 0.7948 - val_loss: 0.2824 - val_acc: 0.9031 - val_auc: 0.7787\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2691 - acc: 0.9020 - auc: 0.7991 - val_loss: 0.2752 - val_acc: 0.9038 - val_auc: 0.7788\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2687 - acc: 0.9017 - auc: 0.8003 - val_loss: 0.2734 - val_acc: 0.9036 - val_auc: 0.7829\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2670 - acc: 0.9021 - auc: 0.8042 - val_loss: 0.2734 - val_acc: 0.9044 - val_auc: 0.7821\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2657 - acc: 0.9032 - auc: 0.8056 - val_loss: 0.2735 - val_acc: 0.9048 - val_auc: 0.7805\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2635 - acc: 0.9032 - auc: 0.8106 - val_loss: 0.2737 - val_acc: 0.9042 - val_auc: 0.7818\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2621 - acc: 0.9034 - auc: 0.8137 - val_loss: 0.2754 - val_acc: 0.9039 - val_auc: 0.7824\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2597 - acc: 0.9049 - auc: 0.8173 - val_loss: 0.2786 - val_acc: 0.9039 - val_auc: 0.7808\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2582 - acc: 0.9053 - auc: 0.8206 - val_loss: 0.2772 - val_acc: 0.9044 - val_auc: 0.7805\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2579 - acc: 0.9050 - auc: 0.8201 - val_loss: 0.2736 - val_acc: 0.9048 - val_auc: 0.7809\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2552 - acc: 0.9054 - auc: 0.8262 - val_loss: 0.2757 - val_acc: 0.9032 - val_auc: 0.7808\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2528 - acc: 0.9065 - auc: 0.8295 - val_loss: 0.2792 - val_acc: 0.9038 - val_auc: 0.7785\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2507 - acc: 0.9067 - auc: 0.8336 - val_loss: 0.2767 - val_acc: 0.9041 - val_auc: 0.7800\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2499 - acc: 0.9076 - auc: 0.8346 - val_loss: 0.2787 - val_acc: 0.9031 - val_auc: 0.7797\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2473 - acc: 0.9079 - auc: 0.8388 - val_loss: 0.2755 - val_acc: 0.9038 - val_auc: 0.7784\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 9s 60us/step - loss: 0.2450 - acc: 0.9086 - auc: 0.8425 - val_loss: 0.2834 - val_acc: 0.9039 - val_auc: 0.7743\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2411 - acc: 0.9104 - auc: 0.8489 - val_loss: 0.2790 - val_acc: 0.9027 - val_auc: 0.7735\n",
      "Epoch 25/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2394 - acc: 0.9106 - auc: 0.8511 - val_loss: 0.2845 - val_acc: 0.9023 - val_auc: 0.7715\n",
      "Epoch 26/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2370 - acc: 0.9118 - auc: 0.8545 - val_loss: 0.2901 - val_acc: 0.9028 - val_auc: 0.7690\n",
      "Epoch 27/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2331 - acc: 0.9133 - auc: 0.8604 - val_loss: 0.2819 - val_acc: 0.9027 - val_auc: 0.7706\n",
      "Epoch 28/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2310 - acc: 0.9152 - auc: 0.8630 - val_loss: 0.2851 - val_acc: 0.9009 - val_auc: 0.7694\n",
      "Epoch 29/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2287 - acc: 0.9158 - auc: 0.8669 - val_loss: 0.2894 - val_acc: 0.9024 - val_auc: 0.7669\n",
      "Epoch 30/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2242 - acc: 0.9172 - auc: 0.8722 - val_loss: 0.2902 - val_acc: 0.9018 - val_auc: 0.7663\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2523 - acc: 0.9077 - auc: 0.8287 - val_loss: 0.2402 - val_acc: 0.9116 - val_auc: 0.8512\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2520 - acc: 0.9066 - auc: 0.8303 - val_loss: 0.2442 - val_acc: 0.9104 - val_auc: 0.8463\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2511 - acc: 0.9083 - auc: 0.8306 - val_loss: 0.2425 - val_acc: 0.9105 - val_auc: 0.8468\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2490 - acc: 0.9085 - auc: 0.8348 - val_loss: 0.2457 - val_acc: 0.9106 - val_auc: 0.8455\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2475 - acc: 0.9088 - auc: 0.8373 - val_loss: 0.2440 - val_acc: 0.9119 - val_auc: 0.8416\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2449 - acc: 0.9101 - auc: 0.8404 - val_loss: 0.2485 - val_acc: 0.9086 - val_auc: 0.8420\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2437 - acc: 0.9104 - auc: 0.8442 - val_loss: 0.2467 - val_acc: 0.9100 - val_auc: 0.8410\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 9s 59us/step - loss: 0.2415 - acc: 0.9110 - auc: 0.8476 - val_loss: 0.2477 - val_acc: 0.9110 - val_auc: 0.8375\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2394 - acc: 0.9123 - auc: 0.8499 - val_loss: 0.2469 - val_acc: 0.9108 - val_auc: 0.8391\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2360 - acc: 0.9136 - auc: 0.8541 - val_loss: 0.2455 - val_acc: 0.9119 - val_auc: 0.8373\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2329 - acc: 0.9142 - auc: 0.8592 - val_loss: 0.2446 - val_acc: 0.9116 - val_auc: 0.8387\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2305 - acc: 0.9158 - auc: 0.8624 - val_loss: 0.2498 - val_acc: 0.9101 - val_auc: 0.8377\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2286 - acc: 0.9163 - auc: 0.8648 - val_loss: 0.2519 - val_acc: 0.9108 - val_auc: 0.8370\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2238 - acc: 0.9190 - auc: 0.8701 - val_loss: 0.2472 - val_acc: 0.9086 - val_auc: 0.8368\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2213 - acc: 0.9201 - auc: 0.8743 - val_loss: 0.2507 - val_acc: 0.9094 - val_auc: 0.8351\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2179 - acc: 0.9214 - auc: 0.8771 - val_loss: 0.2489 - val_acc: 0.9108 - val_auc: 0.8381\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2140 - acc: 0.9235 - auc: 0.8814 - val_loss: 0.2491 - val_acc: 0.9109 - val_auc: 0.8369\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2096 - acc: 0.9250 - auc: 0.8874 - val_loss: 0.2489 - val_acc: 0.9117 - val_auc: 0.8344\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 56us/step - loss: 0.2079 - acc: 0.9255 - auc: 0.8898 - val_loss: 0.2521 - val_acc: 0.9113 - val_auc: 0.8342\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2031 - acc: 0.9276 - auc: 0.8951 - val_loss: 0.2609 - val_acc: 0.9103 - val_auc: 0.8275\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 7s 46us/step - loss: 0.2002 - acc: 0.9290 - auc: 0.8972 - val_loss: 0.2567 - val_acc: 0.9109 - val_auc: 0.8333\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2283 - acc: 0.9178 - auc: 0.8640 - val_loss: 0.1989 - val_acc: 0.9279 - val_auc: 0.9058\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2265 - acc: 0.9182 - auc: 0.8657 - val_loss: 0.2043 - val_acc: 0.9251 - val_auc: 0.9025\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2252 - acc: 0.9182 - auc: 0.8686 - val_loss: 0.2091 - val_acc: 0.9226 - val_auc: 0.8934\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2231 - acc: 0.9196 - auc: 0.8711 - val_loss: 0.2068 - val_acc: 0.9233 - val_auc: 0.8989\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2200 - acc: 0.9208 - auc: 0.8745 - val_loss: 0.2130 - val_acc: 0.9197 - val_auc: 0.8985\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2167 - acc: 0.9223 - auc: 0.8780 - val_loss: 0.2056 - val_acc: 0.9256 - val_auc: 0.8943\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2149 - acc: 0.9229 - auc: 0.8808 - val_loss: 0.2082 - val_acc: 0.9246 - val_auc: 0.8975\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2108 - acc: 0.9249 - auc: 0.8861 - val_loss: 0.2097 - val_acc: 0.9227 - val_auc: 0.8941\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2078 - acc: 0.9257 - auc: 0.8889 - val_loss: 0.2035 - val_acc: 0.9274 - val_auc: 0.8950\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2043 - acc: 0.9269 - auc: 0.8924 - val_loss: 0.2393 - val_acc: 0.9103 - val_auc: 0.8884\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.2020 - acc: 0.9281 - auc: 0.8952 - val_loss: 0.2123 - val_acc: 0.9212 - val_auc: 0.8926\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1977 - acc: 0.9304 - auc: 0.8998 - val_loss: 0.2130 - val_acc: 0.9217 - val_auc: 0.8937\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1930 - acc: 0.9320 - auc: 0.9049 - val_loss: 0.2173 - val_acc: 0.9195 - val_auc: 0.8934\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1898 - acc: 0.9331 - auc: 0.9080 - val_loss: 0.2034 - val_acc: 0.9287 - val_auc: 0.8965\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1868 - acc: 0.9343 - auc: 0.9107 - val_loss: 0.2116 - val_acc: 0.9261 - val_auc: 0.8941\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1830 - acc: 0.9363 - auc: 0.9142 - val_loss: 0.2064 - val_acc: 0.9261 - val_auc: 0.8937\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1791 - acc: 0.9380 - auc: 0.9170 - val_loss: 0.2203 - val_acc: 0.9202 - val_auc: 0.8908\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1759 - acc: 0.9390 - auc: 0.9202 - val_loss: 0.2174 - val_acc: 0.9249 - val_auc: 0.8936\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1732 - acc: 0.9401 - auc: 0.9237 - val_loss: 0.2120 - val_acc: 0.9241 - val_auc: 0.8925\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1693 - acc: 0.9418 - auc: 0.9264 - val_loss: 0.2013 - val_acc: 0.9294 - val_auc: 0.8960\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1664 - acc: 0.9424 - auc: 0.9299 - val_loss: 0.2040 - val_acc: 0.9277 - val_auc: 0.8980\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2004 - acc: 0.9290 - auc: 0.8964 - val_loss: 0.1622 - val_acc: 0.9427 - val_auc: 0.9434\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.2020 - acc: 0.9290 - auc: 0.8937 - val_loss: 0.1670 - val_acc: 0.9414 - val_auc: 0.9389\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1976 - acc: 0.9296 - auc: 0.9008 - val_loss: 0.1695 - val_acc: 0.9378 - val_auc: 0.9385\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1960 - acc: 0.9317 - auc: 0.9015 - val_loss: 0.1681 - val_acc: 0.9411 - val_auc: 0.9384\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1937 - acc: 0.9313 - auc: 0.9051 - val_loss: 0.1640 - val_acc: 0.9437 - val_auc: 0.9352\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1879 - acc: 0.9336 - auc: 0.9099 - val_loss: 0.1647 - val_acc: 0.9424 - val_auc: 0.9361\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1850 - acc: 0.9350 - auc: 0.9127 - val_loss: 0.1633 - val_acc: 0.9456 - val_auc: 0.9317\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1835 - acc: 0.9358 - auc: 0.9146 - val_loss: 0.1610 - val_acc: 0.9454 - val_auc: 0.9340\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1788 - acc: 0.9371 - auc: 0.9187 - val_loss: 0.1769 - val_acc: 0.9354 - val_auc: 0.9368\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1747 - acc: 0.9387 - auc: 0.9234 - val_loss: 0.1734 - val_acc: 0.9347 - val_auc: 0.9385\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1715 - acc: 0.9405 - auc: 0.9252 - val_loss: 0.1643 - val_acc: 0.9409 - val_auc: 0.9354\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1700 - acc: 0.9403 - auc: 0.9278 - val_loss: 0.1634 - val_acc: 0.9431 - val_auc: 0.9337\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1655 - acc: 0.9423 - auc: 0.9319 - val_loss: 0.1686 - val_acc: 0.9402 - val_auc: 0.9330\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1635 - acc: 0.9434 - auc: 0.9324 - val_loss: 0.1709 - val_acc: 0.9405 - val_auc: 0.9363\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1596 - acc: 0.9444 - auc: 0.9361 - val_loss: 0.1612 - val_acc: 0.9444 - val_auc: 0.9362\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1554 - acc: 0.9461 - auc: 0.9396 - val_loss: 0.1678 - val_acc: 0.9397 - val_auc: 0.9355\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1521 - acc: 0.9472 - auc: 0.9425 - val_loss: 0.1685 - val_acc: 0.9418 - val_auc: 0.9344\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1490 - acc: 0.9483 - auc: 0.9444 - val_loss: 0.1585 - val_acc: 0.9459 - val_auc: 0.9355\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1476 - acc: 0.9496 - auc: 0.9455 - val_loss: 0.1637 - val_acc: 0.9430 - val_auc: 0.9343\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1424 - acc: 0.9502 - auc: 0.9498 - val_loss: 0.1811 - val_acc: 0.9377 - val_auc: 0.9348\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1407 - acc: 0.9514 - auc: 0.9501 - val_loss: 0.1630 - val_acc: 0.9453 - val_auc: 0.9363\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1753 - acc: 0.9386 - auc: 0.9231 - val_loss: 0.1274 - val_acc: 0.9563 - val_auc: 0.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1791 - acc: 0.9381 - auc: 0.9184 - val_loss: 0.1329 - val_acc: 0.9527 - val_auc: 0.9623\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1746 - acc: 0.9390 - auc: 0.9242 - val_loss: 0.1444 - val_acc: 0.9447 - val_auc: 0.9621\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1716 - acc: 0.9401 - auc: 0.9268 - val_loss: 0.1353 - val_acc: 0.9496 - val_auc: 0.9602\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1696 - acc: 0.9405 - auc: 0.9279 - val_loss: 0.1419 - val_acc: 0.9460 - val_auc: 0.9617\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 55us/step - loss: 0.1663 - acc: 0.9422 - auc: 0.9317 - val_loss: 0.1568 - val_acc: 0.9418 - val_auc: 0.9591\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1636 - acc: 0.9428 - auc: 0.9330 - val_loss: 0.1380 - val_acc: 0.9483 - val_auc: 0.9602\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1609 - acc: 0.9435 - auc: 0.9367 - val_loss: 0.1327 - val_acc: 0.9524 - val_auc: 0.9582\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1537 - acc: 0.9455 - auc: 0.9424 - val_loss: 0.1432 - val_acc: 0.9461 - val_auc: 0.9612\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1521 - acc: 0.9465 - auc: 0.9434 - val_loss: 0.1468 - val_acc: 0.9437 - val_auc: 0.9622\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1491 - acc: 0.9479 - auc: 0.9452 - val_loss: 0.1419 - val_acc: 0.9452 - val_auc: 0.9617\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1474 - acc: 0.9486 - auc: 0.9459 - val_loss: 0.1522 - val_acc: 0.9408 - val_auc: 0.9618\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1429 - acc: 0.9503 - auc: 0.9494 - val_loss: 0.1488 - val_acc: 0.9409 - val_auc: 0.9636\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1405 - acc: 0.9514 - auc: 0.9511 - val_loss: 0.1382 - val_acc: 0.9488 - val_auc: 0.9601\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1371 - acc: 0.9526 - auc: 0.9535 - val_loss: 0.1360 - val_acc: 0.9487 - val_auc: 0.9616\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 59us/step - loss: 0.1335 - acc: 0.9539 - auc: 0.9553 - val_loss: 0.1444 - val_acc: 0.9426 - val_auc: 0.9639\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1300 - acc: 0.9547 - auc: 0.9581 - val_loss: 0.1319 - val_acc: 0.9518 - val_auc: 0.9621\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 58us/step - loss: 0.1291 - acc: 0.9548 - auc: 0.9590 - val_loss: 0.1347 - val_acc: 0.9497 - val_auc: 0.9625\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.1251 - acc: 0.9561 - auc: 0.9618 - val_loss: 0.1353 - val_acc: 0.9489 - val_auc: 0.9625\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1237 - acc: 0.9574 - auc: 0.9619 - val_loss: 0.1354 - val_acc: 0.9491 - val_auc: 0.9618\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1210 - acc: 0.9579 - auc: 0.9644 - val_loss: 0.1267 - val_acc: 0.9544 - val_auc: 0.9635\n",
      "Run time 16.190694542725883 min\n"
     ]
    }
   ],
   "source": [
    "train_nn_result_ucm_1_2 = train_nn(train_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 49us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40964529108256104, 0.8953000018000603, 0.7162384706535537]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 55us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = train_nn_result_ucm_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40964529108256104, 0.8953000018000603, 0.7162384706535537]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_polinomial_values_ucm_1_2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6215"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model = Sequential()\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "###sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(Dropout(0.4))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "###sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 2, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 10, kernel_initializer='normal', activation='sigmoid'))\n",
    "###sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(Dropout(0.4))\n",
    "##sequential_nn_model.add(BatchNormalization())\n",
    "##sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='relu'))\n",
    "##sequential_nn_model.add(Dropout(0.1))\n",
    "##sequential_nn_model.add(BatchNormalization())\n",
    "##sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dropout(0.76))\n",
    "#sequential_nn_model.add(Dropout(0.24))\n",
    "##sequential_nn_model.add(Dropout(0.1))\n",
    "##sequential_nn_model.add(BatchNormalization())\n",
    "##sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='relu'))\n",
    "##sequential_nn_model.add(Dropout(0.1))\n",
    "##sequential_nn_model.add(BatchNormalization())\n",
    "##sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='sigmoid'))\n",
    "##sequential_nn_model.add(Dropout(0.1))\n",
    "##sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 57us/step - loss: 0.2873 - acc: 0.8991 - auc: 0.7600 - val_loss: 0.2802 - val_acc: 0.9019 - val_auc: 0.7811\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2755 - acc: 0.9005 - auc: 0.7835 - val_loss: 0.2751 - val_acc: 0.9026 - val_auc: 0.7857\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2714 - acc: 0.9018 - auc: 0.7928 - val_loss: 0.2758 - val_acc: 0.9033 - val_auc: 0.7868\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2681 - acc: 0.9031 - auc: 0.8019 - val_loss: 0.2731 - val_acc: 0.9035 - val_auc: 0.7881\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2639 - acc: 0.9036 - auc: 0.8090 - val_loss: 0.2736 - val_acc: 0.9039 - val_auc: 0.7849\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2605 - acc: 0.9046 - auc: 0.8161 - val_loss: 0.2725 - val_acc: 0.9041 - val_auc: 0.7880\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2575 - acc: 0.9052 - auc: 0.8223 - val_loss: 0.2734 - val_acc: 0.9029 - val_auc: 0.7840\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2540 - acc: 0.9057 - auc: 0.8291 - val_loss: 0.2759 - val_acc: 0.9032 - val_auc: 0.7823\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2510 - acc: 0.9072 - auc: 0.8344 - val_loss: 0.2752 - val_acc: 0.9032 - val_auc: 0.7815\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2467 - acc: 0.9081 - auc: 0.8425 - val_loss: 0.2793 - val_acc: 0.9041 - val_auc: 0.7816\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2442 - acc: 0.9087 - auc: 0.8465 - val_loss: 0.2828 - val_acc: 0.9038 - val_auc: 0.7808\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2401 - acc: 0.9097 - auc: 0.8538 - val_loss: 0.2811 - val_acc: 0.9030 - val_auc: 0.7788\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2362 - acc: 0.9106 - auc: 0.8603 - val_loss: 0.2835 - val_acc: 0.9026 - val_auc: 0.7767\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2314 - acc: 0.9120 - auc: 0.8673 - val_loss: 0.2874 - val_acc: 0.9036 - val_auc: 0.7747\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2275 - acc: 0.9125 - auc: 0.8743 - val_loss: 0.2918 - val_acc: 0.9028 - val_auc: 0.7725\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 55us/step - loss: 0.2233 - acc: 0.9137 - auc: 0.8797 - val_loss: 0.2933 - val_acc: 0.9021 - val_auc: 0.7683\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2173 - acc: 0.9154 - auc: 0.8873 - val_loss: 0.2924 - val_acc: 0.9016 - val_auc: 0.7689\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2138 - acc: 0.9161 - auc: 0.8925 - val_loss: 0.3010 - val_acc: 0.8989 - val_auc: 0.7656\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.2068 - acc: 0.9185 - auc: 0.9016 - val_loss: 0.3111 - val_acc: 0.8999 - val_auc: 0.7630\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.2027 - acc: 0.9196 - auc: 0.9065 - val_loss: 0.3106 - val_acc: 0.8983 - val_auc: 0.7643\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1959 - acc: 0.9219 - auc: 0.9137 - val_loss: 0.3140 - val_acc: 0.8994 - val_auc: 0.7564\n",
      "Epoch 22/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1890 - acc: 0.9241 - auc: 0.9205 - val_loss: 0.3221 - val_acc: 0.8994 - val_auc: 0.7561\n",
      "Epoch 23/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1836 - acc: 0.9261 - auc: 0.9261 - val_loss: 0.3372 - val_acc: 0.8961 - val_auc: 0.7544\n",
      "Epoch 24/50\n",
      "144000/144000 [==============================] - 7s 49us/step - loss: 0.1771 - acc: 0.9284 - auc: 0.9316 - val_loss: 0.3471 - val_acc: 0.8974 - val_auc: 0.7479\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2200 - acc: 0.9159 - auc: 0.8824 - val_loss: 0.2048 - val_acc: 0.9221 - val_auc: 0.9031\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2161 - acc: 0.9171 - auc: 0.8888 - val_loss: 0.2091 - val_acc: 0.9166 - val_auc: 0.8983\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2103 - acc: 0.9186 - auc: 0.8955 - val_loss: 0.2090 - val_acc: 0.9166 - val_auc: 0.8985\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.2061 - acc: 0.9196 - auc: 0.9007 - val_loss: 0.2107 - val_acc: 0.9175 - val_auc: 0.8949\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2010 - acc: 0.9215 - auc: 0.9062 - val_loss: 0.2116 - val_acc: 0.9186 - val_auc: 0.8950\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1950 - acc: 0.9237 - auc: 0.9126 - val_loss: 0.2160 - val_acc: 0.9171 - val_auc: 0.8947\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1875 - acc: 0.9260 - auc: 0.9212 - val_loss: 0.2165 - val_acc: 0.9174 - val_auc: 0.8881\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1848 - acc: 0.9270 - auc: 0.9238 - val_loss: 0.2196 - val_acc: 0.9149 - val_auc: 0.8885\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1768 - acc: 0.9300 - auc: 0.9304 - val_loss: 0.2218 - val_acc: 0.9177 - val_auc: 0.8862\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1711 - acc: 0.9324 - auc: 0.9351 - val_loss: 0.2226 - val_acc: 0.9171 - val_auc: 0.8841\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 6s 44us/step - loss: 0.1652 - acc: 0.9339 - auc: 0.9410 - val_loss: 0.2231 - val_acc: 0.9171 - val_auc: 0.8860\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1584 - acc: 0.9373 - auc: 0.9459 - val_loss: 0.2281 - val_acc: 0.9166 - val_auc: 0.8821\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1513 - acc: 0.9403 - auc: 0.9505 - val_loss: 0.2359 - val_acc: 0.9161 - val_auc: 0.8827\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 7s 45us/step - loss: 0.1439 - acc: 0.9439 - auc: 0.9555 - val_loss: 0.2388 - val_acc: 0.9156 - val_auc: 0.8788\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1378 - acc: 0.9468 - auc: 0.9593 - val_loss: 0.2463 - val_acc: 0.9154 - val_auc: 0.8794\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1335 - acc: 0.9490 - auc: 0.9618 - val_loss: 0.2466 - val_acc: 0.9159 - val_auc: 0.8777\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1272 - acc: 0.9510 - auc: 0.9657 - val_loss: 0.2584 - val_acc: 0.9150 - val_auc: 0.8765\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1234 - acc: 0.9529 - auc: 0.9676 - val_loss: 0.2647 - val_acc: 0.9155 - val_auc: 0.8731\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1182 - acc: 0.9557 - auc: 0.9703 - val_loss: 0.2477 - val_acc: 0.9142 - val_auc: 0.8778\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1123 - acc: 0.9575 - auc: 0.9733 - val_loss: 0.2517 - val_acc: 0.9154 - val_auc: 0.8776\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.1074 - acc: 0.9599 - auc: 0.9751 - val_loss: 0.2627 - val_acc: 0.9141 - val_auc: 0.8755\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 6s 44us/step - loss: 0.1604 - acc: 0.9399 - auc: 0.9412 - val_loss: 0.1247 - val_acc: 0.9546 - val_auc: 0.9671\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1574 - acc: 0.9406 - auc: 0.9444 - val_loss: 0.1260 - val_acc: 0.9531 - val_auc: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1520 - acc: 0.9425 - auc: 0.9482 - val_loss: 0.1302 - val_acc: 0.9500 - val_auc: 0.9634\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 52us/step - loss: 0.1462 - acc: 0.9451 - auc: 0.9530 - val_loss: 0.1314 - val_acc: 0.9482 - val_auc: 0.9630\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1391 - acc: 0.9477 - auc: 0.9572 - val_loss: 0.1352 - val_acc: 0.9479 - val_auc: 0.9594\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1351 - acc: 0.9496 - auc: 0.9599 - val_loss: 0.1364 - val_acc: 0.9492 - val_auc: 0.9590\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1286 - acc: 0.9526 - auc: 0.9631 - val_loss: 0.1445 - val_acc: 0.9430 - val_auc: 0.9591\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1252 - acc: 0.9539 - auc: 0.9654 - val_loss: 0.1350 - val_acc: 0.9491 - val_auc: 0.9590\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 6s 45us/step - loss: 0.1186 - acc: 0.9567 - auc: 0.9688 - val_loss: 0.1374 - val_acc: 0.9485 - val_auc: 0.9593\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1149 - acc: 0.9577 - auc: 0.9713 - val_loss: 0.1455 - val_acc: 0.9442 - val_auc: 0.9598\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1066 - acc: 0.9616 - auc: 0.9745 - val_loss: 0.1405 - val_acc: 0.9468 - val_auc: 0.9586\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1048 - acc: 0.9619 - auc: 0.9754 - val_loss: 0.1471 - val_acc: 0.9456 - val_auc: 0.9557\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0990 - acc: 0.9644 - auc: 0.9784 - val_loss: 0.1441 - val_acc: 0.9484 - val_auc: 0.9560\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0936 - acc: 0.9664 - auc: 0.9801 - val_loss: 0.1476 - val_acc: 0.9451 - val_auc: 0.9581\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0895 - acc: 0.9683 - auc: 0.9819 - val_loss: 0.1461 - val_acc: 0.9456 - val_auc: 0.9580\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0854 - acc: 0.9697 - auc: 0.9835 - val_loss: 0.1501 - val_acc: 0.9444 - val_auc: 0.9557\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0834 - acc: 0.9703 - auc: 0.9846 - val_loss: 0.1478 - val_acc: 0.9469 - val_auc: 0.9571\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0788 - acc: 0.9720 - auc: 0.9859 - val_loss: 0.1529 - val_acc: 0.9455 - val_auc: 0.9557\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0759 - acc: 0.9733 - auc: 0.9866 - val_loss: 0.1520 - val_acc: 0.9470 - val_auc: 0.9543\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 7s 52us/step - loss: 0.0741 - acc: 0.9739 - auc: 0.9874 - val_loss: 0.1497 - val_acc: 0.9473 - val_auc: 0.9553\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0696 - acc: 0.9757 - auc: 0.9887 - val_loss: 0.1696 - val_acc: 0.9435 - val_auc: 0.9541\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1229 - acc: 0.9556 - auc: 0.9651 - val_loss: 0.0741 - val_acc: 0.9791 - val_auc: 0.9892\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.1209 - acc: 0.9560 - auc: 0.9671 - val_loss: 0.0776 - val_acc: 0.9777 - val_auc: 0.9885\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1144 - acc: 0.9583 - auc: 0.9709 - val_loss: 0.0822 - val_acc: 0.9770 - val_auc: 0.9871\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1117 - acc: 0.9591 - auc: 0.9720 - val_loss: 0.0776 - val_acc: 0.9760 - val_auc: 0.9868\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1049 - acc: 0.9621 - auc: 0.9755 - val_loss: 0.0802 - val_acc: 0.9747 - val_auc: 0.9870\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0989 - acc: 0.9644 - auc: 0.9782 - val_loss: 0.0792 - val_acc: 0.9711 - val_auc: 0.9875\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0964 - acc: 0.9652 - auc: 0.9792 - val_loss: 0.0839 - val_acc: 0.9682 - val_auc: 0.9860\n",
      "Epoch 8/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0923 - acc: 0.9669 - auc: 0.9807 - val_loss: 0.0826 - val_acc: 0.9722 - val_auc: 0.9854\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0876 - acc: 0.9692 - auc: 0.9824 - val_loss: 0.0804 - val_acc: 0.9705 - val_auc: 0.9865\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0828 - acc: 0.9709 - auc: 0.9842 - val_loss: 0.0795 - val_acc: 0.9729 - val_auc: 0.9857\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0807 - acc: 0.9717 - auc: 0.9853 - val_loss: 0.0817 - val_acc: 0.9696 - val_auc: 0.9863\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0741 - acc: 0.9742 - auc: 0.9870 - val_loss: 0.0814 - val_acc: 0.9706 - val_auc: 0.9855\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0719 - acc: 0.9746 - auc: 0.9884 - val_loss: 0.0795 - val_acc: 0.9729 - val_auc: 0.9862\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0710 - acc: 0.9750 - auc: 0.9884 - val_loss: 0.0854 - val_acc: 0.9679 - val_auc: 0.9869\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0665 - acc: 0.9769 - auc: 0.9895 - val_loss: 0.0831 - val_acc: 0.9714 - val_auc: 0.9846\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0641 - acc: 0.9776 - auc: 0.9906 - val_loss: 0.0830 - val_acc: 0.9707 - val_auc: 0.9858\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0599 - acc: 0.9795 - auc: 0.9914 - val_loss: 0.0890 - val_acc: 0.9679 - val_auc: 0.9859\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 7s 50us/step - loss: 0.0569 - acc: 0.9802 - auc: 0.9924 - val_loss: 0.0889 - val_acc: 0.9686 - val_auc: 0.9856\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0546 - acc: 0.9811 - auc: 0.9926 - val_loss: 0.0851 - val_acc: 0.9693 - val_auc: 0.9851\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0541 - acc: 0.9812 - auc: 0.9931 - val_loss: 0.0864 - val_acc: 0.9688 - val_auc: 0.9849\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0514 - acc: 0.9823 - auc: 0.9934 - val_loss: 0.0823 - val_acc: 0.9708 - val_auc: 0.9858\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.1008 - acc: 0.9645 - auc: 0.9765 - val_loss: 0.0539 - val_acc: 0.9833 - val_auc: 0.9956\n",
      "Epoch 2/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0975 - acc: 0.9648 - auc: 0.9791 - val_loss: 0.0502 - val_acc: 0.9854 - val_auc: 0.9955\n",
      "Epoch 3/50\n",
      "144000/144000 [==============================] - 7s 48us/step - loss: 0.0944 - acc: 0.9659 - auc: 0.9808 - val_loss: 0.0491 - val_acc: 0.9854 - val_auc: 0.9951\n",
      "Epoch 4/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.0886 - acc: 0.9684 - auc: 0.9826 - val_loss: 0.0534 - val_acc: 0.9851 - val_auc: 0.9941\n",
      "Epoch 5/50\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.0864 - acc: 0.9683 - auc: 0.9836 - val_loss: 0.0521 - val_acc: 0.9862 - val_auc: 0.9942\n",
      "Epoch 6/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0813 - acc: 0.9710 - auc: 0.9852 - val_loss: 0.0544 - val_acc: 0.9826 - val_auc: 0.9952\n",
      "Epoch 7/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0786 - acc: 0.9719 - auc: 0.9865 - val_loss: 0.0549 - val_acc: 0.9832 - val_auc: 0.9944\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0745 - acc: 0.9731 - auc: 0.9882 - val_loss: 0.0512 - val_acc: 0.9849 - val_auc: 0.9945\n",
      "Epoch 9/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0717 - acc: 0.9749 - auc: 0.9886 - val_loss: 0.0544 - val_acc: 0.9816 - val_auc: 0.9947\n",
      "Epoch 10/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0672 - acc: 0.9764 - auc: 0.9897 - val_loss: 0.0513 - val_acc: 0.9844 - val_auc: 0.9942\n",
      "Epoch 11/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0645 - acc: 0.9774 - auc: 0.9905 - val_loss: 0.0544 - val_acc: 0.9821 - val_auc: 0.9940\n",
      "Epoch 12/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0623 - acc: 0.9785 - auc: 0.9912 - val_loss: 0.0528 - val_acc: 0.9831 - val_auc: 0.9937\n",
      "Epoch 13/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0581 - acc: 0.9800 - auc: 0.9921 - val_loss: 0.0567 - val_acc: 0.9799 - val_auc: 0.9939\n",
      "Epoch 14/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0548 - acc: 0.9809 - auc: 0.9932 - val_loss: 0.0544 - val_acc: 0.9832 - val_auc: 0.9933\n",
      "Epoch 15/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0532 - acc: 0.9818 - auc: 0.9933 - val_loss: 0.0499 - val_acc: 0.9833 - val_auc: 0.9942\n",
      "Epoch 16/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0517 - acc: 0.9820 - auc: 0.9937 - val_loss: 0.0471 - val_acc: 0.9851 - val_auc: 0.9945\n",
      "Epoch 17/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0476 - acc: 0.9835 - auc: 0.9949 - val_loss: 0.0500 - val_acc: 0.9841 - val_auc: 0.9942\n",
      "Epoch 18/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0472 - acc: 0.9838 - auc: 0.9946 - val_loss: 0.0512 - val_acc: 0.9839 - val_auc: 0.9938\n",
      "Epoch 19/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0452 - acc: 0.9844 - auc: 0.9951 - val_loss: 0.0491 - val_acc: 0.9841 - val_auc: 0.9938\n",
      "Epoch 20/50\n",
      "144000/144000 [==============================] - 8s 54us/step - loss: 0.0429 - acc: 0.9853 - auc: 0.9954 - val_loss: 0.0485 - val_acc: 0.9842 - val_auc: 0.9938\n",
      "Epoch 21/50\n",
      "144000/144000 [==============================] - 8s 53us/step - loss: 0.0396 - acc: 0.9863 - auc: 0.9963 - val_loss: 0.0488 - val_acc: 0.9842 - val_auc: 0.9934\n",
      "Run time 13.482337999343873 min\n"
     ]
    }
   ],
   "source": [
    "secquential_nn_model_1_2 = train_nn(train_polinomial_values_ucm_1_2, train_target_values_ucm_1_2, sequential_nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 52us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = secquential_nn_model_1_2.evaluate(holdout_test_polinomial_values_ucm_1_2, holdout_test_target_values_ucm_1_2, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.585995932482183, 0.8846999990940094, 0.5885962312027564]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5543117852136493, 0.8831499993801117, 0.7176417884978589]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min = Sequential()\n",
    "sequential_nn_model_min.add(Dense(batch_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model_min.add(Dropout(0.4))\n",
    "sequential_nn_model_min.add(BatchNormalization())\n",
    "sequential_nn_model_min.add(Dense(batch_size, input_dim=input_dim / 10, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model_min.add(Dropout(0.4))\n",
    "sequential_nn_model_min.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model_min.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
