{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standart_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_train_values = min_max_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "scaled_train_values = standart_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "#scaled_train_values = robust_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_values.shape)\n",
    "print(train_target_values.shape)\n",
    "print(holdout_test_values.shape)\n",
    "print(holdout_test_target_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_code = test_df['ID_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ID_code[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.py_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "#def auc(y_pred, y_true):\n",
    "    #print(y_true[:5])\n",
    "    #print(y_pred[:5])  \n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    #return tf.py_func(roc_auc_score, (y_true, y_pred), tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'sequential_nn_model_{epoch:02d}.h5',\n",
    "    monitor='val_acc',\n",
    "    #monitor=auc,\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    #mode='min',\n",
    "    mode='max'\n",
    "    #save_weights_only = True\n",
    ")\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    #monitor=auc,\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    #mode='max',\n",
    "    epsilon=0.001\n",
    ")\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    #monitor=auc,\n",
    "    mode=\"min\",\n",
    "    #mode='max',\n",
    "    patience=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks_list = [checkpoint, reduceLROnPlat, early]\n",
    "#callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести mean_shift кластеризацию на множестве переменных (features)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts = sequential_nn_model.predict(test_df[test_df.columns.drop('ID_code')].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(submission_predicts[:5])\n",
    "#submission_predicts_values = submission_predicts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values >= 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245] = 0\n",
    "#submission_predicts_values[submission_predicts_values >= 0.245] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.to_csv('submission_mlp_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_threshold(classes_ratio, step_size, predicted_values):\n",
    "    threshold = 0\n",
    "    values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "    values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "    threshold_classes_ratio =  values_abowe_threshold / values_below_threshold\n",
    "    \n",
    "    while(threshold_classes_ratio < clasess_ratio):\n",
    "        threshold += step_size        \n",
    "        values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "        values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "        threshold_classes_ratio =  values_abowe_threshold / values_below_threshold\n",
    "    predicted_values[predicted_values < threshold] = 0\n",
    "    predicted_values[predicted_values >= threshold] = 1\n",
    "    return threshold, predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model = None\n",
    "#del sequential_nn_model\n",
    "if sequential_nn_model:\n",
    "    del sequential_nn_model\n",
    "sequential_nn_model = Sequential()\n",
    "#sequential_nn_model.add(Dense(batch_size, input_dim=200, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.2))\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sequential_nn_model.fit(train_values, train_target_values, batch_size=100, epochs=20, verbose=1, validation_split=0.2)\n",
    "print(\"Run time {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = sequential_nn_model.evaluate(holdout_test_values, holdout_test_target_values, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
