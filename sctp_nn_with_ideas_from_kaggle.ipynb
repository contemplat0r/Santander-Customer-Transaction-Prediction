{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras import callbacks\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "train_targets = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "for feature in features:\n",
    "    train_features['mean_'+feature] = (train_features[feature].mean()-train_features[feature])\n",
    "    train_features['z_'+feature] = (train_features[feature] - train_features[feature].mean()) / train_features[feature].std(ddof=0)\n",
    "    train_features['sq_'+feature] = (train_features[feature])**2\n",
    "    train_features['sqrt_'+feature] = (train_features['sq_'+feature])**(1/4)\n",
    "    train_features['log_'+feature] = np.log(train_features['sq_'+feature]+10)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_var_198</th>\n",
       "      <th>z_var_198</th>\n",
       "      <th>sq_var_198</th>\n",
       "      <th>sqrt_var_198</th>\n",
       "      <th>log_var_198</th>\n",
       "      <th>mean_var_199</th>\n",
       "      <th>z_var_199</th>\n",
       "      <th>sq_var_199</th>\n",
       "      <th>sqrt_var_199</th>\n",
       "      <th>log_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>3.09042</td>\n",
       "      <td>-1.026398</td>\n",
       "      <td>163.336068</td>\n",
       "      <td>3.574955</td>\n",
       "      <td>2.577616</td>\n",
       "      <td>-2.235137</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>1.191154</td>\n",
       "      <td>1.044701</td>\n",
       "      <td>1.207562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.48528</td>\n",
       "      <td>0.825417</td>\n",
       "      <td>336.942736</td>\n",
       "      <td>4.284390</td>\n",
       "      <td>2.924580</td>\n",
       "      <td>-5.278337</td>\n",
       "      <td>0.505685</td>\n",
       "      <td>3.809523</td>\n",
       "      <td>1.397068</td>\n",
       "      <td>1.312679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14852</td>\n",
       "      <td>-0.381449</td>\n",
       "      <td>216.743173</td>\n",
       "      <td>3.836952</td>\n",
       "      <td>2.711909</td>\n",
       "      <td>-3.723037</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>0.157212</td>\n",
       "      <td>0.629682</td>\n",
       "      <td>1.159092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.09898</td>\n",
       "      <td>0.697118</td>\n",
       "      <td>322.910118</td>\n",
       "      <td>4.239068</td>\n",
       "      <td>2.903936</td>\n",
       "      <td>5.673063</td>\n",
       "      <td>-0.543502</td>\n",
       "      <td>80.992800</td>\n",
       "      <td>2.999933</td>\n",
       "      <td>2.255390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.12668</td>\n",
       "      <td>0.706318</td>\n",
       "      <td>323.906407</td>\n",
       "      <td>4.242334</td>\n",
       "      <td>2.905430</td>\n",
       "      <td>5.483863</td>\n",
       "      <td>-0.525375</td>\n",
       "      <td>77.623148</td>\n",
       "      <td>2.968232</td>\n",
       "      <td>2.236523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9     ...       mean_var_198  z_var_198  sq_var_198  sqrt_var_198  \\\n",
       "0  5.7470     ...            3.09042  -1.026398  163.336068      3.574955   \n",
       "1  8.0851     ...           -2.48528   0.825417  336.942736      4.284390   \n",
       "2  5.9525     ...            1.14852  -0.381449  216.743173      3.836952   \n",
       "3  8.2450     ...           -2.09898   0.697118  322.910118      4.239068   \n",
       "4  7.6784     ...           -2.12668   0.706318  323.906407      4.242334   \n",
       "\n",
       "   log_var_198  mean_var_199  z_var_199  sq_var_199  sqrt_var_199  log_var_199  \n",
       "0     2.577616     -2.235137   0.214135    1.191154      1.044701     1.207562  \n",
       "1     2.924580     -5.278337   0.505685    3.809523      1.397068     1.312679  \n",
       "2     2.711909     -3.723037   0.356681    0.157212      0.629682     1.159092  \n",
       "3     2.903936      5.673063  -0.543502   80.992800      2.999933     2.255390  \n",
       "4     2.905430      5.483863  -0.525375   77.623148      2.968232     2.236523  \n",
       "\n",
       "[5 rows x 1200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train_features = sc.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_features.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printAUC(callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super(printAUC, self).__init__()\n",
    "        self.bestAUC = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred = self.model.predict(np.array(self.X_train))\n",
    "        auc = roc_auc_score(self.y_train, pred)\n",
    "        print(\"Train AUC: \" + str(auc))\n",
    "        #pred = self.model.predict(self.validation_data[0])\n",
    "        #auc = roc_auc_score(self.validation_data[1], pred)\n",
    "        #print (\"Validation AUC: \" + str(auc))\n",
    "        if (self.bestAUC < auc) :\n",
    "            self.bestAUC = auc\n",
    "            self.model.save(\"bestNet.h5\", overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def augment(x, y, t=2):\n",
    "    xs, xn = [], []\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t // 2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x, xs, xn])\n",
    "    y = np.concatenate([y, ys, yn])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "standart_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_train_values = min_max_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "scaled_train_values = standart_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "#scaled_train_values = robust_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 200)\n",
      "(160000,)\n",
      "(40000, 200)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_values.shape)\n",
    "print(train_target_values.shape)\n",
    "print(holdout_test_values.shape)\n",
    "print(holdout_test_target_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_code = test_df['ID_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n"
     ]
    }
   ],
   "source": [
    "print(ID_code[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.py_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "#def auc(y_pred, y_true):\n",
    "    #print(y_true[:5])\n",
    "    #print(y_pred[:5])  \n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    #return tf.py_func(roc_auc_score, (y_true, y_pred), tf.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести mean_shift кластеризацию на множестве переменных (features)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts = sequential_nn_model.predict(test_df[test_df.columns.drop('ID_code')].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(submission_predicts[:5])\n",
    "#submission_predicts_values = submission_predicts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values >= 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245] = 0\n",
    "#submission_predicts_values[submission_predicts_values >= 0.245] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.to_csv('submission_mlp_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_threshold(classes_ratio, step_size, predicted_values):\n",
    "    threshold = predicted_values.min()\n",
    "    values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "    values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "    #threshold_classes_ratio =  values_above_threshold / values_below_threshold\n",
    "    threshold_classes_ratio = 1\n",
    "    \n",
    "    while(threshold_classes_ratio > classes_ratio):\n",
    "        threshold += step_size        \n",
    "        values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "        values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "        threshold_classes_ratio =  values_above_threshold / values_below_threshold\n",
    "    predicted_values[predicted_values < threshold] = 0\n",
    "    predicted_values[predicted_values >= threshold] = 1\n",
    "    return threshold, predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsequential_nn_model = None\\n#del sequential_nn_model\\nif sequential_nn_model:\\n    del sequential_nn_model\\nsequential_nn_model = Sequential()\\nsequential_nn_model.add(Dense(batch_size, input_dim=200, kernel_initializer='normal', activation='relu'))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(batch_size, input_dim=100, kernel_initializer='normal', activation='sigmoid'))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='relu'))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='sigmoid'))\\n#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\\n#sequential_nn_model.add(Dropout(0.76))\\n#sequential_nn_model.add(Dropout(0.24))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='relu'))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='sigmoid'))\\nsequential_nn_model.add(Dropout(0.1))\\nsequential_nn_model.add(BatchNormalization())\\nsequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sequential_nn_model = None\n",
    "#del sequential_nn_model\n",
    "if sequential_nn_model:\n",
    "    del sequential_nn_model\n",
    "sequential_nn_model = Sequential()\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=200, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=100, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dropout(0.76))\n",
    "#sequential_nn_model.add(Dropout(0.24))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential_nn_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy', auc])\n",
    "#sequential_nn_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nsequential_nn_model.fit(train_values, train_target_values, batch_size=100, epochs=40, verbose=1, validation_split=0.2)\\nprint(\"Run time {} min\".format((time.time() - start_time) / 60))\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start_time = time.time()\n",
    "sequential_nn_model.fit(train_values, train_target_values, batch_size=100, epochs=40, verbose=1, validation_split=0.2)\n",
    "print(\"Run time {} min\".format((time.time() - start_time) / 60))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_and_metrics = sequential_nn_model.evaluate(holdout_test_values, holdout_test_target_values, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_and_metrics\n",
    "# [0.25161404045298696, 0.9094000032544136, 0.8320361980522218] [0.2493363002128899, 0.9096750013530255, 0.8369347876192563]\n",
    "# [0.24582509476691483, 0.9101250021159649, 0.8396344886385845] [0.24802235754206778, 0.9094000029563903, 0.8385308386618173]\n",
    "# [0.24494799628853797, 0.9102000007033348, 0.839084512352511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_json = sequential_nn_model.to_json()\\nwith open(\"sequential_nn_model_relu_droput024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.json\", \"w\") as json_file:\\n    json_file.write(model_json)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_json = sequential_nn_model.to_json()\n",
    "with open(\"sequential_nn_model_relu_droput024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential_nn_model.save(\"sequential_nn_model_relu_dropout024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential_nn_model.save_weights(\"sequential_nn_model_weights_relu_dropout024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predict_values = sequential_nn_model.predict(test_df[test_df.columns.drop('ID_code')].values)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_ratio = train_df[train_df['target'] == 1].shape[0] / train_df[train_df['target'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold, submission_predicts = detect_threshold(classes_ratio, 0.01, submission_predict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts[submission_predicts == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts[submission_predicts == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.to_csv('submission_mlp_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer=regularizers.l2(0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del sequential_nn_model\n",
    "sequential_nn_model = Sequential()\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 2, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 4, kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dropout(0.76))\n",
    "#sequential_nn_model.add(Dropout(0.24))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=input_dim / 30, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378088 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "378088/378088 [==============================] - 11s 29us/step - loss: 0.2242 - acc: 0.9154 - auc: 0.9222 - val_loss: 0.2058 - val_acc: 0.9268 - val_auc: 0.9086\n",
      "Epoch 2/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.2014 - acc: 0.9290 - auc: 0.9347 - val_loss: 0.2075 - val_acc: 0.9266 - val_auc: 0.9060\n",
      "Epoch 3/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1951 - acc: 0.9324 - auc: 0.9380 - val_loss: 0.2059 - val_acc: 0.9245 - val_auc: 0.9031\n",
      "Epoch 4/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1877 - acc: 0.9353 - auc: 0.9427 - val_loss: 0.2064 - val_acc: 0.9236 - val_auc: 0.9006\n",
      "Epoch 5/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1827 - acc: 0.9374 - auc: 0.9459 - val_loss: 0.2075 - val_acc: 0.9213 - val_auc: 0.9002\n",
      "Epoch 6/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1787 - acc: 0.9387 - auc: 0.9487 - val_loss: 0.2086 - val_acc: 0.9214 - val_auc: 0.8988\n",
      "Epoch 7/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1754 - acc: 0.9402 - auc: 0.9499 - val_loss: 0.2118 - val_acc: 0.9230 - val_auc: 0.8976\n",
      "Epoch 8/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1716 - acc: 0.9412 - auc: 0.9518 - val_loss: 0.2117 - val_acc: 0.9222 - val_auc: 0.8961\n",
      "Epoch 9/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1691 - acc: 0.9424 - auc: 0.9532 - val_loss: 0.2096 - val_acc: 0.9224 - val_auc: 0.8948\n",
      "Epoch 10/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1668 - acc: 0.9427 - auc: 0.9549 - val_loss: 0.2097 - val_acc: 0.9220 - val_auc: 0.8950\n",
      "Epoch 11/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1646 - acc: 0.9435 - auc: 0.9560 - val_loss: 0.2121 - val_acc: 0.9215 - val_auc: 0.8943\n",
      "Epoch 12/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1627 - acc: 0.9445 - auc: 0.9569 - val_loss: 0.2125 - val_acc: 0.9208 - val_auc: 0.8940\n",
      "Epoch 13/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1624 - acc: 0.9446 - auc: 0.9571 - val_loss: 0.2101 - val_acc: 0.9212 - val_auc: 0.8955\n",
      "Epoch 14/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1595 - acc: 0.9454 - auc: 0.9586 - val_loss: 0.2116 - val_acc: 0.9200 - val_auc: 0.8935\n",
      "Epoch 15/50\n",
      "378088/378088 [==============================] - 10s 25us/step - loss: 0.1574 - acc: 0.9466 - auc: 0.9597 - val_loss: 0.2125 - val_acc: 0.9206 - val_auc: 0.8925\n",
      "Epoch 16/50\n",
      "378088/378088 [==============================] - 10s 25us/step - loss: 0.1571 - acc: 0.9460 - auc: 0.9596 - val_loss: 0.2147 - val_acc: 0.9204 - val_auc: 0.8923\n",
      "Epoch 17/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1560 - acc: 0.9468 - auc: 0.9605 - val_loss: 0.2097 - val_acc: 0.9204 - val_auc: 0.8930\n",
      "Epoch 18/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1554 - acc: 0.9469 - auc: 0.9607 - val_loss: 0.2143 - val_acc: 0.9202 - val_auc: 0.8940\n",
      "Epoch 19/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1533 - acc: 0.9477 - auc: 0.9615 - val_loss: 0.2118 - val_acc: 0.9198 - val_auc: 0.8939\n",
      "Epoch 20/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1524 - acc: 0.9485 - auc: 0.9617 - val_loss: 0.2098 - val_acc: 0.9203 - val_auc: 0.8935\n",
      "Epoch 21/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1517 - acc: 0.9487 - auc: 0.9620 - val_loss: 0.2177 - val_acc: 0.9202 - val_auc: 0.8935\n",
      "Train on 378088 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1857 - acc: 0.9324 - auc: 0.9464 - val_loss: 0.1891 - val_acc: 0.9311 - val_auc: 0.9132\n",
      "Epoch 2/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1806 - acc: 0.9351 - auc: 0.9494 - val_loss: 0.1937 - val_acc: 0.9297 - val_auc: 0.9099\n",
      "Epoch 3/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1752 - acc: 0.9376 - auc: 0.9518 - val_loss: 0.1962 - val_acc: 0.9284 - val_auc: 0.9081\n",
      "Epoch 4/50\n",
      "378088/378088 [==============================] - 11s 29us/step - loss: 0.1730 - acc: 0.9389 - auc: 0.9527 - val_loss: 0.1998 - val_acc: 0.9270 - val_auc: 0.9046\n",
      "Epoch 5/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1693 - acc: 0.9400 - auc: 0.9544 - val_loss: 0.2088 - val_acc: 0.9225 - val_auc: 0.9035\n",
      "Epoch 6/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1669 - acc: 0.9410 - auc: 0.9558 - val_loss: 0.2002 - val_acc: 0.9268 - val_auc: 0.9039\n",
      "Epoch 7/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1645 - acc: 0.9423 - auc: 0.9564 - val_loss: 0.2013 - val_acc: 0.9267 - val_auc: 0.9033\n",
      "Epoch 8/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1620 - acc: 0.9432 - auc: 0.9577 - val_loss: 0.2035 - val_acc: 0.9256 - val_auc: 0.9020\n",
      "Epoch 9/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1604 - acc: 0.9440 - auc: 0.9588 - val_loss: 0.2030 - val_acc: 0.9265 - val_auc: 0.8997\n",
      "Epoch 10/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1598 - acc: 0.9442 - auc: 0.9589 - val_loss: 0.2046 - val_acc: 0.9249 - val_auc: 0.9014\n",
      "Epoch 11/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1575 - acc: 0.9448 - auc: 0.9602 - val_loss: 0.2061 - val_acc: 0.9230 - val_auc: 0.9003\n",
      "Epoch 12/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1561 - acc: 0.9456 - auc: 0.9605 - val_loss: 0.2057 - val_acc: 0.9231 - val_auc: 0.9004\n",
      "Epoch 13/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1551 - acc: 0.9465 - auc: 0.9611 - val_loss: 0.2040 - val_acc: 0.9253 - val_auc: 0.8995\n",
      "Epoch 14/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1547 - acc: 0.9465 - auc: 0.9612 - val_loss: 0.2114 - val_acc: 0.9204 - val_auc: 0.9006\n",
      "Epoch 15/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1523 - acc: 0.9472 - auc: 0.9622 - val_loss: 0.2115 - val_acc: 0.9196 - val_auc: 0.9008\n",
      "Epoch 16/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1519 - acc: 0.9475 - auc: 0.9623 - val_loss: 0.2081 - val_acc: 0.9206 - val_auc: 0.9009\n",
      "Epoch 17/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1496 - acc: 0.9479 - auc: 0.9632 - val_loss: 0.2046 - val_acc: 0.9261 - val_auc: 0.8983\n",
      "Epoch 18/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1489 - acc: 0.9489 - auc: 0.9634 - val_loss: 0.2036 - val_acc: 0.9256 - val_auc: 0.8991\n",
      "Epoch 19/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1483 - acc: 0.9491 - auc: 0.9637 - val_loss: 0.2036 - val_acc: 0.9259 - val_auc: 0.8986\n",
      "Epoch 20/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1487 - acc: 0.9487 - auc: 0.9637 - val_loss: 0.2041 - val_acc: 0.9254 - val_auc: 0.8995\n",
      "Epoch 21/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1474 - acc: 0.9496 - auc: 0.9640 - val_loss: 0.2062 - val_acc: 0.9246 - val_auc: 0.8985\n",
      "Train on 378088 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1816 - acc: 0.9345 - auc: 0.9488 - val_loss: 0.1949 - val_acc: 0.9310 - val_auc: 0.9073\n",
      "Epoch 2/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1743 - acc: 0.9378 - auc: 0.9523 - val_loss: 0.2013 - val_acc: 0.9267 - val_auc: 0.9052\n",
      "Epoch 3/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1710 - acc: 0.9397 - auc: 0.9535 - val_loss: 0.2000 - val_acc: 0.9274 - val_auc: 0.9013\n",
      "Epoch 4/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1679 - acc: 0.9409 - auc: 0.9552 - val_loss: 0.2063 - val_acc: 0.9243 - val_auc: 0.8995\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1651 - acc: 0.9421 - auc: 0.9564 - val_loss: 0.2038 - val_acc: 0.9263 - val_auc: 0.8973\n",
      "Epoch 6/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1630 - acc: 0.9427 - auc: 0.9575 - val_loss: 0.2045 - val_acc: 0.9255 - val_auc: 0.8988\n",
      "Epoch 7/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1615 - acc: 0.9435 - auc: 0.9578 - val_loss: 0.2100 - val_acc: 0.9224 - val_auc: 0.8981\n",
      "Epoch 8/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1583 - acc: 0.9451 - auc: 0.9593 - val_loss: 0.2056 - val_acc: 0.9244 - val_auc: 0.8954\n",
      "Epoch 9/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1566 - acc: 0.9450 - auc: 0.9600 - val_loss: 0.2111 - val_acc: 0.9188 - val_auc: 0.8965\n",
      "Epoch 10/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1557 - acc: 0.9459 - auc: 0.9603 - val_loss: 0.2093 - val_acc: 0.9234 - val_auc: 0.8958\n",
      "Epoch 11/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1542 - acc: 0.9463 - auc: 0.9612 - val_loss: 0.2089 - val_acc: 0.9240 - val_auc: 0.8948\n",
      "Epoch 12/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1523 - acc: 0.9473 - auc: 0.9617 - val_loss: 0.2083 - val_acc: 0.9236 - val_auc: 0.8955\n",
      "Epoch 13/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1517 - acc: 0.9477 - auc: 0.9622 - val_loss: 0.2100 - val_acc: 0.9211 - val_auc: 0.8949\n",
      "Epoch 14/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1511 - acc: 0.9481 - auc: 0.9623 - val_loss: 0.2079 - val_acc: 0.9234 - val_auc: 0.8945\n",
      "Epoch 15/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1492 - acc: 0.9487 - auc: 0.9629 - val_loss: 0.2080 - val_acc: 0.9236 - val_auc: 0.8945\n",
      "Epoch 16/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1486 - acc: 0.9489 - auc: 0.9633 - val_loss: 0.2079 - val_acc: 0.9227 - val_auc: 0.8946\n",
      "Epoch 17/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1474 - acc: 0.9492 - auc: 0.9643 - val_loss: 0.2094 - val_acc: 0.9220 - val_auc: 0.8938\n",
      "Epoch 18/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1466 - acc: 0.9496 - auc: 0.9642 - val_loss: 0.2093 - val_acc: 0.9218 - val_auc: 0.8936\n",
      "Epoch 19/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1458 - acc: 0.9500 - auc: 0.9647 - val_loss: 0.2076 - val_acc: 0.9226 - val_auc: 0.8941\n",
      "Epoch 20/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1454 - acc: 0.9499 - auc: 0.9650 - val_loss: 0.2093 - val_acc: 0.9220 - val_auc: 0.8942\n",
      "Epoch 21/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1454 - acc: 0.9500 - auc: 0.9647 - val_loss: 0.2144 - val_acc: 0.9218 - val_auc: 0.8935\n",
      "Train on 378088 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1783 - acc: 0.9359 - auc: 0.9508 - val_loss: 0.1960 - val_acc: 0.9291 - val_auc: 0.9081\n",
      "Epoch 2/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1740 - acc: 0.9379 - auc: 0.9524 - val_loss: 0.1988 - val_acc: 0.9271 - val_auc: 0.9070\n",
      "Epoch 3/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1696 - acc: 0.9401 - auc: 0.9541 - val_loss: 0.2000 - val_acc: 0.9270 - val_auc: 0.9028\n",
      "Epoch 4/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1671 - acc: 0.9415 - auc: 0.9550 - val_loss: 0.1989 - val_acc: 0.9269 - val_auc: 0.9017\n",
      "Epoch 5/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1649 - acc: 0.9419 - auc: 0.9563 - val_loss: 0.2029 - val_acc: 0.9265 - val_auc: 0.8997\n",
      "Epoch 6/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1629 - acc: 0.9430 - auc: 0.9573 - val_loss: 0.2041 - val_acc: 0.9240 - val_auc: 0.8977\n",
      "Epoch 7/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1604 - acc: 0.9439 - auc: 0.9585 - val_loss: 0.2051 - val_acc: 0.9245 - val_auc: 0.8982\n",
      "Epoch 8/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1584 - acc: 0.9447 - auc: 0.9596 - val_loss: 0.2070 - val_acc: 0.9227 - val_auc: 0.8961\n",
      "Epoch 9/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1580 - acc: 0.9450 - auc: 0.9595 - val_loss: 0.2067 - val_acc: 0.9239 - val_auc: 0.8954\n",
      "Epoch 10/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1557 - acc: 0.9460 - auc: 0.9601 - val_loss: 0.2118 - val_acc: 0.9177 - val_auc: 0.8983\n",
      "Epoch 11/50\n",
      "378088/378088 [==============================] - 10s 25us/step - loss: 0.1545 - acc: 0.9467 - auc: 0.9607 - val_loss: 0.2057 - val_acc: 0.9236 - val_auc: 0.8958\n",
      "Epoch 12/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1526 - acc: 0.9474 - auc: 0.9616 - val_loss: 0.2060 - val_acc: 0.9232 - val_auc: 0.8956\n",
      "Epoch 13/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1513 - acc: 0.9477 - auc: 0.9619 - val_loss: 0.2065 - val_acc: 0.9234 - val_auc: 0.8950\n",
      "Epoch 14/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1513 - acc: 0.9479 - auc: 0.9622 - val_loss: 0.2061 - val_acc: 0.9232 - val_auc: 0.8965\n",
      "Epoch 15/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1486 - acc: 0.9487 - auc: 0.9632 - val_loss: 0.2109 - val_acc: 0.9202 - val_auc: 0.8960\n",
      "Epoch 16/50\n",
      "378088/378088 [==============================] - 10s 25us/step - loss: 0.1485 - acc: 0.9489 - auc: 0.9634 - val_loss: 0.2092 - val_acc: 0.9218 - val_auc: 0.8951\n",
      "Epoch 17/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1472 - acc: 0.9488 - auc: 0.9635 - val_loss: 0.2122 - val_acc: 0.9198 - val_auc: 0.8958\n",
      "Epoch 18/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1459 - acc: 0.9501 - auc: 0.9640 - val_loss: 0.2078 - val_acc: 0.9231 - val_auc: 0.8940\n",
      "Epoch 19/50\n",
      "378088/378088 [==============================] - 10s 28us/step - loss: 0.1466 - acc: 0.9498 - auc: 0.9643 - val_loss: 0.2092 - val_acc: 0.9218 - val_auc: 0.8956\n",
      "Epoch 20/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1455 - acc: 0.9502 - auc: 0.9647 - val_loss: 0.2075 - val_acc: 0.9226 - val_auc: 0.8954\n",
      "Epoch 21/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1447 - acc: 0.9504 - auc: 0.9652 - val_loss: 0.2085 - val_acc: 0.9222 - val_auc: 0.8939\n",
      "Train on 378088 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1769 - acc: 0.9369 - auc: 0.9505 - val_loss: 0.1931 - val_acc: 0.9301 - val_auc: 0.9110\n",
      "Epoch 2/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1723 - acc: 0.9389 - auc: 0.9528 - val_loss: 0.1941 - val_acc: 0.9272 - val_auc: 0.9083\n",
      "Epoch 3/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1681 - acc: 0.9407 - auc: 0.9550 - val_loss: 0.1956 - val_acc: 0.9269 - val_auc: 0.9104\n",
      "Epoch 4/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1661 - acc: 0.9413 - auc: 0.9555 - val_loss: 0.1983 - val_acc: 0.9280 - val_auc: 0.9062\n",
      "Epoch 5/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1646 - acc: 0.9427 - auc: 0.9562 - val_loss: 0.2000 - val_acc: 0.9262 - val_auc: 0.9038\n",
      "Epoch 6/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1610 - acc: 0.9438 - auc: 0.9579 - val_loss: 0.2026 - val_acc: 0.9234 - val_auc: 0.9024\n",
      "Epoch 7/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1598 - acc: 0.9444 - auc: 0.9585 - val_loss: 0.2034 - val_acc: 0.9239 - val_auc: 0.9021\n",
      "Epoch 8/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1584 - acc: 0.9449 - auc: 0.9587 - val_loss: 0.2038 - val_acc: 0.9242 - val_auc: 0.9011\n",
      "Epoch 9/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1559 - acc: 0.9460 - auc: 0.9599 - val_loss: 0.2020 - val_acc: 0.9236 - val_auc: 0.9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1548 - acc: 0.9459 - auc: 0.9605 - val_loss: 0.2010 - val_acc: 0.9250 - val_auc: 0.9005\n",
      "Epoch 11/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1540 - acc: 0.9467 - auc: 0.9605 - val_loss: 0.2057 - val_acc: 0.9214 - val_auc: 0.9022\n",
      "Epoch 12/50\n",
      "378088/378088 [==============================] - 11s 28us/step - loss: 0.1519 - acc: 0.9474 - auc: 0.9617 - val_loss: 0.2034 - val_acc: 0.9241 - val_auc: 0.9006\n",
      "Epoch 13/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1513 - acc: 0.9478 - auc: 0.9621 - val_loss: 0.2084 - val_acc: 0.9195 - val_auc: 0.9016\n",
      "Epoch 14/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1506 - acc: 0.9484 - auc: 0.9618 - val_loss: 0.2081 - val_acc: 0.9210 - val_auc: 0.9014\n",
      "Epoch 15/50\n",
      "378088/378088 [==============================] - 11s 29us/step - loss: 0.1497 - acc: 0.9490 - auc: 0.9622 - val_loss: 0.2043 - val_acc: 0.9237 - val_auc: 0.8990\n",
      "Epoch 16/50\n",
      "378088/378088 [==============================] - 10s 27us/step - loss: 0.1482 - acc: 0.9494 - auc: 0.9633 - val_loss: 0.2026 - val_acc: 0.9243 - val_auc: 0.9002\n",
      "Epoch 17/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1485 - acc: 0.9492 - auc: 0.9628 - val_loss: 0.2016 - val_acc: 0.9243 - val_auc: 0.9008\n",
      "Epoch 18/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1479 - acc: 0.9497 - auc: 0.9633 - val_loss: 0.2051 - val_acc: 0.9227 - val_auc: 0.9001\n",
      "Epoch 19/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1462 - acc: 0.9501 - auc: 0.9643 - val_loss: 0.2021 - val_acc: 0.9247 - val_auc: 0.8995\n",
      "Epoch 20/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1459 - acc: 0.9501 - auc: 0.9642 - val_loss: 0.2029 - val_acc: 0.9240 - val_auc: 0.8992\n",
      "Epoch 21/50\n",
      "378088/378088 [==============================] - 10s 26us/step - loss: 0.1448 - acc: 0.9504 - auc: 0.9646 - val_loss: 0.2035 - val_acc: 0.9233 - val_auc: 0.8994\n",
      "Run time 152.288589711984 min\n"
     ]
    }
   ],
   "source": [
    "loss_history = LossHistory()\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [EarlyStopping(monitor='val_auc', patience=20, mode='max'), loss_history, annealer]\n",
    "sss = StratifiedShuffleSplit(n_splits=5)\n",
    "start_time = time.time()\n",
    "for train_index, test_index in sss.split(train_features, train_targets):\n",
    "    X_train, X_val = train_features[train_index], train_features[test_index]\n",
    "    Y_train, Y_val = train_targets[train_index], train_targets[test_index]\n",
    "    X_tr, Y_tr = augment(X_train, Y_train)\n",
    "    #print(\"{} iteration\".format(i+1))\n",
    "    history= model.fit(X_tr, Y_tr, batch_size=512, epochs=50, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "    #history= sequential_nn_model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "    del X_train, X_val, Y_train, Y_val\n",
    "    gc.collect()\n",
    "print(\"Run time {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1200)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, train_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "test_features = test.drop(['ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    test_features['mean_' + feature] = (test_features[feature].mean()-test_features[feature])\n",
    "    test_features['z_' + feature] = (test_features[feature] - test_features[feature].mean())/test_features[feature].std(ddof=0)\n",
    "    test_features['sq_' + feature] = (test_features[feature]) ** 2\n",
    "    test_features['sqrt_' + feature] = (test_features['sq_' + feature])**(1 / 4)\n",
    "    test_features['log_' + feature] = np.log(test_features['sq_' + feature]+10) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = sc.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_code_test = test['ID_code']\n",
    "# Make predicitions\n",
    "pred = model.predict(test_features)\n",
    "pred_ = pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08493365"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df['target'].mean())\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ratio = train_df[train_df['target'] == 1].shape[0] / train_df[train_df['target'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, submission_predicts = detect_threshold(classes_ratio, 0.01, pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"ID_code\" : id_code_test, \"target\" : submission_predicts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_mlp_6.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"kagle_keras_model_2019-04-01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180191, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[submission_df['target'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19809, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[submission_df['target'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.099045"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_predicts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df = pd.DataFrame(columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.09910e+00, -3.93220e+00,  9.69010e+00,  9.74460e+00,\n",
       "         1.10506e+01, -1.44260e+01,  6.77440e+00,  1.73437e+01,\n",
       "         2.01950e+00,  6.41530e+00,  8.98650e+00,  2.05350e+00,\n",
       "         1.41613e+01,  2.47140e+00,  9.34870e+00,  1.45943e+01,\n",
       "         6.88320e+00, -1.06779e+01,  1.43240e+01,  8.33870e+00,\n",
       "         1.52482e+01,  2.06087e+01,  2.65340e+00,  2.44530e+00,\n",
       "         1.00399e+01,  1.38218e+01, -6.88520e+00, -1.16850e+00,\n",
       "         5.05910e+00,  4.87390e+00, -1.22046e+01,  1.28039e+01,\n",
       "        -3.47360e+00,  2.04335e+01,  1.13065e+01,  7.27220e+00,\n",
       "         5.29920e+00,  9.80610e+00,  6.74520e+00,  6.16680e+00,\n",
       "        -3.07680e+00,  1.13123e+01,  1.10928e+01,  1.17899e+01,\n",
       "         5.33800e+00, -6.41370e+00,  1.18883e+01, -1.27800e-01,\n",
       "        -2.71940e+00,  1.69911e+01,  1.14219e+01,  1.79810e+01,\n",
       "         4.53060e+00,  5.22180e+00,  1.59150e+00,  1.06834e+01,\n",
       "         1.44413e+01,  6.61530e+00, -4.95690e+00,  8.49670e+00,\n",
       "         9.57500e+00, -2.40555e+01, -1.57380e+00,  9.55400e-01,\n",
       "         4.60830e+00,  7.88240e+00,  5.68430e+00,  1.09504e+01,\n",
       "         5.00600e+00, -2.43040e+00,  2.84551e+01,  9.83700e-01,\n",
       "         6.24330e+00,  2.22504e+01,  2.08433e+01,  1.32217e+01,\n",
       "         5.88470e+00,  1.96742e+01,  7.13590e+00,  1.62765e+01,\n",
       "         1.33966e+01,  1.70369e+01,  6.89550e+00, -5.42180e+00,\n",
       "        -1.35363e+01,  2.14494e+01,  1.28863e+01,  9.87750e+00,\n",
       "         1.06664e+01,  4.18050e+00, -3.22860e+00,  7.08630e+00,\n",
       "         1.06674e+01,  9.68190e+00,  1.34133e+01, -3.36000e-01,\n",
       "         1.22675e+01,  2.71430e+01,  2.19240e+00, -2.57130e+00,\n",
       "        -1.05870e+00,  1.23877e+01,  2.82417e+01,  1.91430e+00,\n",
       "         1.13902e+01,  3.12290e+00,  6.81510e+00,  1.65731e+01,\n",
       "         1.43040e+01,  2.34182e+01,  1.03590e+00,  6.34310e+00,\n",
       "         2.83080e+00,  9.07310e+00,  3.88100e+00,  2.17890e+00,\n",
       "         4.67080e+00,  2.22020e+00, -1.14280e+00,  8.56270e+00,\n",
       "         3.04814e+01,  1.25041e+01,  6.23720e+00,  9.35890e+00,\n",
       "         5.37900e-01,  1.29176e+01,  1.46984e+01,  1.48220e+00,\n",
       "        -2.29130e+00,  1.84590e+01,  1.11990e+01,  6.38000e-01,\n",
       "         9.30150e+00,  6.95540e+00, -7.96400e+00,  2.77340e+00,\n",
       "         1.73591e+01,  1.19889e+01,  4.05050e+00, -6.03600e+00,\n",
       "         4.44700e+00,  1.77400e+00,  1.12602e+01,  1.31566e+01,\n",
       "         9.98940e+00, -4.51500e-01,  1.26659e+01, -3.46910e+00,\n",
       "         4.11800e+00,  1.16319e+01,  1.26496e+01,  1.15594e+01,\n",
       "         9.71130e+00,  1.27353e+01, -1.66510e+00,  1.18393e+01,\n",
       "         1.42559e+01, -9.18030e+00,  2.87144e+01,  1.88787e+01,\n",
       "         9.37820e+00,  5.26150e+00,  7.21210e+00,  1.23381e+01,\n",
       "        -5.57980e+00,  2.47740e+01,  2.73140e+00, -4.28690e+00,\n",
       "         2.87410e+00,  5.92080e+00, -1.74740e+00, -7.02350e+00,\n",
       "         1.10432e+01,  6.82550e+00,  1.67212e+01,  7.27380e+00,\n",
       "        -6.36870e+00,  1.19946e+01, -1.63738e+01,  3.92620e+00,\n",
       "        -2.88760e+00,  1.07941e+01, -6.05860e+00,  1.05717e+01,\n",
       "         1.71287e+01, -2.52550e+00,  9.13310e+00, -1.75818e+01,\n",
       "         1.91240e+01,  3.31300e-01,  8.75540e+00,  6.46010e+00,\n",
       "         3.30270e+00, -2.38100e-01,  2.12423e+01,  1.17030e+00,\n",
       "        -9.08600e-01,  1.00840e+01,  1.85854e+01, -6.15580e+00],\n",
       "       [ 6.87620e+00, -3.00100e-01,  9.22230e+00,  9.37380e+00,\n",
       "         1.24580e+01, -7.77640e+00,  4.01240e+00,  2.03773e+01,\n",
       "        -6.46000e-02,  6.01330e+00, -7.87850e+00, -3.79740e+00,\n",
       "         1.39970e+01,  1.55949e+01,  5.16530e+00,  1.49969e+01,\n",
       "         6.16210e+00, -1.72548e+01,  2.26581e+01,  6.30860e+00,\n",
       "         1.30016e+01,  1.73448e+01,  4.74730e+00,  3.04860e+00,\n",
       "         1.39628e+01,  1.30930e+01, -6.49640e+00, -6.43200e-01,\n",
       "         5.59970e+00,  2.32990e+00, -8.31600e+00,  9.95620e+00,\n",
       "        -2.00090e+00,  2.02305e+01,  1.05409e+01,  4.24440e+00,\n",
       "         4.64850e+00,  8.54490e+00,  7.28730e+00,  2.93030e+00,\n",
       "        -2.37756e+01,  5.93170e+00,  1.26409e+01,  1.16271e+01,\n",
       "         8.53490e+00,  9.65320e+00,  9.45920e+00, -1.48183e+01,\n",
       "         3.12353e+01,  3.11314e+01,  1.22663e+01,  2.35157e+01,\n",
       "        -5.94530e+00,  6.15190e+00, -3.82880e+00,  9.98220e+00,\n",
       "         1.75919e+01,  5.31240e+00,  3.25940e+00,  8.32220e+00,\n",
       "         1.14927e+01, -2.71083e+01,  5.45930e+00,  4.22900e-01,\n",
       "         8.87640e+00, -1.67140e+00,  5.13750e+00,  1.45270e+01,\n",
       "         5.01930e+00, -5.37430e+00,  1.53338e+01,  2.91600e-01,\n",
       "        -2.38800e+00,  1.34436e+01,  3.48233e+01,  1.62209e+01,\n",
       "         4.13770e+00,  1.84468e+01,  6.28700e+00,  1.60144e+01,\n",
       "         1.30103e+01,  1.64309e+01, -6.73080e+00,  6.99130e+00,\n",
       "        -8.13040e+00,  2.24643e+01,  4.53080e+00,  8.04220e+00,\n",
       "         1.11144e+01,  5.41260e+00, -3.00517e+01,  7.08370e+00,\n",
       "         1.63377e+01,  1.04577e+01,  8.92430e+00, -8.23200e-01,\n",
       "         5.04840e+00,  3.59284e+01,  2.21960e+00, -2.52540e+00,\n",
       "         4.17190e+00,  1.64378e+01,  1.41573e+01,  1.42270e+00,\n",
       "         1.27578e+01,  5.90670e+00,  7.58090e+00,  1.38503e+01,\n",
       "         1.40888e+01,  1.61389e+01,  8.40210e+00,  6.86220e+00,\n",
       "         3.25010e+00,  1.13514e+01,  4.98150e+00,  5.65680e+00,\n",
       "         5.45200e-01, -1.80250e+00, -3.26670e+00,  1.09040e+00,\n",
       "         2.65754e+01,  9.17750e+00,  5.32550e+00,  9.13380e+00,\n",
       "         4.66020e+00,  1.19313e+01,  1.39451e+01,  4.41630e+00,\n",
       "        -5.60570e+00,  2.13270e+01,  1.15241e+01,  9.60600e-01,\n",
       "         8.42130e+00,  6.10660e+00, -1.24071e+01, -5.77580e+00,\n",
       "         4.18417e+01,  2.74730e+00,  6.51930e+00,  1.74140e+01,\n",
       "         3.85030e+00,  4.90720e+00,  7.08050e+00,  1.59130e+01,\n",
       "         9.60130e+00,  5.96290e+00,  1.48042e+01, -2.52200e+00,\n",
       "         4.29490e+00,  1.47199e+01,  1.43746e+01,  1.48593e+01,\n",
       "         4.95100e+00,  1.97726e+01,  5.59480e+00, -7.90410e+00,\n",
       "         1.33250e+01, -3.07900e+00,  4.83050e+00,  1.19658e+01,\n",
       "         1.27015e+01,  5.89110e+00,  6.22590e+00,  1.56531e+01,\n",
       "        -8.72630e+00,  2.13939e+01,  3.42490e+00,  3.27100e-01,\n",
       "         1.26898e+01,  5.58130e+00,  6.61270e+00,  1.72980e+00,\n",
       "         1.86579e+01, -2.59700e-01,  1.61391e+01,  1.40998e+01,\n",
       "        -1.56869e+01,  1.03868e+01, -1.71448e+01,  1.67080e+00,\n",
       "        -1.39270e+00,  9.98760e+00, -7.07060e+00,  7.45400e+00,\n",
       "         1.56118e+01, -3.11930e+00,  9.62350e+00,  5.17180e+00,\n",
       "         1.86158e+01, -1.21800e+00, -4.81000e-01,  5.29150e+00,\n",
       "         3.38860e+00,  5.75320e+00,  1.90456e+01, -1.50030e+00,\n",
       "         5.10210e+00,  7.76570e+00,  1.81101e+01, -4.73240e+00],\n",
       "       [ 1.21769e+01, -4.40940e+00,  1.33772e+01,  6.58170e+00,\n",
       "         8.66500e+00, -1.86870e+00,  6.28430e+00,  2.05886e+01,\n",
       "         5.44290e+00,  8.98640e+00, -1.65110e+00, -2.66060e+00,\n",
       "         1.41309e+01,  1.20418e+01,  4.96720e+00,  1.50465e+01,\n",
       "         1.59396e+01,  4.83800e+00,  2.17988e+01,  2.04721e+01,\n",
       "         1.53212e+01,  2.05066e+01,  5.37020e+00,  2.55120e+00,\n",
       "         1.77674e+01,  1.37587e+01,  1.61810e+00, -2.66300e+00,\n",
       "         6.07540e+00,  4.42960e+00, -1.61397e+01,  1.41470e+01,\n",
       "        -4.12560e+00,  1.26199e+01,  1.14066e+01,  3.66400e+00,\n",
       "         1.81530e+00,  4.50860e+00,  9.91570e+00,  6.08830e+00,\n",
       "        -2.06696e+01,  5.31600e-01,  1.07571e+01,  1.17474e+01,\n",
       "         1.35983e+01,  3.21810e+00,  8.28250e+00,  3.01180e+00,\n",
       "         1.92602e+01,  1.41630e+01,  1.22137e+01,  6.91100e-01,\n",
       "        -2.99540e+00,  7.02140e+00, -4.32780e+00,  1.91415e+01,\n",
       "         1.13129e+01,  5.72230e+00, -6.57600e-01,  9.29380e+00,\n",
       "         1.07819e+01,  8.16820e+00,  1.30620e+00,  6.06040e+00,\n",
       "         8.19680e+00,  2.66890e+00,  6.02250e+00,  1.77943e+01,\n",
       "         5.02420e+00, -6.38970e+00,  4.64712e+01,  1.12330e+00,\n",
       "         4.04290e+00,  3.58068e+01,  1.81538e+01,  1.34100e+01,\n",
       "         1.16496e+01,  1.61051e+01,  4.09550e+00,  1.37319e+01,\n",
       "         8.41220e+00,  1.32711e+01, -1.36170e+01, -7.88150e+00,\n",
       "         9.40910e+00,  1.77650e+01, -2.44020e+00,  7.79600e+00,\n",
       "         7.62970e+00,  4.76420e+00, -5.99770e+00,  7.38770e+00,\n",
       "         1.20014e+01,  1.06649e+01,  1.01014e+01, -1.00530e+00,\n",
       "         8.24090e+00,  9.37270e+00,  1.52770e+00,  2.23430e+00,\n",
       "        -1.44699e+01,  1.01630e+01,  3.48431e+01,  1.62400e+00,\n",
       "         1.24866e+01,  4.25340e+00,  1.14368e+01,  2.00194e+01,\n",
       "         1.43195e+01,  1.88376e+01,  7.22090e+00,  4.30500e+00,\n",
       "         5.40670e+00,  1.05167e+01,  2.53520e+00,  4.94970e+00,\n",
       "         3.11960e+00,  3.48943e+01, -2.02840e+00,  4.32070e+00,\n",
       "         2.99846e+01,  1.17833e+01,  9.26600e-01,  1.10700e-01,\n",
       "         2.21650e+00,  1.26616e+01,  1.15351e+01, -5.43600e-01,\n",
       "         2.08970e+00,  1.69925e+01,  1.11598e+01, -3.62000e-02,\n",
       "         8.80160e+00,  7.41590e+00, -3.50170e+00,  3.42690e+00,\n",
       "         8.67970e+00,  1.82564e+01,  1.10916e+01,  8.24210e+00,\n",
       "         5.58200e-01, -1.42842e+01,  1.68341e+01,  1.32640e+01,\n",
       "         9.29200e+00,  1.30846e+01,  6.98510e+00,  2.79000e-02,\n",
       "         4.00160e+00,  8.34670e+00,  1.83082e+01,  8.68210e+00,\n",
       "         6.85010e+00,  1.76719e+01, -5.75020e+00, -2.72310e+00,\n",
       "         1.40796e+01, -2.08490e+00,  7.13180e+00,  1.82330e+00,\n",
       "         3.53548e+01,  5.80560e+00,  4.71250e+00,  9.95240e+00,\n",
       "        -1.76330e+00,  1.64843e+01,  2.30680e+00,  1.38329e+01,\n",
       "         1.62290e+00,  5.85160e+00,  4.62980e+00,  8.46230e+00,\n",
       "         1.50145e+01,  5.60240e+00,  3.13335e+01,  1.13896e+01,\n",
       "        -1.11863e+01,  1.22167e+01, -1.70560e+00,  2.77250e+00,\n",
       "         1.11000e+00,  7.94890e+00,  1.92210e+00,  1.02339e+01,\n",
       "         4.48040e+00, -5.42500e+00,  1.00438e+01, -1.79018e+01,\n",
       "         6.82230e+00,  9.18900e-01,  4.42740e+00,  9.84700e+00,\n",
       "         1.84100e-01,  7.23590e+00,  1.32345e+01,  3.13830e+00,\n",
       "         5.02370e+00,  9.59570e+00,  2.17772e+01, -1.10987e+01],\n",
       "       [ 1.15058e+01,  4.74000e-01,  8.35000e+00,  5.64070e+00,\n",
       "         1.02666e+01,  1.43550e+00,  5.20660e+00,  1.57359e+01,\n",
       "         3.86950e+00,  7.33430e+00, -6.22080e+00,  4.31890e+00,\n",
       "         1.42848e+01,  1.31875e+01,  7.04860e+00,  1.44296e+01,\n",
       "         1.38090e+01, -8.87170e+00,  9.19150e+00,  4.51500e+00,\n",
       "         7.19590e+00,  1.50825e+01,  6.40800e+00,  3.03410e+00,\n",
       "         1.42573e+01,  1.40106e+01, -3.78720e+00, -1.07230e+00,\n",
       "         6.03280e+00,  3.45010e+00, -4.08090e+00,  9.27690e+00,\n",
       "        -3.18660e+00,  1.41473e+01,  1.12089e+01,  2.75750e+00,\n",
       "         5.44200e+00,  6.43860e+00,  1.38515e+01,  7.20480e+00,\n",
       "        -1.11830e+01,  1.31038e+01,  1.11026e+01,  1.16431e+01,\n",
       "         1.31261e+01, -4.12156e+01,  1.06799e+01, -1.37842e+01,\n",
       "         2.01317e+01,  2.58013e+01,  1.32731e+01,  2.49416e+01,\n",
       "        -8.09540e+00,  6.37640e+00,  1.39029e+01,  1.86572e+01,\n",
       "         1.21285e+01,  6.71620e+00, -1.38680e+00,  8.98590e+00,\n",
       "         1.10041e+01, -1.07496e+01,  1.94900e+00,  1.73200e-01,\n",
       "         5.75790e+00, -7.79400e-01,  7.60810e+00,  6.34000e-01,\n",
       "         5.02700e+00, -2.02580e+00,  4.42634e+01,  6.87900e-01,\n",
       "        -1.48210e+00,  2.52357e+01,  3.75000e-01,  1.80451e+01,\n",
       "        -9.29520e+00,  2.20536e+01,  6.20410e+00,  1.54426e+01,\n",
       "         4.49480e+00,  1.84138e+01, -7.59320e+00,  1.09250e+00,\n",
       "        -1.23136e+01,  2.08797e+01,  2.29660e+00,  4.24700e+00,\n",
       "         1.25936e+01,  1.75900e+00, -2.07206e+01,  6.83910e+00,\n",
       "         1.32856e+01,  1.09240e+01,  9.38750e+00, -2.22800e-01,\n",
       "         1.49799e+01,  3.40381e+01,  1.75950e+00, -2.63440e+00,\n",
       "        -1.86722e+01,  1.11389e+01,  3.37914e+01,  1.62270e+00,\n",
       "         1.32729e+01,  3.83910e+00,  7.48620e+00,  2.02909e+01,\n",
       "         1.40899e+01,  1.66825e+01,  2.08660e+00,  5.00740e+00,\n",
       "         4.32540e+00,  7.08090e+00,  2.77720e+00,  4.73430e+00,\n",
       "         8.64300e-01,  2.59862e+01, -6.54520e+00,  5.47420e+00,\n",
       "         2.78077e+01,  1.43908e+01,  6.82290e+00, -2.00000e-03,\n",
       "         6.80540e+00,  1.22622e+01,  1.20551e+01,  2.81240e+00,\n",
       "        -5.32650e+00,  1.95069e+01,  1.26780e+01,  5.67000e-01,\n",
       "         6.87700e+00,  6.87700e+00,  1.83400e+00, -1.48346e+01,\n",
       "         1.61089e+01,  1.50380e+01, -3.98160e+00,  1.57534e+01,\n",
       "         3.60550e+00, -2.36860e+00,  1.76040e+00,  1.27339e+01,\n",
       "         8.10400e+00,  6.40790e+00,  1.26827e+01,  7.95800e-01,\n",
       "         3.98980e+00,  9.55850e+00,  1.19149e+01,  1.68499e+01,\n",
       "         3.38240e+00,  1.86657e+01,  1.03592e+01, -1.78490e+00,\n",
       "         1.28641e+01, -4.78610e+00,  3.08349e+01,  1.19587e+01,\n",
       "         2.85252e+01,  5.26460e+00,  2.38090e+00,  9.55860e+00,\n",
       "        -4.75870e+00,  2.13016e+01,  2.85840e+00,  1.84270e+00,\n",
       "         6.43570e+00,  5.33400e+00,  7.05140e+00, -2.37470e+00,\n",
       "         1.31209e+01, -5.54520e+00,  1.71329e+01,  1.22328e+01,\n",
       "        -3.32270e+00,  1.65465e+01,  1.65392e+01,  5.04300e-01,\n",
       "         4.30730e+00,  7.60730e+00,  8.67560e+00,  8.83360e+00,\n",
       "         1.04537e+01, -3.26640e+00,  1.02468e+01, -1.41073e+01,\n",
       "         1.10573e+01,  9.68800e-01,  1.07660e+00,  3.80110e+00,\n",
       "         2.60810e+00,  1.89280e+00,  1.49046e+01, -1.19270e+00,\n",
       "         5.00260e+00,  8.73340e+00,  1.34507e+01, -1.82404e+01],\n",
       "       [ 1.06614e+01, -8.28690e+00,  1.44109e+01,  1.10407e+01,\n",
       "         1.33478e+01, -1.70677e+01,  4.57920e+00,  1.45798e+01,\n",
       "         7.17700e-01,  9.24230e+00,  2.11330e+00, -1.21774e+01,\n",
       "         1.36651e+01,  5.50540e+00,  4.86150e+00,  1.43701e+01,\n",
       "         8.21990e+00,  3.64600e-01,  6.12910e+00,  1.94088e+01,\n",
       "         2.25589e+01,  3.84630e+00,  4.53180e+00,  3.23430e+00,\n",
       "         1.24395e+01,  1.39510e+01, -9.29830e+00, -1.69350e+00,\n",
       "         3.45580e+00,  2.55950e+00, -2.42432e+01,  6.87060e+00,\n",
       "         6.68000e-02,  1.28041e+01,  1.20169e+01,  1.85840e+00,\n",
       "         4.15230e+00,  3.87170e+00,  4.69320e+00, -3.68000e-01,\n",
       "        -1.38225e+01,  1.54566e+01,  1.08374e+01,  1.18825e+01,\n",
       "         1.03509e+01, -2.66786e+01,  1.25065e+01, -3.27564e+01,\n",
       "        -7.70160e+00,  4.64530e+00,  1.19592e+01,  1.00319e+01,\n",
       "        -1.51450e+00,  6.64430e+00, -7.18420e+00,  1.16773e+01,\n",
       "         2.00610e+01,  6.90350e+00,  5.87800e-01,  8.17050e+00,\n",
       "         1.38105e+01, -1.99650e+01,  1.73020e+00,  3.03300e+00,\n",
       "         8.56530e+00, -1.54890e+00,  8.19170e+00,  5.22630e+00,\n",
       "         5.02320e+00,  3.46580e+00,  2.92572e+01,  9.70900e-01,\n",
       "        -1.19870e+00,  8.76340e+00,  1.85294e+01,  1.10647e+01,\n",
       "         2.84980e+00,  1.50201e+01,  4.29980e+00,  1.38608e+01,\n",
       "         5.17210e+00,  1.19109e+01,  4.24520e+00,  1.09054e+01,\n",
       "         3.73530e+00,  1.55390e+01,  5.78190e+00,  1.24500e+01,\n",
       "         1.15410e+01,  2.78610e+00, -3.34544e+01,  6.98380e+00,\n",
       "         1.36569e+01,  1.09595e+01,  1.19729e+01, -4.62500e-01,\n",
       "         1.27476e+01,  1.84625e+01,  2.23830e+00, -2.83140e+00,\n",
       "         2.13130e+00,  7.51380e+00,  2.97536e+01,  1.36730e+00,\n",
       "         1.14873e+01,  4.53080e+00,  6.12360e+00,  1.78274e+01,\n",
       "         1.41225e+01,  1.92557e+01,  5.15800e+00,  7.13370e+00,\n",
       "         6.37520e+00,  1.43607e+01,  4.66600e+00,  7.39000e-02,\n",
       "         1.98730e+00, -6.23660e+00,  1.28098e+01,  2.52430e+00,\n",
       "         3.67557e+01,  9.43450e+00,  9.70100e+00,  4.32450e+00,\n",
       "         1.90180e+00,  1.27335e+01,  1.36362e+01,  2.95350e+00,\n",
       "        -1.83270e+00,  2.12024e+01,  1.22598e+01,  1.92000e-02,\n",
       "         6.86460e+00,  6.64050e+00,  2.02080e+00, -8.53600e+00,\n",
       "         1.27060e+01,  7.20620e+00,  1.15419e+01,  1.47860e+01,\n",
       "         9.54260e+00, -4.76630e+00,  1.04099e+01,  1.21088e+01,\n",
       "         7.47910e+00,  3.74830e+00,  8.30070e+00, -1.61357e+01,\n",
       "         4.10780e+00,  2.30593e+01,  1.63337e+01,  1.02347e+01,\n",
       "         6.25370e+00,  1.51654e+01,  4.03620e+00, -1.27257e+01,\n",
       "         1.24911e+01, -8.74950e+00,  3.13433e+01,  6.96850e+00,\n",
       "         2.27062e+01,  5.89350e+00,  4.89820e+00,  1.59987e+01,\n",
       "         1.57080e+00,  2.21671e+01,  2.63800e+00, -7.94260e+00,\n",
       "         8.59430e+00,  5.49390e+00,  5.13490e+00,  4.50120e+00,\n",
       "         2.64348e+01, -5.80470e+00,  3.20266e+01,  8.80830e+00,\n",
       "        -2.81440e+00,  1.66939e+01, -1.09847e+01,  6.13500e-01,\n",
       "        -1.45520e+00,  1.01348e+01,  1.68976e+01,  4.55030e+00,\n",
       "         2.90499e+01, -9.36330e+00,  1.12679e+01, -1.20766e+01,\n",
       "         1.11868e+01,  6.49100e-01,  8.01650e+00,  6.14760e+00,\n",
       "         7.67000e-01,  4.76790e+00,  1.88727e+01,  2.46380e+00,\n",
       "         2.51030e+00,  8.57020e+00,  1.69667e+01,  6.73990e+00]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_test_values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(features):\n",
    "    holdout_df[feature] = holdout_test_values[:, i]\n",
    "    holdout_df['mean_' + feature] = (holdout_df[feature].mean() - holdout_df[feature])\n",
    "    holdout_df['z_' + feature] = (holdout_df[feature] - holdout_df[feature].mean()) / holdout_df[feature].std(ddof=0)\n",
    "    holdout_df['sq_' + feature] = (holdout_df[feature]) ** 2\n",
    "    holdout_df['sqrt_' + feature] = (holdout_df['sq_' + feature]) ** (1 / 4)\n",
    "    holdout_df['log_' + feature] = np.log(holdout_df['sq_' + feature] +10 ) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 31us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(holdout_df.values, holdout_test_target_values, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4954945859909057, 0.899675, 0.7047215181122616]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
