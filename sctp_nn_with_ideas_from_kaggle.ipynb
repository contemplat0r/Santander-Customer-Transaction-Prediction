{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from keras import callbacks\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "train_targets = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "for feature in features:\n",
    "    train_features['mean_'+feature] = (train_features[feature].mean()-train_features[feature])\n",
    "    train_features['z_'+feature] = (train_features[feature] - train_features[feature].mean()) / train_features[feature].std(ddof=0)\n",
    "    train_features['sq_'+feature] = (train_features[feature])**2\n",
    "    train_features['sqrt_'+feature] = (train_features['sq_'+feature])**(1/4)\n",
    "    train_features['log_'+feature] = np.log(train_features['sq_'+feature]+10)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_var_198</th>\n",
       "      <th>z_var_198</th>\n",
       "      <th>sq_var_198</th>\n",
       "      <th>sqrt_var_198</th>\n",
       "      <th>log_var_198</th>\n",
       "      <th>mean_var_199</th>\n",
       "      <th>z_var_199</th>\n",
       "      <th>sq_var_199</th>\n",
       "      <th>sqrt_var_199</th>\n",
       "      <th>log_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>3.09042</td>\n",
       "      <td>-1.026398</td>\n",
       "      <td>163.336068</td>\n",
       "      <td>3.574955</td>\n",
       "      <td>2.577616</td>\n",
       "      <td>-2.235137</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>1.191154</td>\n",
       "      <td>1.044701</td>\n",
       "      <td>1.207562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.48528</td>\n",
       "      <td>0.825417</td>\n",
       "      <td>336.942736</td>\n",
       "      <td>4.284390</td>\n",
       "      <td>2.924580</td>\n",
       "      <td>-5.278337</td>\n",
       "      <td>0.505685</td>\n",
       "      <td>3.809523</td>\n",
       "      <td>1.397068</td>\n",
       "      <td>1.312679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14852</td>\n",
       "      <td>-0.381449</td>\n",
       "      <td>216.743173</td>\n",
       "      <td>3.836952</td>\n",
       "      <td>2.711909</td>\n",
       "      <td>-3.723037</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>0.157212</td>\n",
       "      <td>0.629682</td>\n",
       "      <td>1.159092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.09898</td>\n",
       "      <td>0.697118</td>\n",
       "      <td>322.910118</td>\n",
       "      <td>4.239068</td>\n",
       "      <td>2.903936</td>\n",
       "      <td>5.673063</td>\n",
       "      <td>-0.543502</td>\n",
       "      <td>80.992800</td>\n",
       "      <td>2.999933</td>\n",
       "      <td>2.255390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.12668</td>\n",
       "      <td>0.706318</td>\n",
       "      <td>323.906407</td>\n",
       "      <td>4.242334</td>\n",
       "      <td>2.905430</td>\n",
       "      <td>5.483863</td>\n",
       "      <td>-0.525375</td>\n",
       "      <td>77.623148</td>\n",
       "      <td>2.968232</td>\n",
       "      <td>2.236523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9     ...       mean_var_198  z_var_198  sq_var_198  sqrt_var_198  \\\n",
       "0  5.7470     ...            3.09042  -1.026398  163.336068      3.574955   \n",
       "1  8.0851     ...           -2.48528   0.825417  336.942736      4.284390   \n",
       "2  5.9525     ...            1.14852  -0.381449  216.743173      3.836952   \n",
       "3  8.2450     ...           -2.09898   0.697118  322.910118      4.239068   \n",
       "4  7.6784     ...           -2.12668   0.706318  323.906407      4.242334   \n",
       "\n",
       "   log_var_198  mean_var_199  z_var_199  sq_var_199  sqrt_var_199  log_var_199  \n",
       "0     2.577616     -2.235137   0.214135    1.191154      1.044701     1.207562  \n",
       "1     2.924580     -5.278337   0.505685    3.809523      1.397068     1.312679  \n",
       "2     2.711909     -3.723037   0.356681    0.157212      0.629682     1.159092  \n",
       "3     2.903936      5.673063  -0.543502   80.992800      2.999933     2.255390  \n",
       "4     2.905430      5.483863  -0.525375   77.623148      2.968232     2.236523  \n",
       "\n",
       "[5 rows x 1200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train_features = sc.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_features.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printAUC(callbacks.Callback):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super(printAUC, self).__init__()\n",
    "        self.bestAUC = 0\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pred = self.model.predict(np.array(self.X_train))\n",
    "        auc = roc_auc_score(self.y_train, pred)\n",
    "        print(\"Train AUC: \" + str(auc))\n",
    "        #pred = self.model.predict(self.validation_data[0])\n",
    "        #auc = roc_auc_score(self.validation_data[1], pred)\n",
    "        #print (\"Validation AUC: \" + str(auc))\n",
    "        if (self.bestAUC < auc) :\n",
    "            self.bestAUC = auc\n",
    "            self.model.save(\"bestNet.h5\", overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def augment(x, y, t=2):\n",
    "    xs, xn = [], []\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t // 2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x, xs, xn])\n",
    "    y = np.concatenate([y, ys, yn])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "standart_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_train_values = min_max_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "scaled_train_values = standart_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])\n",
    "#scaled_train_values = robust_scaler.fit_transform(train_df[train_df.columns.drop(['ID_code', 'target'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = train_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, holdout_test_values, train_target_values, holdout_test_target_values = train_test_split(\n",
    "    #scaled_train_values,\n",
    "    train_df[train_df.columns.drop(['ID_code', 'target'])].values,\n",
    "    target_values,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 200)\n",
      "(160000,)\n",
      "(40000, 200)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_values.shape)\n",
    "print(train_target_values.shape)\n",
    "print(holdout_test_values.shape)\n",
    "print(holdout_test_target_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_code = test_df['ID_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0' 'test_1' 'test_2' 'test_3' 'test_4' 'test_5' 'test_6' 'test_7'\n",
      " 'test_8' 'test_9']\n"
     ]
    }
   ],
   "source": [
    "print(ID_code[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.py_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "#def auc(y_pred, y_true):\n",
    "    #print(y_true[:5])\n",
    "    #print(y_pred[:5])  \n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    #return tf.py_func(roc_auc_score, (y_true, y_pred), tf.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести mean_shift кластеризацию на множестве переменных (features)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts = sequential_nn_model.predict(test_df[test_df.columns.drop('ID_code')].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(submission_predicts[:5])\n",
    "#submission_predicts_values = submission_predicts[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(submission_predicts_values < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values >= 0.245].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values < 0.245] = 0\n",
    "#submission_predicts_values[submission_predicts_values >= 0.245] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_predicts_values[submission_predicts_values == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts_values.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df.to_csv('submission_mlp_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_threshold(classes_ratio, step_size, predicted_values):\n",
    "    threshold = predicted_values.min()\n",
    "    values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "    values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "    #threshold_classes_ratio =  values_above_threshold / values_below_threshold\n",
    "    threshold_classes_ratio = 1\n",
    "    \n",
    "    while(threshold_classes_ratio > classes_ratio):\n",
    "        threshold += step_size        \n",
    "        values_below_threshold = (predicted_values[predicted_values < threshold]).shape[0]\n",
    "        values_above_threshold = (predicted_values[predicted_values >= threshold]).shape[0]\n",
    "        threshold_classes_ratio =  values_above_threshold / values_below_threshold\n",
    "    predicted_values[predicted_values < threshold] = 0\n",
    "    predicted_values[predicted_values >= threshold] = 1\n",
    "    return threshold, predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model = None\n",
    "#del sequential_nn_model\n",
    "if sequential_nn_model:\n",
    "    del sequential_nn_model\n",
    "sequential_nn_model = Sequential()\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=200, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=100, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=50, kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dense(batch_size, input_shape=(100, 200), kernel_initializer='normal', activation='sigmoid'))\n",
    "#sequential_nn_model.add(Dropout(0.76))\n",
    "#sequential_nn_model.add(Dropout(0.24))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(batch_size, input_dim=10, kernel_initializer='normal', activation='sigmoid'))\n",
    "sequential_nn_model.add(Dropout(0.1))\n",
    "sequential_nn_model.add(BatchNormalization())\n",
    "sequential_nn_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential_nn_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy', auc])\n",
    "sequential_nn_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/40\n",
      "128000/128000 [==============================] - 26s 200us/step - loss: 0.3457 - acc: 0.8751 - auc: 0.6574 - val_loss: 0.2586 - val_acc: 0.9023 - val_auc: 0.8147\n",
      "Epoch 2/40\n",
      "128000/128000 [==============================] - 22s 173us/step - loss: 0.2776 - acc: 0.8985 - auc: 0.7852 - val_loss: 0.2502 - val_acc: 0.9023 - val_auc: 0.8280\n",
      "Epoch 3/40\n",
      "128000/128000 [==============================] - 23s 177us/step - loss: 0.2684 - acc: 0.8985 - auc: 0.8067 - val_loss: 0.2474 - val_acc: 0.9124 - val_auc: 0.8313\n",
      "Epoch 4/40\n",
      "128000/128000 [==============================] - 22s 174us/step - loss: 0.2663 - acc: 0.8993 - auc: 0.8094 - val_loss: 0.2535 - val_acc: 0.9023 - val_auc: 0.8319\n",
      "Epoch 5/40\n",
      "128000/128000 [==============================] - 22s 172us/step - loss: 0.2659 - acc: 0.8986 - auc: 0.8106 - val_loss: 0.2469 - val_acc: 0.9023 - val_auc: 0.8333\n",
      "Epoch 6/40\n",
      "128000/128000 [==============================] - 23s 177us/step - loss: 0.2640 - acc: 0.8992 - auc: 0.8137 - val_loss: 0.2465 - val_acc: 0.9023 - val_auc: 0.8346\n",
      "Epoch 7/40\n",
      "128000/128000 [==============================] - 23s 177us/step - loss: 0.2622 - acc: 0.8996 - auc: 0.8173 - val_loss: 0.2479 - val_acc: 0.9023 - val_auc: 0.8373\n",
      "Epoch 8/40\n",
      "128000/128000 [==============================] - 22s 172us/step - loss: 0.2627 - acc: 0.8994 - auc: 0.8172 - val_loss: 0.2530 - val_acc: 0.9065 - val_auc: 0.8354\n",
      "Epoch 9/40\n",
      "128000/128000 [==============================] - 22s 170us/step - loss: 0.2642 - acc: 0.8984 - auc: 0.8150 - val_loss: 0.2496 - val_acc: 0.9023 - val_auc: 0.8368\n",
      "Epoch 10/40\n",
      "128000/128000 [==============================] - 22s 174us/step - loss: 0.2612 - acc: 0.8985 - auc: 0.8217 - val_loss: 0.2521 - val_acc: 0.9023 - val_auc: 0.8377\n",
      "Epoch 11/40\n",
      "128000/128000 [==============================] - 22s 175us/step - loss: 0.2586 - acc: 0.9007 - auc: 0.8255 - val_loss: 0.2565 - val_acc: 0.9099 - val_auc: 0.8383\n",
      "Epoch 12/40\n",
      "128000/128000 [==============================] - 22s 172us/step - loss: 0.2575 - acc: 0.9002 - auc: 0.8285 - val_loss: 0.2515 - val_acc: 0.9077 - val_auc: 0.8381\n",
      "Epoch 13/40\n",
      " 92900/128000 [====================>.........] - ETA: 5s - loss: 0.2566 - acc: 0.9010 - auc: 0.8284"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[Node: metrics/auc/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_DOUBLE], token=\"pyfunc_0\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_dense_7_target_0_1, dense_7/Sigmoid/_389)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-03b0aa3c5592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msequential_nn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run time {} min\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[Node: metrics/auc/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_DOUBLE], token=\"pyfunc_0\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_dense_7_target_0_1, dense_7/Sigmoid/_389)]]"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sequential_nn_model.fit(train_values, train_target_values, batch_size=100, epochs=40, verbose=1, validation_split=0.2)\n",
    "print(\"Run time {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = sequential_nn_model.evaluate(holdout_test_values, holdout_test_target_values, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics\n",
    "# [0.25161404045298696, 0.9094000032544136, 0.8320361980522218] [0.2493363002128899, 0.9096750013530255, 0.8369347876192563]\n",
    "# [0.24582509476691483, 0.9101250021159649, 0.8396344886385845] [0.24802235754206778, 0.9094000029563903, 0.8385308386618173]\n",
    "# [0.24494799628853797, 0.9102000007033348, 0.839084512352511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = sequential_nn_model.to_json()\n",
    "with open(\"sequential_nn_model_relu_droput024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.save(\"sequential_nn_model_relu_dropout024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_nn_model.save_weights(\"sequential_nn_model_weights_relu_dropout024_lr001_sigmoid_batchnorm_40_epochs_2019-03-31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_predict_values = sequential_nn_model.predict(test_df[test_df.columns.drop('ID_code')].values)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ratio = train_df[train_df['target'] == 1].shape[0] / train_df[train_df['target'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1117163789174106"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, submission_predicts = detect_threshold(classes_ratio, 0.01, submission_predict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38138799776323157"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180180,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_predicts[submission_predicts == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19820,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_predicts[submission_predicts == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'ID_code': ID_code, 'target': submission_predicts.astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_mlp_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1200)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer=regularizers.l2(0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(PreLU(alpha=.001))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2357 - acc: 0.9109 - auc: 0.8603 - val_loss: 0.2197 - val_acc: 0.9173 - val_auc: 0.8771\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2334 - acc: 0.9114 - auc: 0.8639 - val_loss: 0.2215 - val_acc: 0.9168 - val_auc: 0.8761\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2311 - acc: 0.9115 - auc: 0.8678 - val_loss: 0.2177 - val_acc: 0.9186 - val_auc: 0.8779\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2294 - acc: 0.9125 - auc: 0.8706 - val_loss: 0.2191 - val_acc: 0.9187 - val_auc: 0.8762\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2288 - acc: 0.9126 - auc: 0.8715 - val_loss: 0.2191 - val_acc: 0.9182 - val_auc: 0.8770\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2269 - acc: 0.9131 - auc: 0.8746 - val_loss: 0.2197 - val_acc: 0.9181 - val_auc: 0.8778\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2257 - acc: 0.9139 - auc: 0.8757 - val_loss: 0.2183 - val_acc: 0.9185 - val_auc: 0.8773\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2245 - acc: 0.9144 - auc: 0.8775 - val_loss: 0.2165 - val_acc: 0.9198 - val_auc: 0.8787\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2240 - acc: 0.9140 - auc: 0.8780 - val_loss: 0.2172 - val_acc: 0.9201 - val_auc: 0.8786\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2230 - acc: 0.9146 - auc: 0.8796 - val_loss: 0.2182 - val_acc: 0.9190 - val_auc: 0.8780\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 5s 27us/step - loss: 0.2217 - acc: 0.9152 - auc: 0.8808 - val_loss: 0.2199 - val_acc: 0.9182 - val_auc: 0.8773\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 5s 26us/step - loss: 0.2216 - acc: 0.9149 - auc: 0.8817 - val_loss: 0.2211 - val_acc: 0.9167 - val_auc: 0.8774\n",
      "Epoch 13/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2193 - acc: 0.9158 - auc: 0.8847 - val_loss: 0.2183 - val_acc: 0.9195 - val_auc: 0.8785\n",
      "Epoch 14/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2189 - acc: 0.9159 - auc: 0.8853 - val_loss: 0.2214 - val_acc: 0.9185 - val_auc: 0.8790\n",
      "Epoch 15/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2173 - acc: 0.9165 - auc: 0.8871 - val_loss: 0.2174 - val_acc: 0.9199 - val_auc: 0.8782\n",
      "Epoch 16/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2163 - acc: 0.9176 - auc: 0.8877 - val_loss: 0.2191 - val_acc: 0.9191 - val_auc: 0.8785\n",
      "Epoch 17/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2157 - acc: 0.9177 - auc: 0.8885 - val_loss: 0.2174 - val_acc: 0.9197 - val_auc: 0.8787\n",
      "Epoch 18/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2152 - acc: 0.9172 - auc: 0.8898 - val_loss: 0.2190 - val_acc: 0.9193 - val_auc: 0.8769\n",
      "Epoch 19/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2137 - acc: 0.9183 - auc: 0.8909 - val_loss: 0.2176 - val_acc: 0.9201 - val_auc: 0.8779\n",
      "Epoch 20/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2129 - acc: 0.9184 - auc: 0.8921 - val_loss: 0.2241 - val_acc: 0.9190 - val_auc: 0.8776\n",
      "Epoch 21/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2122 - acc: 0.9191 - auc: 0.8930 - val_loss: 0.2199 - val_acc: 0.9187 - val_auc: 0.8765\n",
      "Epoch 22/50\n",
      "180000/180000 [==============================] - 6s 31us/step - loss: 0.2110 - acc: 0.9190 - auc: 0.8946 - val_loss: 0.2229 - val_acc: 0.9188 - val_auc: 0.8765\n",
      "Epoch 23/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2101 - acc: 0.9195 - auc: 0.8957 - val_loss: 0.2193 - val_acc: 0.9190 - val_auc: 0.8770\n",
      "Epoch 24/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2103 - acc: 0.9194 - auc: 0.8948 - val_loss: 0.2207 - val_acc: 0.9192 - val_auc: 0.8763\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2181 - acc: 0.9173 - auc: 0.8850 - val_loss: 0.2094 - val_acc: 0.9228 - val_auc: 0.8976\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 5s 27us/step - loss: 0.2176 - acc: 0.9169 - auc: 0.8860 - val_loss: 0.2093 - val_acc: 0.9223 - val_auc: 0.8940\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 5s 27us/step - loss: 0.2179 - acc: 0.9176 - auc: 0.8856 - val_loss: 0.2125 - val_acc: 0.9191 - val_auc: 0.8906\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2155 - acc: 0.9183 - auc: 0.8880 - val_loss: 0.2119 - val_acc: 0.9216 - val_auc: 0.8889\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 6s 31us/step - loss: 0.2159 - acc: 0.9182 - auc: 0.8868 - val_loss: 0.2129 - val_acc: 0.9208 - val_auc: 0.8886\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2143 - acc: 0.9185 - auc: 0.8891 - val_loss: 0.2139 - val_acc: 0.9200 - val_auc: 0.8876\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 5s 31us/step - loss: 0.2137 - acc: 0.9191 - auc: 0.8902 - val_loss: 0.2173 - val_acc: 0.9184 - val_auc: 0.8871\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2132 - acc: 0.9191 - auc: 0.8905 - val_loss: 0.2153 - val_acc: 0.9200 - val_auc: 0.8853\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2112 - acc: 0.9203 - auc: 0.8923 - val_loss: 0.2177 - val_acc: 0.9193 - val_auc: 0.8848\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 6s 31us/step - loss: 0.2108 - acc: 0.9200 - auc: 0.8932 - val_loss: 0.2156 - val_acc: 0.9205 - val_auc: 0.8847\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 5s 31us/step - loss: 0.2095 - acc: 0.9210 - auc: 0.8939 - val_loss: 0.2151 - val_acc: 0.9194 - val_auc: 0.8850\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2141 - acc: 0.9188 - auc: 0.8899 - val_loss: 0.1986 - val_acc: 0.9241 - val_auc: 0.9065\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2141 - acc: 0.9193 - auc: 0.8888 - val_loss: 0.2051 - val_acc: 0.9217 - val_auc: 0.9029\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2125 - acc: 0.9198 - auc: 0.8905 - val_loss: 0.2036 - val_acc: 0.9233 - val_auc: 0.8999\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2131 - acc: 0.9203 - auc: 0.8899 - val_loss: 0.2068 - val_acc: 0.9225 - val_auc: 0.8984\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2115 - acc: 0.9203 - auc: 0.8927 - val_loss: 0.2075 - val_acc: 0.9217 - val_auc: 0.8969\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 5s 27us/step - loss: 0.2106 - acc: 0.9202 - auc: 0.8934 - val_loss: 0.2126 - val_acc: 0.9189 - val_auc: 0.8939\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2099 - acc: 0.9207 - auc: 0.8940 - val_loss: 0.2077 - val_acc: 0.9220 - val_auc: 0.8938\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2083 - acc: 0.9218 - auc: 0.8956 - val_loss: 0.2092 - val_acc: 0.9219 - val_auc: 0.8939\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2082 - acc: 0.9221 - auc: 0.8956 - val_loss: 0.2120 - val_acc: 0.9200 - val_auc: 0.8938\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2076 - acc: 0.9218 - auc: 0.8968 - val_loss: 0.2102 - val_acc: 0.9218 - val_auc: 0.8926\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2074 - acc: 0.9217 - auc: 0.8970 - val_loss: 0.2138 - val_acc: 0.9182 - val_auc: 0.8925\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2110 - acc: 0.9212 - auc: 0.8915 - val_loss: 0.1977 - val_acc: 0.9274 - val_auc: 0.9132\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2101 - acc: 0.9211 - auc: 0.8937 - val_loss: 0.1961 - val_acc: 0.9273 - val_auc: 0.9081\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2090 - acc: 0.9213 - auc: 0.8942 - val_loss: 0.1994 - val_acc: 0.9244 - val_auc: 0.9070\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2091 - acc: 0.9215 - auc: 0.8940 - val_loss: 0.1997 - val_acc: 0.9242 - val_auc: 0.9044\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2087 - acc: 0.9215 - auc: 0.8945 - val_loss: 0.2021 - val_acc: 0.9230 - val_auc: 0.9032\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2062 - acc: 0.9233 - auc: 0.8979 - val_loss: 0.2004 - val_acc: 0.9251 - val_auc: 0.9031\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2067 - acc: 0.9230 - auc: 0.8963 - val_loss: 0.2074 - val_acc: 0.9189 - val_auc: 0.9013\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2058 - acc: 0.9230 - auc: 0.8986 - val_loss: 0.2062 - val_acc: 0.9212 - val_auc: 0.9010\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 5s 29us/step - loss: 0.2050 - acc: 0.9234 - auc: 0.8989 - val_loss: 0.2055 - val_acc: 0.9216 - val_auc: 0.9011\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 5s 30us/step - loss: 0.2037 - acc: 0.9246 - auc: 0.9003 - val_loss: 0.2028 - val_acc: 0.9237 - val_auc: 0.9001\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 5s 28us/step - loss: 0.2028 - acc: 0.9245 - auc: 0.9007 - val_loss: 0.2056 - val_acc: 0.9218 - val_auc: 0.8993\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "178688/180000 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9225 - auc: 0.8968"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[Node: metrics_2/auc/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_DOUBLE], token=\"pyfunc_2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_dense_18_target_0_1, dense_18/Sigmoid/_1357)]]\n\t [[Node: metrics_2/auc/PyFunc/_1403 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_235_metrics_2/auc/PyFunc\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-79421bb68851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#X_tr, y_tr = augment(X_train.values, y_train.values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(\"{} iteration\".format(i+1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/home/uldo/miniconda3/envs/DS-New/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[Node: metrics_2/auc/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_DOUBLE], token=\"pyfunc_2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_dense_18_target_0_1, dense_18/Sigmoid/_1357)]]\n\t [[Node: metrics_2/auc/PyFunc/_1403 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_235_metrics_2/auc/PyFunc\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "loss_history = LossHistory()\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [EarlyStopping(monitor='val_auc', patience=5, mode='max'), loss_history, annealer]\n",
    "sss = StratifiedShuffleSplit(n_splits=10)\n",
    "start_time = time.time()\n",
    "for train_index, test_index in sss.split(train_features, train_targets):\n",
    "    X_train, X_val = train_features[train_index], train_features[test_index]\n",
    "    Y_train, Y_val = train_targets[train_index], train_targets[test_index]\n",
    "    #X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "    #print(\"{} iteration\".format(i+1))\n",
    "    history= model.fit(X_train, Y_train, batch_size=512, epochs=50, callbacks=callbacks_list, verbose=1, validation_data=(X_val,Y_val))\n",
    "    del X_train, X_val, Y_train, Y_val\n",
    "    gc.collect()\n",
    "print(\"Run time {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, train_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "test_features = test.drop(['ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    test_features['mean_'+feature] = (test_features[feature].mean()-test_features[feature])\n",
    "    test_features['z_'+feature] = (test_features[feature] - test_features[feature].mean())/test_features[feature].std(ddof=0)\n",
    "    test_features['sq_'+feature] = (test_features[feature])**2\n",
    "    test_features['sqrt_'+feature] = (test_features['sq_'+feature])**(1/4)\n",
    "    test_features['log_'+feature] = np.log(test_features['sq_'+feature]+10)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = sc.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_code_test = test['ID_code']\n",
    "# Make predicitions\n",
    "pred = model.predict(test_features)\n",
    "pred_ = pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['target'].mean())\n",
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({\"ID_code\" : id_code_test, \"target\" : pred_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('submission.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
